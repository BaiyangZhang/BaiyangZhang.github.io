<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://baiyangzhang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://baiyangzhang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-26T03:48:30+00:00</updated><id>https://baiyangzhang.github.io/feed.xml</id><title type="html">Baiyang Zhang</title><subtitle>A place dedicated to sharing insights and reflections on mathematics, physics, and social sciences. </subtitle><entry><title type="html">Kink in Quantum Field Theory, A Broad Outline</title><link href="https://baiyangzhang.github.io/blog/2024/Quantum-Kinks/" rel="alternate" type="text/html" title="Kink in Quantum Field Theory, A Broad Outline"/><published>2024-02-25T00:00:00+00:00</published><updated>2024-02-25T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Quantum-Kinks</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Quantum-Kinks/"><![CDATA[<p>Since the details of calculation can be found in other notes, here I will only talk about the broad outline. I will use as few as formula as possible.</p> <p>We does it mean to <em>quantize</em> the kink? It is similar to what we mean by <em>quantizing the free theory</em>? Generally speaking, there exist two different but equivalent methods, the canonical quantization and path integral quantization. Regarding the canonical quantization,</p> <ol> <li>given a classical field theory, we first need to identify the equation of motion and its set of solutions, namely eigen functions.</li> <li>Expand the fields in these eigenfunctions, this is how we diagonalize the Hamiltonian.</li> <li>Introduce the canonical quantization relation.</li> </ol> <p>In textbooks we always start from some simple model for scalar fields $\phi$, based on which the above steps are illustrated. The vacuum of the field theory is conveniently chose as $\phi=0$. In a sense, we are expanding the field in the background of $0$, namely the vacuum of the model. Then to quantize the kink simply means we change the background about which we expand the scalar field, from zero to the specific kink solution.</p> <p>Using the picture of path integral things are much more obvious. Here, to consider the quantum correction to a kink solution is to include the quantum effects of fluctuation about the classical kink solution.</p> <p>The quantization we described above is akin to the familiar second quantization. Further, if one would like to describe the creation and annihilation of kinks themselves by suitable kink creation and annihilation operators, this would be what people call the <em>third quantization</em>.</p> <p>It turns out that quantum corrections always reduces the kink energy.</p> <hr/> <p>We will adopt perturbative methods to study the quantization of kinks. As we all know, perturbation stops working at strong coupling, $\lambda \gg 1$. What happens to $\mathcal{Z}_ {2}$ and sine-Gordon kinks when the coupling is large? From the classical kink solution we know that the mass of a kink is proportional to $1 / \lambda$, so the kink mass decreases as $\lambda$ increases. Eventually kinks will be even lighter than mesons. At large $\lambda$ we know much more in sine-Gordon model than $\mathcal{Z}_ {2}$ model. In sine-Gordon, we have a dual theory, namely the massive Thirring model.</p> <h1 id="quantization-procedure">Quantization procedure</h1> <p>The broad outline is as following.</p> <ol> <li>Consider the 2D QFT model with compact spatial dimension of size $L$. Let $\phi$ be the degree of freedom. We could adopt either periodic or anti-periodic boundary condition. Eventually we will take $L \to \infty$, but for now it is large but finite.</li> <li>Consider small quantum fluctuation $\psi$ about the kink ground $\phi_ {k}$, namely $\psi = \phi - \phi_ {k}$.</li> <li>Linearize the equation for the fluctuation field $\psi$ (not the original field). Find the solutions, also known as <code class="language-plaintext highlighter-rouge">eigenmodes</code> or <code class="language-plaintext highlighter-rouge">normal modes</code>. Expand the fluctuation field $\psi$ in normal modes.</li> <li><code class="language-plaintext highlighter-rouge">Quantization.</code> Each normal mode corresponds to a quantum harmonic oscillator, with zero point fluctuations. Sum up the zero point energies of all the normal modes. This is the quantum correction we were looking for, but without appropriate renormalization procedure the sum is divergent.</li> <li><code class="language-plaintext highlighter-rouge">Renormalization</code> must be performed. This is the subtle part. The zero point energy of the trivial vacuum (without kink background) must be subtracted from the zero point energy of the kink, since we want the energy of the trivial vacuum to be zero. Also, the energy must be expressed in terms of renormalized parameters.</li> </ol> <p>As we turn on the potential slowly, some of the low-lying modes in the trivial box become the bound states of the kink.</p> <p>Notice that in the trivial vacuum, the solutions to the equation of motion, a.k.a. the scattering states, are plane waves. They are eigenfunctions to both energy and momentum operator; in the presence of a kink, however, the scattering states are now normal modes, which are eigenstates of energy operator but <em>not eigenstates to momentum operator</em>.</p> <p>To consistently compare the energy difference between trivial vacuum sector (just vacuum sector from now on) and kink sector, we need to carefully match discrete modes (thanks to finite box size $L$) in these two.</p>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Since the details of calculation can be found in other notes, here I will only talk about the broad outline. I will use as few as formula as possible.]]></summary></entry><entry><title type="html">Note on the kink mass correction in 3D Part I</title><link href="https://baiyangzhang.github.io/blog/2024/Note-on-Kink-Mass-Correction-in-3D-Part-I/" rel="alternate" type="text/html" title="Note on the kink mass correction in 3D Part I"/><published>2024-01-25T00:00:00+00:00</published><updated>2024-01-25T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Note-on-Kink-Mass-Correction-in-3D-Part-I</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Note-on-Kink-Mass-Correction-in-3D-Part-I/"><![CDATA[<h1 id="1-introduction">1 Introduction</h1> <h2 id="11-background">1.1 Background</h2> <p>We will establish the model and notation in this section. First, some nomenclatures.</p> <p><code class="language-plaintext highlighter-rouge">Shape modes</code>: In theories with a kink solution, the equation of motion in the background of the kink typically has discrete, bounded solutions. They are called <code class="language-plaintext highlighter-rouge">shape modes</code>. They are localized around the kink. Shape modes represent small fluctuations or deformations of the kink’s shape. Unlike the continuum of delocalized modes that represent free particle states, the shape modes are confined to the vicinity of the kink, with discrete energy levels.</p> <p><code class="language-plaintext highlighter-rouge">Oscillons</code>: They are localized, non-solitonic, and semi-stable field configurations that oscillate in time. They are interesting because they represent a form of partial stable, localized energy concentration that can persist for long times, even though they are not topologically protected like solitons or kinks. Oscillons are found in various nonlinear field theories and have been studied in different contexts, including cosmology and condensed matter physics. Their persistence and behaviors under various conditions are subjects of ongoing research in theoretical physics. However, it is believed that quantum correction will make oscillons rapidly decay into a pair of fundamental particles.</p> <p><code class="language-plaintext highlighter-rouge">The Unruh effect</code>: The Unruh effect is a prediction in quantum field theory, stating that an observer accelerating through a vacuum will perceive a thermal bath of particles, whereas an inertial observer would see none. This effect arises from the realization that <em>the concept of a vacuum state (or empty space) is observer-dependent</em>. For an accelerating observer, what appears as empty space to an inertial observer is seen as a warm gas of particles. This effect, named after physicist William Unruh, highlights the interplay between quantum theory and relativity, especially in contexts like black hole physics.</p> <p>In the frame work of the linearized soliton perturbation theory, we can systematically study the quantum corrections to both static and time-dependent solitonic solutions.</p> <hr/> <p>Firstly, we work in the Schrodinger picture where the operator are time-independent while the wave functions (vectors in Hilbert space) are time dependent. Secondly, we will start with the Hamiltonian formalism where the canonical momentum, $\pi$, is considered as a fundamental ingredient, rather than the time derivative of $\phi$, the field of the Lagrangian.</p> <p>In $2+1$ dimension, the Hamiltonian $H$ is the integral of the Hamiltonian density $\mathcal{H}$ over the 2D manifold of space alone,</p> \[H = \int_ {M} d^{2}x\, \mathcal{H}(\phi,\pi),\quad \mathcal{H}=\frac{1}{2}\pi^{2}(x)+\frac{1}{2} (\partial_ i \phi)^{2} + \frac{1}{\lambda}V(\sqrt{ \lambda }\phi(x))\] <p><strong>Dimensional analysis</strong></p> <p>In Lagrangian formalism, $[S]=[\hbar]$ where $S$ is the action, and $S = \int d^d x \, \mathcal{L}$, where $\mathcal{L}$ is the Lagrangian (density) and $d$ is the space-time dimension. Note that right now we are working with a partially “natural” units, where $c=1$ but $\hbar \neq 1$. Since $c=1$ we still have $[x] = [t]$, namely $L=T$ ($L$ is length and $T$ is time), but no longer do we have $T=E^{-1}$ since this is a result of $[\hbar]=ET=1$ (recall that $\hbar \omega=E$, meaning $[\hbar \omega]=E$, and $\omega$ is the frequency with dimension $1 / T$ ).</p> <p>Let $d$ be the dimension of spacetime, in the partial natural unit we have</p> \[\int d^{d}x \, \mathcal{L}\sim \hbar \implies [\mathcal{L}]=[\hbar] L^{-d}\] <p>Take a specific term, say $(\partial \phi)^{2}$, to continue the analysis,</p> \[[(\partial \phi)^{2}] = L^{-2} [\phi^{2}] = [\mathcal{L}] = [\hbar]L^{-d} \implies [\phi^{2}]=[\hbar] L^{2-d}\] <p>which is</p> \[[\phi] = [\sqrt{ \hbar }] \, L^{1-d / 2}.\tag{1}\] <p>This agrees with the convention that field operator $\phi$ scales as $\sqrt{ \hbar }$. Furthermore, this scaling property does not depend on the spacetime dimension $d$, it holds for any spacetime dimension.</p> <p>I don’t think the $\hbar$-dependence given by Eq. (1) is unique, apparently there exist other possibilities, we can move $\hbar$ around in the Lagrangian, just to make sure that the action altogether is of dimension $\hbar$. However it seems that $\phi\sim \hbar^{1/2}$ is indeed the most convenient option. Another way to see the advantage of this choice is from the action,</p> \[S \sim \hbar \sim \int d^{4}x \, (m^{2} \phi^{2}+(\partial \phi)^{2} +U(\phi)),\] <p>then</p> \[\int d^{4}x \, \left[ m^{2} \xi^{2}+(\partial \xi)^{2} + U(\xi) \right] \sim 1, \quad \xi:= \frac{\phi}{\sqrt{ \hbar } } .\] <p>In this way, we can absorb $\hbar$ into the definition of $\phi$, this is similar to absorbing the coupling $g$ into the field definition in gauge theory. We now <em>define</em> $\xi$ to be <em>independent</em> of $\hbar$.</p> <p>Having fixed the $\hbar$-dependence of $\phi$, we can substitute it to the potential $U$, for example the $\phi^{4}$ model to determine the $\hbar$ dependence of the coupling,</p> \[[S]\sim\int d^{d}x \, \lambda \phi^{4} \sim L^{d} [\lambda][\hbar^{2}] L^{4-2d} = L^{4-d}[\hbar^{2}][\lambda],\] <p>on the other hand we already know that $S\sim \hbar$ so</p> \[L^{4-d}[\hbar^{2}][\lambda] = [\hbar] \implies [\lambda \hbar] = L^{d-4}.\] <p>If we choose $L$ to be the fundamental unit instead of energy $E$, it is clear the $\lambda \hbar$ is independent of $\hbar$. Plus, we see that $d=4$ is special.</p> <p>For the sake of completeness, let’s consider the mass term in the Lagrangian. Similar to what we have for the kinetic term,</p> \[[m^{2} \phi^{2}] = E^{2}\, [\phi^{2}] = [\mathcal{L}] = [\hbar]\,L^{-d} \implies [\phi] = [\sqrt{ \hbar }]L^{-d/2}E^{-1} . \tag{2}\] <p><strong>Dimension and measurement</strong></p> <p>If two things are of the same dimension, for example, say</p> \[[A] \sim [a] = L\] <p>where $\sim$ means having the same dimension. Then we can use one of them as the unit to measure the other, say, use $a$ as the “ruler” to measure $A$, the result $\widetilde{A} :=A / a$ is a dimensionless number.</p> <p>Suppose $[\phi]=[\hbar]^{1/2}$, another way to say the same ting is $\phi \sim \sqrt{ \hbar }$, note that the tilde does not imply any relation between the <em>values</em> of $\phi$ and $\sqrt{ \hbar }$, it only means that they have the same dimension. The point is, since they have the same dimension, we can use one of them to measure the other, for example we can define</p> \[\tilde{\phi} = \phi / \sqrt{ \hbar }\] <p>which is a dimensionless number. Since $\hbar$ scales the “quantumness”, the more classical the world is, the smaller $\hbar$ (and $\sqrt{ \hbar }$), hence the bigger numeric value of $\tilde{\phi}$.</p> <hr/> <p>In the partial natural units, I’d like to think there are two fundamental “rulers” to measure all the quantities, such as mass, coupling, field, etc. One of them is the unit of energy, for example $\text{MeV}$, the other is $\hbar$ whose dimension is $ET$. To measure the length of something, we can use $\frac{\hbar}{\text{MeV} }$ as unit. The advantage of the partial natural unit is that it makes explicit the $\hbar$ factor, revealing the direct relations between quantities with $\hbar$, which is the scale of quantumness, this enables us to discern the importance of various quantities in the classical limit, making the analysis regarding semi-classical more straightforward.</p> <h2 id="12-digression-on-hbar-expansion">1.2 Digression on $\hbar$-expansion</h2> <p>To appreciate the importance of $\hbar$, just recall that in canonical quantization $[x,p]=i\hbar$, $\hbar$ enters explicitly in the commutation relation, providing the fundamental basis of quantum theory. This is also true in the case of quantum field theory. Furthermore, at each order of an expansion in $\hbar$, the physical symmetries (Lorentz invariance, $U(1)$ symmetry, etc.) must be satisfied, otherwise there will be some special value of $\hbar$ only at which the symmetries are preserved, which is just strange.</p> <p>In the unit where $c=1$, the Planck’s constant $\hbar$ has the unit of action, or rather the action has the unit of $[\hbar]=ET$, where $E$ is the energy scale and $T$ the time. It turns out that there are more than one way to assign $\hbar$-dependence for quantities such as the mass $m$, the coupling $g,\lambda$ etc. A criterion for the “right” choice is that, at $\hbar\to 0$ limit, the quantum theory agrees with the classical theory. As an example, Stanley Brodsky and Paul Hoyer in their <a href="https://arxiv.org/pdf/1009.2313.pdf">paper</a> used the quantum mechanical harmonic oscillator as an example in Eq.(1). The gist is that, you can rescale $x$ to $x / \sqrt{ \hbar }$, then the propagator is formally independent of $\hbar$. However, this will change how we view distance, in the $\hbar\to 0$ limit, for a fixed distance $L$, the “length” measure will increase as $1 / \sqrt{ \hbar }$, hence we are going to smaller and smaller area.</p> <p>It is generally understood that each loop contribution to amplitudes is associated with one factor of $\hbar$. However, to fully define the $\hbar\to 0$ limit one need to specify the $\hbar$ dependence of various quantities in the Lagrangian as mentioned before, such as the field operator, the mass, the coupling, etc. This is not as straightforward as one might think, for $\hbar$ not only appears in the action $iS / \hbar$ but also appears in the Lagrangian. In Brodsky’s paper mentioned above, the authors proposed a way to establish the $\hbar$ dependence such that the loop and $\hbar$ expansions are equivalent. We will go to more details in the following.</p> <p><strong>First, regard $\hbar$ as a constant of nature with certain dimension, use $\hbar$ to make terms in the Lagrangian dimensionless.</strong></p> <p>Again, let’s work with the assumption that $c = \epsilon_ {0} = 1$. Require $[S]=\hbar$, and $\alpha_ {s} = g^{2} / 4\pi \hbar$ is dimensionless, the latter implies that $[g]=\sqrt{ \hbar }=\sqrt{ ET }=\sqrt{ EL }$. From the self-energy of gluons $G_ {\mu \nu}G^{\mu \nu}$ where $G = \partial A - \partial A +ig / \hbar [A,A]$ we have</p> \[[A] = \sqrt{ \frac{E}{L} }.\] <p>For the same reasons, in the scalar QED the classical electric charge $e$ and mass $m$ are divided by $\hbar$,</p> \[S_ {\text{sQED} } = \int d^{4}x \, \left\lbrace \left\lvert D\phi \right\rvert ^{2}-\frac{m^{2} }{\hbar^{2} }\left\lvert \phi \right\rvert ^{2} \right\rbrace , \quad D = \partial +i \frac{e}{\hbar }A.\] <p>The boson field dimension</p> \[[\phi]=[A]= \sqrt{ \frac{E}{L} }.\] <p>Fermion fields are more complicated, since they have no classical counterparts, their dimensions are convention-dependent. We will deal with fermions in a different note perhaps.</p> <p><strong>Second step is to specify $\hbar$ dependence of all quantities appearing in the action.</strong></p> <p>The choice made by Brodsky and Hoyer is as following:</p> \[\widetilde{A}:= \frac{A}{\sqrt{ \hbar } },\quad \tilde{\phi}:= \frac{\phi}{\sqrt{ \hbar } }\] <p>where $\widetilde{A},\tilde{\phi}$ are $\hbar$-independent. Similarly, define the following $\hbar$-independent quantities</p> \[\widetilde{g}:= \frac{g}{\hbar},\quad \widetilde{e}:= \frac{e}{\hbar},\quad \widetilde{m}:= \frac{m}{\hbar}.\] <p>Then one can write the Lagrangian in terms of these $\hbar$-independent quantities to check the $\hbar$ dependence explicitly. It turns out that, at least in the simple models discussion in the paper, $\hbar$ always appears in the combination</p> \[\widetilde{g}\sqrt{ \hbar } \quad \text{and}\quad \widetilde{e}\sqrt{ \hbar }\] <p>that is, with the coupling. Hence loop correction of $\mathcal{O}(g^{2},e^{2})$ will be of order $\hbar$.</p> <p>This derivation is equivalent to the standard one of, for example, Mark Srednicki’s textbook, which associates a factor $\hbar$ to each propagator and $h^{-1}$ with each vertex, and assume the parameters appearing in the action to be independent of $\hbar$.</p> <p>Fore more details please refer to Brodsky and Hoyer’s paper mentioned above.</p> <h2 id="13-review-of-kink-mass-quantization">1.3 Review of Kink mass quantization</h2> <h1 id="2-kinks-in-3d">2 Kinks in 3D</h1> <p>In R. Jackiw’s <a href="https://www.sciencedirect.com/science/article/abs/pii/037015737690048X">1976 paper</a>, he made three assumption:</p> <ol> <li>The energy (mass) is finite;</li> <li>The energy is locally minimum, meaning the soliton is stable;</li> <li>The potential $U$ depends on a coupling constant $\lambda$ according to the scaling law</li> </ol> \[U(\phi;\lambda) = \frac{1}{\lambda}U(\sqrt{ \lambda }\,\phi;1).\] <p>The choice is such that all the $\lambda$ dependence are now moved to the pre-factor $1 / \lambda$. As for $\hbar$-expansion, we take the scheme such that $\hbar$-expansion agrees with $\lambda$-expansion, namely each loop brings in a factor of $\hbar$.</p> <p>Let the Hamiltonian be</p> \[H = \int d^{2}x \, : \mathcal{H} :_ {a},\quad \mathcal{H}(x) = \frac{\pi^{2} }{2} + \frac{(\partial_ {x}\phi(x))^{2} }{2} + \frac{1}{\lambda} V\left(\sqrt{ \lambda}\, \phi(x) \right).\] <p>Now, in order to get the equation of motion, we have two options: 1) Legendre-transform the equation to the Lagrangian formalism and adopt Euler-Lagrange equation, or 2) stick with the Hamiltonian formalism and adopt the Hamiltonian equations of motion (Hamilton equations) instead. Here we will take the second option.</p> <p>Recall that the Hamilton equations in classical field theory reads</p> \[\begin{align*} \frac{\delta \mathcal{H} }{\delta \phi_i} &amp;=-\dot{\pi}(x), \\ \frac{\delta \mathcal{H} }{\delta \pi_i} &amp;= \dot{\phi}_i. \end{align*}\] <p>This is a non-trivial generalization of the familiar Hamiltonian in classical mechanics, non-trivial since the connection between variational derivative and partial derivative is not as simple as one might think, we have</p> \[\frac{\delta \mathcal{H} }{\delta \phi} = \frac{\partial\mathcal{H} }{\partial \phi } - \left( \partial_ x\frac{\partial \mathcal{H} }{\partial(\partial_ {x}\phi)} \right).\] <p>Taking everything into consideration, we obtain the equation of motion by straightforward calculation. But before going there, let’s rewrite the Hamiltonian in a more compact form:</p> \[\boxed{ \lambda \, \mathcal{H} = \frac{1}{2} \tilde{\pi}^{2} + \frac{1}{2} \vec{\nabla}^{2}\,\tilde{\pi} + V(\tilde{\phi}),\quad \tilde{\pi} := \sqrt{ \lambda }\, \pi,\quad \tilde{\phi} := \sqrt{ \lambda }\,\phi. }\] <p>Then we can first obtain the EOM in terms of $\tilde{\phi}$ and $\tilde{\pi}$, the changing to un-tilded version is trivial. Finally we have</p> \[\ddot{\phi} - \vec{\nabla}^{2} \phi(x,t) + \frac{1}{\sqrt{ \lambda } } V^{(1)}(\sqrt{ \lambda }\phi) = 0\] <p>with definition</p> <p>\(V^{(n)} := \frac{ \partial^{n } V(\tilde{\phi})}{ \partial \tilde{\phi}^{n} }.\)</p> <h2 id="21-normal-modes-and-quantization">2.1. Normal modes and quantization</h2> <p>When kink solutions are placed in more than one spatial dimension, they become extended planar structures called “domain walls.”</p> <p>Now, how can we borrow the kink result form 2D directly to 3D? Consider a static kink solution in the $x$ direction</p> \[\phi(x,y) =: f(x,y)=: f_ {1}(x)\times f_ {2}(y) ,\] <p>where we have assumed the possibility of separation of variables. To say the kink is in the $x$ direction is to say the solution satisfies the equation of motion in the $x$ direction,</p> \[\frac{ \partial^{2} f(x,y) }{ \partial x^{2} } = \frac{1}{\lambda} \frac{ \partial V }{ \partial \phi } = \frac{1}{\sqrt{ \lambda } } \frac{ \partial V }{ \partial \tilde{\phi} } = \frac{1}{\sqrt{ \lambda } }V^{(1)}(\tilde{\phi}).\] <hr/> <p>First, consider the case in 2D. Writing the filed as a kink background plus fluctuation,</p> \[\phi(x,t) =: f(x) + {\mathfrak g}(x) e^{ -i\omega t }\] <p>where $f(x)$ is the 1-dimensional kink solution, the equation of motion in terms of ${\mathfrak g}$ reads</p> \[[-\omega^{2}-\partial_ {x}^{2}+V^{(2)}(\sqrt{ \lambda }f(x))]\, {\mathfrak g}(x) = 0.\] <p>As we mentioned before, there are three kinks of solutions: the zero mode, the shape mode and the continuum.</p> <hr/> <p>The equation of motion is the Sturm-Liouville equation. A general Sturm-Liouville problem is typically written in the form:</p> \[\frac{d}{dx}\left[ p(x) \frac{dy}{dx} \right] - q(x)y + \lambda r(x)y = 0\] <p>Here, $y$ is the function of the variable $x$ that we are solving for, and $p(x)$, $q(x)$, and $r(x)$ are known functions that specify the particular Sturm-Liouville problem. The parameter $\lambda$ is often referred to as the eigenvalue.</p> <p>Key characteristics and applications of the Sturm-Liouville equation include:</p> <ol> <li> <p><strong>Eigenvalue Problem</strong>: The Sturm-Liouville equation is an eigenvalue problem. The solutions $y(x)$ are eigenfunctions, and the associated values of $\lambda$ are eigenvalues. These eigenvalues are typically discrete and can be ordered as a sequence $\lambda_1, \lambda_2, \lambda_3, \ldots$, where each $\lambda_n$ corresponds to a particular eigenfunction $y_n(x)$.</p> </li> <li> <p><strong>Orthogonality and Completeness</strong>: The eigenfunctions of a Sturm-Liouville problem are orthogonal with respect to the weight function $r(x)$. This property is crucial in solving partial differential equations, as it allows the expansion of functions in terms of these eigenfunctions (similar to Fourier series).</p> </li> <li> <p><strong>Boundary Conditions</strong>: Sturm-Liouville problems are typically accompanied by boundary conditions that the solutions must satisfy. These conditions are usually specified at the endpoints of the interval in which the equation is defined.</p> </li> <li> <p><strong>Physical Applications</strong>: The Sturm-Liouville problem appears in various areas of physics, such as quantum mechanics (in solving the Schrödinger equation), heat conduction, wave propagation, and vibrations analysis. It is essential in the separation of variables technique for solving partial differential equations.</p> </li> <li> <p><strong>Self-Adjoint Form</strong>: The equation is often referred to as a self-adjoint form, which has important implications in the theory of linear operators and functional analysis.</p> </li> </ol> <p>In our case, the weight function is trivial.</p> <hr/> <p>We will denote the zero mode by ${\mathfrak g}_ {B}$ and the shape mode by ${\mathfrak g}_ {S}$. The $B$ in ${\mathfrak g}_ {B}$ has a historical reason, but in our note it is just part of the name. The normalization conditions are</p> \[\int dx \, {\mathfrak g}_ {S}^{2} = \int dx \, {\mathfrak g}_ {B}^{2} = 1 , \quad \int dx \, {\mathfrak g}_ {B}{\mathfrak g}_ {S} = 0 ,\quad \int dx \, {\mathfrak g}_ {k}(x){\mathfrak g}_ {p}(x) = 2\pi i\delta(p-k).\] <p>The sign of ${\mathfrak g}_ {B}$ is fixed using</p> \[{\mathfrak g}_ {B}(x) = - \frac{f'(x)}{\sqrt{ Q_ {0} } },\] <p>where $f$ is again the kink solution.</p> <p>We choose to expand in the $x$ direction in normal modes (in the kink background), while in the $y$ direction in plane waves. The 2D momentum $\vec{k}=\left\lbrace k_ {x},k_ {y} \right\rbrace$, where $k_ {x}=\left\lbrace B,S,k \right\rbrace$, $B$ for the zeromode (bounded solution), $S$ for the shape mode (also bounded) and $k$ for the continuum. A nice illustration of normal modes in the background of kink is shown in the figure below, which I shamelessly copied from Tanmay Vachaspati’s book, all the credits goes to Vachaspati.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kinkLevel-480.webp 480w,/img/kinkLevel-800.webp 800w,/img/kinkLevel-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kinkLevel.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> A trivial potential on a periodic space with period $L$ is shown on the left, while the normal modes in the background of a kink solution is shown on the right. What used to be the $n=0$ mode in the trivial potential (on the left) becomes the lowest bound state, the zero mode, in the non-trivial potential. Similarly a linear combination of the $n=\pm 1$ modes in the trivial case may become the second bound state ($n=+1$ in the illustration), and the other states remain unbounded but shift in form. </div> <p>We want to expand the static fluctuation field $\phi(r)$ (defined by $\phi=f_ {\text{kink} }+g$) in terms of normal modes. Since we have defined the indices $k$ in ${\mathfrak g}_ {k}(x)$ to include everything, we can conveniently write the field expansion as</p> \[\begin{align*} \phi(r) &amp;= \sum\!\!\!\!\!\!\!\!\int \frac{ d^{d}k}{(2\pi )^{d} } \, \left( B_ {k} ^{\ddagger} +\frac{B_ {-k} }{2\omega _ {k} } \right){\mathfrak g}_ {k} (r),\\ \pi(r) &amp;= \sum\!\!\!\!\!\!\!\!\int \frac{ d^{d}k}{(2\pi )^{d} } \, \left( B_ {k} ^{\ddagger} -\frac{B_ {-k} }{2} \right){\mathfrak g}_ {k} (r), \end{align*}\] <p>where $r = (x,y)$. We adopt the convention</p> \[B^{\ddagger}_ {k} = \frac{B^{\dagger}_ {k} }{2\omega _ {k} }.\] <p>This helps us to switch between different conventions for the field expansion.</p> <p>We have omitted the vector sign (or bold font) in $r$ since it would not raise any misunderstanding. We assume (quite reasonably) the separation of variables $x$ and $y$ for 2D normal modes ${\mathfrak g}(r)$,</p> \[{\mathfrak g}(r) = {\mathfrak g}_ {x}\times g_ {y},\quad {\mathfrak g}_ {x} = \text{kink normal modes},\, {\mathfrak g}_ {y} = \text{plane waves.}\] <p>The quantization in terms of $\phi$ and $\pi$ reads</p> \[[\phi(r),\pi(r')] = i\delta^{(d)}(r-r').\] <p>This represents the fundamental quantization relation, unaffected by the selection of sectors. We haven’t given a formal definition of sectors, roughly speaking, within each sector, there exists a distinct set of normal modes for expanding both $\phi$ and $\pi$. Each mode must conform to the aforementioned relation, namely the quantization relation given in space-time positions $r$. Ultimately, the difference across different sectors lies in the diverse backgrounds (regarded as classical functions) used for field expansion. However, as we are analyzing the same theory within the same space-time, the theory should be quantized only once, and, all sectors must consistently align with the same quantization process.</p> <h2 id="22-renormalization-methods-review">2.2 Renormalization methods review</h2> <p>Things does get more complicated when renormalization is included. The commonly used renormalization method include (but not limited to):</p> <ol> <li><code class="language-plaintext highlighter-rouge">Dimensional regularization</code>. This is particularly useful in 4D. This technique regularizes integrals by analytically continuing the number of dimensions of space $d$, usually reduce it by an infinitesimal quantity $\epsilon$. It preserves the gauge symmetry and Lorentz invariance.</li> <li><code class="language-plaintext highlighter-rouge">Cutoff regularization</code>. This method introduces a high-energy cutoff in the energy. By doing this we are making the momentum integrals finite by force, but as a price we would introduce a new parameter $\Lambda$ with the dimension of energy. This $\Lambda$ has profound physical consequence, such as in dimensional transmutation and, most importantly, the Wilsonian RG flow.</li> <li><code class="language-plaintext highlighter-rouge">Pauli-Villars Regularization.</code> This approach involves adding hypothetical heavy particles to the theory to cancel out the divergences. The mass of the heavy particles acts effectively as the cutoff in the integrals.</li> <li><code class="language-plaintext highlighter-rouge">Lattice reguglarization</code>. This method discretizes the spacetime into a lattice. Computations are performed on this lattice, the spacing between different sites, or the resolution of the lattice serves as a cutoff.</li> </ol> <p>There also exist tons of other renormalization methods, such as holographic renormalization, Hopf algebra renormalization, Connes-Kreimer renormalization, and so on. They sounds like fun but, unfortunately, they lie beyond the scope of our work and my comprehension.</p> <p>Different renormalization methods may yield different results depending on the specific sector they are applied to. For instance, the momentum cutoff method produces distinct outcomes when used in the trivial vacuum sector compared to the one-kink sector. From my perspective, it seems more appropriate to <em>consider the regularization method as an integral part of the quantization process</em>. Quantization itself is not a natural, free functor (just means a ); whether one opts for geometrical quantization or path integral quantization (among other methods), additional elements are always needed. For example, incorporating a momentum cutoff is often a crucial step.</p> <p>Different sectors also seem to give different perspectives regarding the relations between different regularization methods. For example, in trivial vacuum sector (which we will just call vacuum sector), the momentum cutoff method is closely connected to the lattice renormalization method, by roughly $\Lambda = 2\pi / a$ where $a$ is the lattice spacing. This very relation is harder to see in, for instance, one-kink sector (which we will just call kink sector).</p> <p>A natural question that follows is, if there exists a regularization method that applies to all the sectors (unlike the momentum cutoff renormalization) equally well? If so, which one? Apparently the space-time itself is the common ground of all sectors, since the lattice regularization is dependent on spacetime alone, it is independent of the specific mode-expansion we adopt for fields, so it seems reasonable to use it as the renormalization scheme. Other advantages of lattice renormalization includes, 1) it made obvious the Wilsonian RG flow, which is continuous change of various parameters in the theory depending on a continuous change of the lattice size. 2) The connection between the lattice quantization and momentum-cutoff renormalization is already know in the trivial vacuum sector. We just need to find a way to generalize it to other sectors.</p> <h2 id="23-lattice-quantization">2.3. Lattice quantization</h2> <p>In our work we will start with the lattice quantization. Recall that the canonical quantization relation in a continuous $d$-dimensional spacetime reads</p> \[[\phi(r),\pi(r')] = i \delta^{(d)} (r-r'), \tag{2.1}\] <p>In lattice quantization, the continuous spacetime of the theory is replaced by a discrete set of points, and the fields are defined only at these points. It is a powerful, comprehensive change of viewpoint, not only of numerical importance, but really alters our view of spacetime. In principal we can translate all concepts we have defined in spacetime continuum into the lattice spacetime, such as the gauge connection, gauge field strength, etc. Sometimes, it is convenient to think the lattices as “sample points” of a spacetime continuum. In this view, between the lattice sites there maybe exists something other than the pure void, but it is meaning less to talk about them anyway. This view is rather useful when discussing the connection between lattice quantization and momentum cutoff quantization.</p> <p>The commutation relation on a lattice should take the form</p> \[[\phi_ {i},\pi_ {j}] =i\delta_ {ij}, \tag{2.2}\] <p>where $i,j$ are the indices of different sites.</p> <p>Recall that in canonical quantization, Eq. (2.1) translate to the momentum space rather trivially, yielding</p> \[[a_ {p},a^{\dagger}_ {p'}] = (2\pi)^{d} \delta^{(d)}(p-p').\] <p>So the question is, how does the lattice commutation relation translates to different sectors? Particularly, in the trivial vacuum sector and the one-kink sector?</p> <h3 id="231-latticization-of-scalar-field">2.3.1 Latticization of scalar field</h3> <p>Write the scalar field $\phi$ in continuum as as function of spacetime position $\phi(x)$, and write the lattice position as a label of the field $\phi_ {a^{\mu} }$, where $a^{\mu}=m^{\mu} a$, $m^{\mu}\in \mathbb{N}^{d}$ is the $d$-dimensional count of the lattice site, $a$ is the lattice distance. The summation on lattices goes to integral in the continuous limit with the following dictionary,</p> \[\begin{align*} \sum_ {m^{d} } &amp;\to \int, \\ a^{d} &amp;\to d^{d}x,\\ f_ {a^{\mu} } &amp;\to f(x) \end{align*}\] <p>where $m^{d}$ indicates the $d$-dimensional lattice. Combined together we have the familiar formula</p> \[\sum_ {m^{d} } a^{d} f_ {a^{\mu} } \to \int d^{d}x \, f(x).\] <p>We can define two types of differences, corresponding to derivatives in the continuous case</p> \[\begin{align*} \partial_ {\mu} f_ {x} &amp;= \frac{1}{a} (f_ {x+\hat{a}^{\mu} }-f_ {x}),\\ \partial'_ {\mu} f_ {x} &amp;= \frac{1}{a} (f_ {x}-f_ {x-\hat{a}^{\mu} }), \end{align*}\] <p>where $\hat{a}^{\mu}$ is a vector in direction $x^{\mu}$ of length $a$, namely $\hat{a}$ moves to the next lattice site in the $x^{\mu}$ direction. These two differences are like differences “from right” and “from left”. For smooth functions of course their continuous limit all give the derivative.</p> <p>The interesting thing is that these two types of differences are kind of dual to each other. Define an inner product</p> \[(f_ {x},g_ {x}) := \sum_ {x} f_ {x} g_ {x},\] <p>similar to the case of differential forms, then</p> \[(f_ {x},\partial g_ {x}) = (-\partial' f_ {x},g_ {x}),\] <p>which corresponds to the integral by part</p> \[\int \, f\partial g = \int \,(-\partial f) g.\] <h3 id="232-second-quantization-in-the-vacuum-sector">2.3.2 Second quantization in the vacuum sector</h3> <p>First let’s review how the second quantization is achieved in the vacuum sector without latticization, namely on a continuum of spacetime of dimension $d+1$. This is what we learnt from textbooks.</p> <p>Note that we will adopt a slight change of variable here. Before we used $\vec{r}$ to denote the spatial vector where $\vec{r}=(x,y, \cdots)$ since in two dimensional space time, it is easier to write $x,y$ than $x_ {1},x_ {2}$. However, since now we are dealing with $d+1$ dimensional spacetime, we will also adopt a different convention, namely $x=(t,\vec{x})$ where $\vec{x}$ is a $d$-dimensional vector with components $x_ {1},\cdots,x_ {d}$. In summary, Latin letters without a vector sign $x$ are covariant $d+1$-vectors, the generalization of $4$-vector to arbitrary dimension.</p> <p>The simplest special relativistic equation of motion a field $\phi$ can satisfy is the massless Klein-Gordon equation,</p> \[\partial^{2}\phi=0,\quad \partial^{2}=\partial_ {\mu}\partial^{\mu}=\partial_ {t}^{2}-\nabla^{2}.\] <p>Decompose $\phi$ into a continuum of momentum mode, each mode can be written as</p> \[a_ {p} (t) e^{ i\vec{p}\cdot \vec{x} }\] <p>where we have assume the separation of variable $t$ and $\vec{x}$, and the time-dependent part of the Klein-Gordon equation gives</p> \[(\partial_ {t}^{2}+\vec{p}\cdot \vec{p})a_ {p} (t) = 0\] <p>with solutions</p> \[a_ {p} (t) =a_ {p} e^{ \pm i\omega t},\quad \omega^{2}= \vec{p}^{2}.\] <p>where $a_ {p}$ now is just some c-number, constant in time. The field can be expanded as a linear combination of all the momentum modes</p> \[\phi(t,\vec{r}) = \int \frac{d^{d}p}{(2\pi)^{d} } \, (a_ {p} e^{ -ipx }+a_ {p} ^{\ast }e^{ipx })\] <p>where the second term in the parenthesis is to make sure that $\phi$ is real. We have assembled $\omega$ and $\vec{p}$ into $p=(\omega,\vec{p})$.</p> <p>Now the second quantization kicks in. This is usually first done in the momentum space, since we are treating each mode as a harmonic oscillator. You can already see one aspect of the difference between the previously define lattice quantization and the textbook second quantization. We introduce the <code class="language-plaintext highlighter-rouge">equal-time commutation relation</code></p> \[[a_ {k} ,a_ {p}^{\dagger}] = (2\pi)^{d} \,\delta^{d}(\vec{k}-\vec{p}),\] <p>where we have omitted the vector sign in the superscript $k,p$ to avoid overly cumbersome notation. The factors of $2\pi$ are a convention, stemming from our convention for Fourier transform, for the details see my other blog on conventions.</p> <p>We want the operators $a_ {p}^{\dagger}$ to create particles with momentum $\vec{p}$. Let $\left\lvert{\vec{p} }\right\rangle$ be a physical state with a single particle with momentum $\vec{p}$, <em>define</em></p> \[a_ {p} ^{\dagger}\left\lvert{\Omega}\right\rangle = \frac{1}{\sqrt{ 2\omega _ {p} } }\left\lvert{\vec{p} }\right\rangle ,\] <p>where $\left\lvert{\Omega}\right\rangle$ is the ground state in the vacuum sector. This factor of $1 / \sqrt{ 2\omega _ {p} }$ is just another convention.</p> <p>From the normalization $\left\langle \Omega \middle\vert \Omega \right\rangle=1$ and the commutation of $a,a^{\dagger}$ we get</p> \[\left\langle \vec{p} \middle\vert \vec{k} \right\rangle =2\omega _ {p} (2\pi)^{d}\delta^{d}(\vec{p}-\vec{k}).\] <p>As a result, the identity operator for one particle states is</p> \[\mathbb{1}=\int \frac{d^{d}p}{(2\pi)^{d} } \, \frac{1}{2\omega _ {p} }\left\lvert{\vec{p} }\right\rangle \left\langle{\vec{p} }\right\rvert .\] <p>We define the quantum field as integrals over $a_ {p}$ and $a_ {p}^{\dagger}$,</p> \[\phi_ {0}(\vec{x})= \int \frac{d^{d}p}{(2\pi)^{d} } \, \frac{1}{\sqrt{ 2\omega } } (a_ {p} e^{ i\vec{p} \cdot \vec{x} } + a_ {p} ^{\dagger}e^{ -i\vec{p}\cdot \vec{x} })\] <p>where the subscript $0$ indicates this is a free field. The traditional view is to take it as the definition of the field operator $\phi_ {0}$ constructed from the creation and annihilation operators $a_ {p}$ and $a_ {p}^{\dagger}$ (<em>Schwartz M.D.</em>), but we shall try an opposite viewpoint, as will be shown later.</p> <p>Later we will work with the Schrodinger picture which is less commonly used compared to the Heisenberg or interaction pictures. To finish the review on the second quantization, we just mentioned that in Heisenberg picture, all the time dependence is in operators such as $\phi$ and $a_ {p}$, the field operator reads</p> \[\phi_ {0}(\vec{x},t) = \int \frac{d^{d}p}{(2\pi)^{d} } \, \frac{1}{\sqrt{ 2\omega _ {p} } }(a_ {p} e^{ -ipx } + a_ {p} ^{\dagger}e^{ ipx }),\] <p>which is <em>not</em> Lorentz invariant.</p> <hr/> <p>Instead of the traditional view of harmonic oscillator quantization in the momentum space, let’s take Eq.(2) as the starting point. Adopt a somewhat un-conventional field expansion</p> \[\begin{align*} \phi(\vec{x}) &amp;= \int \frac{d^{d}p}{(2\pi)^{d} } \, e^{ -i\vec{x}\cdot \vec{p} }\phi_ {p},\\ \pi(\vec{x}) &amp;= \int \frac{d^{d}p}{(2\pi)^{d} } \, e^{ -i \vec{x}\cdot \vec{p} }\pi_ {p}. \end{align*}\] <p>The next question is how to inverse it on a lattice…</p> <h3 id="24-21-dimensional">2.4 (2+1)-dimensional</h3> <p>If we adopt (1) the ultraviolet cutoff $\Lambda$ and (2) the harmonic quantization <em>in the trivial vacuum sector</em> and translate it to the physical spacetime. As a result we get a non-local commutation relation in spacetime,</p> \[[\phi(x),\pi(y)]_ {\Lambda} = i \int_{-\Lambda}^{\Lambda} \frac{dp}{2\pi} \, e^{ -ip(x-y)} = i \frac{\sin(\Lambda x)}{\pi x} .\] <p>This is non-local in the sense that for certain $x\neq y$ the commutator is nonzero. However, this commutation relation does agree with the lattice picture, if we set the lattice spacing to be $\pi / \Lambda$! (check for yourself)</p> <p>But for now let’s forget about the momentum cutoff and work with a more general picture. We can define the normal ordering in the vacuum sector, then propagate it to the kink sector via the displacement operator, which we will talk about shortly.</p> <p>Recall the equation of motion reads</p> \[\partial^{2}\phi-\frac{1}{\lambda} \frac{dV(\sqrt{ \lambda }\phi)}{d\phi}=0,\] <p>separate $\phi(\vec{x},t)$ into the kink background $f(\vec{x})$ and the fluctuation (time-dependent) ${\mathfrak g}$,</p> \[\phi(\vec{x},t) = f(\vec{x})+{\mathfrak g}(\vec{x},t),\] <p>insert it into the equation of motion and use the fact that $f(\vec{x})$ satisfies the time-independent EoM, we get the EoM for the fluctuation field:</p> \[\begin{align*} 0 &amp;= \partial^{2} (f+{\mathfrak g}) -\frac{1}{\lambda} \frac{d V(\sqrt{ \lambda }(f+{\mathfrak g}))}{d\phi} \\ &amp;= \partial^{2} f + \partial^{2}{\mathfrak g}-\frac{1}{\lambda} \frac{d}{d\phi}\left( V( \sqrt{ \lambda } f)+{\mathfrak g} \frac{dV(\sqrt{ \lambda }\phi)}{d\phi} \mid_ {\phi=f} + \mathcal{O}({\mathfrak g^{2} }) \right) \\ &amp;= \partial^{2} f - \frac{1}{\lambda} \frac{dV(\sqrt{\lambda} f)}{df} + \partial^{2}{\mathfrak g}-\frac{ {\mathfrak g} } {\lambda} \frac{d^{2}V(\sqrt{\lambda}f)}{d f^{2} } +\mathcal{O}( {\mathfrak g}^{2} ) \\ &amp;= \partial^{2} {\mathfrak g}+V^{(2)}(\sqrt{ \lambda }f) + \mathcal{O}({\mathfrak g}^{2}), \end{align*}\] <p>where</p> \[V^{(n)} := \frac{d^{n}V(\tilde{\phi})}{d\tilde{\phi}^{n} },\quad \tilde{\phi}:=\sqrt{ \lambda }\phi.\] <hr/> <p>In the below are some results needed for the derivation, not carefully organized in a readable order. I will tidy it up later.</p> <p>The commutation relation reads</p> \[[\phi(\vec{x}_ {1}),\pi(\vec{x}_ {2})] = i \delta^{d}(\vec{x}_ {1}-\vec{x}_ {2}),\] <p>together with the decomposition we have</p> \[\begin{align*} [\phi_ {p_ {1} },\pi_ {p_ {2} }] &amp;= i(2\pi)^{d}\delta^{d}(p_ {1}+p_ {2}),\\ [\phi_ {k_ {1} },\pi_ {k_ {2} }] &amp;= i(2\pi)^{d}\delta^{d}(k_ {1}+k_ {2}), \end{align*}\] <p>note the plus sign instead of minus in the parenthesis.</p> <p>The decomposition into ladder operators reads</p> \[\begin{align*} \phi_ {p} &amp;= A^{\ddagger}_ {p}+\frac{A_ {-p} }{2\omega_ {p} },\quad \pi_ {p}=i\omega_ {p}A^{\ddagger}_ {p}- \frac{iA_ {-p} }{2},\quad A^{\ddagger}_ {p} = \frac{A^{\dagger}_ {p} }{2\omega _ {p} },\\ \phi_ {k} &amp;= B^{\ddagger}_ {k}+\frac{B_ {-k} }{2\omega_ {k} },\quad \pi_ {k}=i\omega_ {k}B^{\ddagger}_ {k}- \frac{iB_ {-k} }{2},\quad B^{\ddagger}_ {k} = \frac{B^{\dagger}_ {k} }{2\omega _ {k} }. \end{align*}\] <p>The commutation relation in terms of those reads</p> \[[B_ {k_ {1} },B^{\ddagger}_ {k_ {2} }] = (2\pi)^{d}\delta^{d}(k_ {1}-k_ {2}).\] <p>Note the minus sign. It is exactly the same as what we’ve got in the trivial vacuum sector where</p> \[[A_ {p_ {1} },A^{\ddagger}_ {p_ {2} }] = (2\pi)^{d}\delta^{d}(p_ {1}-p_ {2}).\] <p>Expand $A,A^{\ddagger}$ in terms of $B^{\dagger},B$ we have</p> \[\begin{align*} A^{\ddagger}_ {p} &amp;= \sum\!\!\!\!\!\!\!\!\int \; \frac{d^{d}k}{(2\pi)^{d} } \, \frac{\tilde{ {\mathfrak g} }_ {k}(-\vec{p})}{2\omega_ {p} } \left[ (\omega_ {p} +\omega _ {k} )B_ {k} ^{\ddagger}+(\omega _ {p} -\omega _ {k} )\frac{B_ {-k} }{2\omega_ {k} } \right] ,\\ A_ {-p}&amp;= \sum\!\!\!\!\!\!\!\!\int \; \frac{d^{d}k}{(2\pi)^{d} } \, \tilde{ {\mathfrak g} }_ {k}(-\vec{p}) \left[ (\omega _ {p} -\omega _ {k} ) B_ {k} ^{\ddagger}+(\omega _ {p} +\omega _ {k} )\frac{B_ {-k} }{2\omega _ {k} } \right]. \end{align*}\] <p>The idea is to</p> <ol> <li>write terms in the Hamiltonian in normal order with respect to $A,A^{\ddagger}$,</li> <li>use the above relation to rewrite it in terms of $B,B^{\ddagger}$,</li> <li>use the commutation relation to diagonalize $H$ in terms of $B,B^{\ddagger}$.</li> </ol> <p>The normal ordered leading order Hamiltonian (in kink sector) reads</p> <p>\(H'_ {2} = A+B+C\) where</p> \[\begin{align*} A &amp;= \frac{1}{2} \int d^{d}x \, :\pi^{2}(\vec{x}):_ {a}, \\ B &amp;= \frac{1}{2} \int d^{d}x \, :(\nabla\phi(\vec{x}))^{2}:_ {a}, \\ C &amp;= \frac{1}{2} \int d^{d}x \, V^{(2)} (\sqrt{ \lambda }f) :\phi^{2}(\vec{x}):_ {a}. \end{align*}\] <p>In plane-wave space and $\vec{k}$-space we have</p> \[\begin{align*} A &amp;= \frac{1}{2} \int\frac{d^{d}p}{(2\pi)^{d}} \, :\pi_ {p}\pi_ {-p}:_ {a} , \\ B+C &amp;= \frac{1}{2} \sum\!\!\!\!\!\!\!\!\int \;\frac{d^{d}k}{(2\pi)^{d}} \, \omega^{2}_ {k} \int \frac{d^{d}p_ {1}}{(2\pi)^{d}} \int \frac{d^{d}p_ {2}}{(2\pi)^{d}} \, \tilde{ {\mathfrak g}}_ {-k}(\vec{p}_ {1}) \tilde{ {\mathfrak g}}_ {k}(\vec{p}_ {2}) :\phi_ {p_ {1}}\phi_ {p_ {2}}:_ {a}. \end{align*}\] <hr/> <p>Define the Fourier transformation $\tilde{f}$ of function $f(x)$ to be</p> \[\tilde{f}(\vec{p}) := \int d^{d}x \, f(\vec{x})e^{ -i\vec{p}\cdot \vec{x} }.\] <p>The Fourier transformation of normal modes reads</p> \[\tilde{ {\mathfrak g} }_ {k}(p) = \int d^{d} x \, {\mathfrak g}_ {k}( \vec{x} ) e^{-i\vec{p} \cdot \vec{x} }\] <p>which satisfies relation</p> \[\tilde{ {\mathfrak g} }_ {k}^{\ast}(\vec{p}) = \tilde{ {\mathfrak g} }_ {-k}(-\vec{p}) .\] <p>Sometime this relation can help to make the numerical calculation easier.</p> <p>The normalization relations for ${\mathfrak g}$ reads</p> \[\begin{align*} \int d^{d}x \, {\mathfrak g}^{\ast }_ {k}(\vec{x}){\mathfrak g}_ {k'}(\vec{x}) &amp;=(2\pi)^{d}\delta ^{d}(\vec{k}-\vec{k}'), \\ \int \frac{d^{d}p}{(2\pi)^{d} } \tilde{ {\mathfrak g} }_ {k}(\vec{p}) \tilde{ {\mathfrak g} }_ {k'}(\vec{p}) &amp;= (2\pi)^{d}\delta ^{d}(\vec{k}+\vec{k}'), \\ \int \frac{d^{d}p}{(2\pi)^{d} } \tilde{ {\mathfrak g} }_ {k}(\vec{p}) \tilde{ {\mathfrak g} }^{\ast }_ {k'}(\vec{p}) &amp;= (2\pi)^{d}\delta ^{d}(\vec{k}-\vec{k}') , \end{align*}\] <p>and the completeness condition (in both spacetime and momentum space)</p> \[\begin{align*} \int \frac{d^{d}k}{(2\pi)^{2}} \, {\mathfrak g}_ {k}(\vec{x}) {\mathfrak g}^{\ast }_ {k}(\vec{y}) &amp;=\delta ^{d}(\vec{x}-\vec{y}), \\ \sum\!\!\!\!\!\!\!\!\int \; \frac{d^{d}k}{(2\pi)^{d}} \, \tilde{ {\frak g} }_ {k}(\vec{p}_ {1}) \tilde{ {\frak g} }^{\ast} _ {k}(\vec{p}_ {2}) &amp;= (2\pi)^{d} \delta^{d}(\vec{p}_ {1} - \vec{p}_ {2}). \end{align*}\] <p>Note that in our convention of Fourier transformation, instead of $+i\vec{p}\cdot \vec{x}$ we have minus sign. This is only the spatial part of the Fourier transformation (recall that our spacetime is $d+1$ dimensional).</p> <hr/> <p>We have divided the leading order, kink-sector Hamiltonian into $A+B+C$ three parts, in normal order we have</p> \[\begin{align*} A &amp;=\frac{1}{2} \int \frac{d^{d}p}{(2\pi)^{d} } \, \left( -\omega^{2}_ {p} A^{\ddagger}_ {p} A^{\ddagger}_ {-p}+ \omega _ {p} A^{\ddagger}_ {p} A_ {p} -\frac{1}{4} A_ {-p}A_ {p} \right), \\ B+C &amp;= \frac{1}{2} \sum\!\!\!\!\!\!\!\!\int \;\frac{d^{d}k}{(2\pi)^{d} } \int \frac{d^{d}p}{(2\pi)^{d} } \frac{d^{d}p'}{(2\pi)^{d} } \,\omega_ {k}^{2}\, \tilde{ {\mathfrak g} }_ {-k}(\vec{p} )\tilde{ {\mathfrak g} }_ {k}(\vec{p}') \\ &amp;\;\;\;\; \times \left[ A^{\ddagger}_ {p }A^{\ddagger}_ {p'} + \frac{A^{\ddagger}_ {p }A_ {-p'} }{2\omega_ {p'} } + \frac{A^{\ddagger}_ {p'}A_ {-p } }{2\omega_ {p } } + \frac{A_ {-p } }{2\omega_ {p } } \frac{A_ {-p'} }{2\omega_ {p'} } \right]. \end{align*}\] <p>In the calculation just keep in mind the property of $\tilde{ {\mathfrak g}}$ and invariance under combined exchange $p \leftrightarrow p’$ with $k \to -k$.</p> <p>The following relations are useful in derivation, with terms that do not annihilate the kink ground state $\left\lvert{0}\right\rangle$:</p> \[\begin{align*} A^{\ddagger}_ {p} A^{\ddagger}_ {p'} &amp;\cong \sum\!\!\!\!\!\!\!\!\int \frac{d^{d}k}{(2\pi)^{d} } \frac{d^{d}k'}{(2\pi)^{d} } \frac{\tilde{ {\mathfrak g} }_ {k}(-\vec{p}) \tilde{ {\mathfrak g} }_ {k'}(-\vec{p}')}{2\omega_ {p} 2\omega_ {p'} } \\ &amp;\;\;\;\;\; \times \left( (\omega _ {p} +\omega _ {k} )(\omega_ {p'}+\omega_ {k'})B^{\ddagger}_ {k} B^{\ddagger}_ {k'}+ \frac{1}{2\omega _ {k} }(\omega _ {p} -\omega _ {k} )(\omega_ {p'}+\omega_ { {k'} }) B_ {-k} B^{\ddagger}_ {k'}) \right), \\ A^{\ddagger}_ {p} A_ {-p'} &amp;\cong \sum\!\!\!\!\!\!\!\!\int \frac{d^{d}k}{(2\pi)^{d} } \frac{d^{d}k'}{(2\pi)^{d} } \frac{1}{2\omega_ {p} } \tilde{ {\mathfrak g} }_ {k}(-\vec{p})\tilde{ {\mathfrak g} }_ {k'}(-\vec{p}') \\ &amp;\;\;\;\;\; \times \left( (\omega _ {p} +\omega _ {k} )(\omega_ {p'}-\omega_ {k'})B^{\ddagger}_ {k} B^{\ddagger}_ {k'}+ \frac{1}{2\omega _ {k} } (\omega _ {p} -\omega _ {k} )(\omega_ {p’}-\omega_ { {k'} }) B_ {-k}B^{\ddagger}_ {k'}) \right), \\ A_ {-p} A_ {-p'} &amp;\cong \sum\!\!\!\!\!\!\!\!\int \frac{d^{d}k}{(2\pi)^{d} }\frac{d^{d}k'}{(2\pi)^{d} } \tilde{ {\mathfrak g} }_ {k}(-\vec{p})\tilde{ {\mathfrak g} }_ {k'}(-\vec{p}')\\ &amp;\;\;\;\;\; \times \left( (\omega _ {p} -\omega _ {k} )(\omega_ {p'}-\omega_ {k'})B^{\ddagger}_ {k} B^{\ddagger}_ {k'} + \frac{1}{2\omega _ {k} }(\omega _ {p} +\omega _ {k} )(\omega_ {p'}-\omega_ { {k'} }) B_ {-k}B^{\ddagger}_ {k'}) \right). \\ \end{align*}\] <p>We just need to keeps the terms surviving acting on $\left\lvert{0}\right\rangle$, namely the terms that are proportional to $B^{\ddagger} B^{\ddagger}$ and $B B^{\ddagger}$.</p> <p>The part in $A$ and $B+C$ that are proportional to $B^{\ddagger}B^{\ddagger}$ reads</p> \[\begin{align*} A &amp;\supset \frac{1}{8} \int \frac{d^{d}p}{(2\pi)^{d} } \sum\!\!\!\!\!\!\!\!\int \frac{\;d^{d}k}{(2\pi)^{d} } \frac{d^{d}k'}{(2\pi)^{d} } \tilde{ {\mathfrak g} }_ {k}(-\vec{p})\tilde{ {\mathfrak g} }_ {k'}(\vec{p}) B_ {k}^{^{\ddagger} } B_ {k'}^{\ddagger} \\ &amp;\;\;\;\;\; \times (-4\omega _ {k} \omega_ {k'} + 2\omega _ {p} \omega _ {k} -2\omega _ {p} \omega_ {k'}) \\ &amp;= - \frac{1}{2} \sum\!\!\!\!\!\!\!\!\int \, \frac{d^{d}k}{(2\pi)^{d} } \, \omega^{2}_ {k}B^{\ddagger}_ {k} B^{\ddagger}_ {-k}, \\ B+C &amp;\supset \frac{1}{2} \sum\!\!\!\!\!\!\!\!\int \; \frac{d^{d}k}{(2\pi)^{d} } \frac{d^{d}k_ {1} }{(2\pi)^{d} } \frac{d^{d}k_ {2} }{(2\pi)^{d} } \int \frac{d^{d}p_ {1} }{(2\pi)^{d} } \frac{d^{d}p_ {2} }{(2\pi)^{d} } \\ &amp; \;\;\;\;\; \times \omega^{2}_ {k} \, \tilde{\mathfrak g}_ {k_ {1} }(-\vec{p}) \tilde{\mathfrak g}_ {k_ {2} }(-\vec{p}') \tilde{\mathfrak g}_ {-k}(\vec{p}) \tilde{\mathfrak g}_ {k}(\vec{p}') B^{\ddagger}_ {k_ {1} }B^{\ddagger}_ {k_ {2} } \\ &amp;= \frac{1}{2} \sum\!\!\!\!\!\!\!\!\int \frac{d^{d}k}{(2\pi)^{d} } \,\omega _ {k} ^{2} B^{\ddagger}_ {k}B^{\ddagger}_ {-k} . \end{align*}\] <p>Note that the last two terms in the second line cancel each other since $k,k’$ are dummy indices, we can simply exchange them. We have used the normalization condition for $\tilde{ {\mathfrak g} }$ functions. Apparently, put together, in $A+B+C$ the terms proportions to $B^{\ddagger}B^{\ddagger}$ disappear! We are left with terms proportional to $B B^{\ddagger}$ only, which can be obtained similarly. We will omit the explicit result here since it can be easily found in other papers.</p>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[1 Introduction]]></summary></entry><entry><title type="html">Note on the kink mass correction in 3D Part II</title><link href="https://baiyangzhang.github.io/blog/2024/Note-on-Kink-Mass-Correction-in-3D-Part-II/" rel="alternate" type="text/html" title="Note on the kink mass correction in 3D Part II"/><published>2024-01-25T00:00:00+00:00</published><updated>2024-01-25T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Note-on-Kink-Mass-Correction-in-3D-Part-II</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Note-on-Kink-Mass-Correction-in-3D-Part-II/"><![CDATA[<h1 id="domain-wall">Domain Wall</h1>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Domain Wall]]></summary></entry><entry><title type="html">Note on Classical Kinks</title><link href="https://baiyangzhang.github.io/blog/2024/Note-on-Classical-Kinks/" rel="alternate" type="text/html" title="Note on Classical Kinks"/><published>2024-01-24T00:00:00+00:00</published><updated>2024-01-24T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Note-on-Classical-Kinks</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Note-on-Classical-Kinks/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>The reason why kinks (and domain walls) are of interest to us is that,</p> <ol> <li>they are known to exist in many laboratory systems and may exist in other exotic settings such as the early universe,</li> <li>they provide a relatively simple setting for studying the non-linear, non-perturbative physics,</li> <li>they shed light on the dynamics of phase transition.</li> </ol> <p>Take the phi-4 model for example, the Lagrangian is (one of many different forms)</p> \[\mathcal{L} = \frac{1}{2}(\partial_ {\mu}\phi)^{2} - \frac{\lambda}{4} (\phi^{2} - \eta^{2})^{2}\] <p>Then we can write down the kink solution, so-called $\mathcal{Z}_ {2}$ kink. The nice thing about $\mathcal{Z}_ {2}$ kink is that almost everything, from the kink solution to its energy, can be written down in closed form, as we shall see in the next chapter.</p> <p>One can rescale the field $\phi$ and the coordinate $y$ such that the Lagrangian reads</p> \[\mathcal{L} = \eta^{2}\left[ \frac{1}{2} (\partial_ {\mu}\phi)^{2} - \frac{1}{4} (\phi^{2}-1)^{2}\right] .\] <p>From this form it is clear that $\eta^{2}$ does not enter the classical equation of motion. It plays the rule of $\frac{1}{\hbar}$.</p> <hr/> <p>Derrick’s theorem states that, broadly speaking, <em>in spatial dimensions greater than (or equal to) two, static, finite-energy, non-singular solutions to the equations of motion (like solitons) cannot exist for scalar field theories with purely local interactions.</em> The theorem, formulated by G.H. Derrick in 1964, implies that such field configurations would be unstable and either collapse to a singularity or disperse. However, in higher spatial space we could still have topological structure with infinite energy, one example of such constructs is <em>domain wall</em>. Domain walls are extended planar structures separating two different vacua.</p> <h1 id="the-model">The Model</h1> <h2 id="phi-fourth-kink">Phi-fourth kink</h2> <p>We will introduce the scalar field in (1+1) dimension. We regard the mass terms as a special type of self-interaction and put it in the interaction $U(\phi(x))$. The Lagrangian is</p> \[\mathcal{L} = \frac{1}{2} (\partial \phi)^{2} - U(\phi), \quad (\partial \phi)^{2} := \partial _ {\mu}\phi \partial ^{\mu}\phi.\] <p>The Euler-Lagrange equation, or the equation of motion, is</p> <p>\(\frac{\partial \mathcal{L}}{\partial \phi}= \partial_ {\mu} \frac{\partial \mathcal{L}}{\partial (\partial _ {\mu}\phi)}\) which in terms of $U(\phi)$ becomes</p> \[\partial _ {\mu}\partial ^{\mu}\phi + \frac{d U(\phi)}{d\phi} =0.\] <p>For a static solution this simplifies to</p> \[\frac{d^{2}\phi}{dx^{2}} = \frac{dU(\phi)}{d\phi}.\] <p>At a certain moment, the instantaneous energy is obtained by the Legendre transformation of the Lagrangian. Then the translational symmetry makes sure that the energy is a conserved quantity in time. Classically, given the field configuration, we just substitute it to the energy functional, then you have the total energy of the field configuration. After quantization, though, there will be infinite zero point energy. But for our concern we will just pretend it is not there and carry on to calculate the difference of energy. This is a common property to quantum field theory models, it is usually possible to calculate the <strong>difference of something</strong> rather than the things themselves, which will be divergent, as it often turn out to be.</p> <p>The vacuum manifold is the manifold given by the minimum of $U( \phi )$. If there exists non-trivial maps</p> \[\text{boundary of space} \to \text{vacuum manifold}\] <p>then we can construct soliton solutions. If there exists non-trivial maps from</p> \[\text{boundary of space-time} \to \text{vacuum manifold}\] <p>then we can construct instanton solutions.</p> <p>The energy functional can be further simplified if we introduce the so-called <code class="language-plaintext highlighter-rouge">superpotential</code> whose derivative gives the potential</p> \[U(\phi) = \frac{1}{2} \left( \frac{dW(\phi)}{d\phi} \right)^{2}.\] <p>Then the energy is given by</p> \[E[\phi] = \frac{1}{2} \int dx \, \left\{ \left( \partial _ {x}\phi \mp \frac{dW}{d\phi} \right) ^{2} \pm \boxed { 2(\partial _ {x}\phi)\left( \frac{dW}{d\phi} \right) }\right\},\] <p>the boxed term can be easily shown to be a total derivative! The integral over</p> \[\left( \frac{\partial\phi}{\partial x} \right) \frac{dW}{d\phi}= \frac{\partial W}{\partial x}\] <p>is a surface term, whose value only depends on the boundary condition of $\phi$. We have</p> \[E[\phi(x)] = \frac{1}{2} \int dx \, \left( \partial _ {x}\phi \mp \frac{dW}{d\phi} \right) ^{2} \pm W{\Large\mid}^{\phi(x=+\infty)}_ {\phi(x=-\infty)}\] <p>which is of the form $E=(\cdots)^{2}+\mathrm{eq}$, the minimum of which is given by $\text{eq}=0$.</p> <p>Recall that for the (anti-)kink solution, the boundary condition is taken such that the potential $U(x)$ takes different vacua at different space boundaries, then $W(x=\pm\infty)$ is fixed. The kink equation will just be</p> \[\boxed { \partial _ {x}\phi \mp \frac{dW}{d\phi} = 0, \quad U(\phi)=\frac{1}{2} \left( \frac{dW}{d\phi} \right)^{2}. }\] <p>where the minus sign is chosen for kinks and plus for anti-kinks. This first-order PDF is called the BPS equation, named after Bogomolny, Prasad, and Sommerfield, the corresponding minimum of energy is called the BPS energy</p> \[E_ {\text{BPS}} = W{\Large\mid}^{\phi(x=+\infty)}_ {\phi(x=-\infty)}.\] <p>Any field configuration with energy equal to BPS energy is said to <strong>saturate the BPS bound</strong>.</p> <p>In terms of the potential $U (x)$, the BPS equation becomes</p> \[\partial _ {x}\phi = \frac{dW}{d\phi} = \sqrt{ 2U(\phi) },\] <p>since the solution to it is a local minimum, the Euler-Lagrange equation is therefore automatically satisfied by solutions of the BPS equation, even though the latter is only a first order differential equation.</p> <hr/> <h2 id="kink-solution">Kink solution</h2> <p>Next we turn to a specific potential, the well-known phi-fourth model. The self-interaction is defined to be</p> \[U(\phi) = \frac{1}{4} (\phi^{2}-1 )^{2} ,\] <p>here we write the potential in a dimensionless and mathematically convenient form. The minimum of $U(\phi)$ is given by $\phi = \pm 1$. If you draw the potential, you’ll see that the potential has two symmetric minima and one maximal given by $\phi=0$.</p> <p>The topological non-trivial solution that connects one vacuum to another smoothly is the classical kink solution. Solve the BPS equation we find</p> \[\phi_ {K} = \tanh \frac{x-a}{l_ {k}},\quad l_ {k} =\sqrt{ 2 }.\] <p>The position of the kink is $a$ and $l_ {k}$ the characteristic size of it. To get a moving kink we just Lorentz boost it by velocity $v$,</p> <p>Besides the kink solution, there is another static solution given by the elliptic sine function. But first, a digression to elliptic functions.</p> <hr/> <p><strong>Jacobi elliptic functions</strong></p> <p>The circular functions arise from ratios of lengths in a circle. In a similar manner, the elliptic functions can be defined by means of ratios of lengths in an ellipse. Many of the key properties of the elliptic functions follow from simple geometric properties of the ellipse.</p> <p>The most general form of Jacobi elliptic functions take two input, the first input behaviors as variable and the second as a parameter that controls the behavior of the function. The first input, the variable, is usually written as either $u$ or $\phi$, related by</p> \[u=\int_{0}^{\phi} d\theta \, \frac{1}{\sqrt{ 1-m \sin ^{2}\theta} }.\] <p>The angle $\phi$ is called the amplitude, a rather confusing name to call an angle.</p> <p>The most general form of elliptic integral is</p> \[f(x)= \int dx \, \frac{A+B}{C+D\sqrt{ S }},\quad A,B,C,D,S\in \mathbb{R}[x], \,\text{deg}(S)=3\text{ or }4.\] <p><em>They can be considered as the generalization of the inverse of trigonometric functions.</em></p> <p>Define something called <code class="language-plaintext highlighter-rouge">modulus</code> $k$ satisfy $0&lt;k^{2}&lt;1$. This is sometimes written in terms of $m:=k^{2}$ or the <code class="language-plaintext highlighter-rouge">modulus angle</code> $k=\sin \alpha$. The <strong>incomplete</strong> <code class="language-plaintext highlighter-rouge">elliptic integral</code> <em>of the first kind</em> reads</p> \[F(\phi,k)=\int_{0}^{\sin \phi} dt \, \frac{1}{\sqrt{ (1-t^{2})(1-k^{2}t^{2}) }},\quad 1\leq k^{2}\leq 1.\] <p>If we let $t=\sin \theta$ then</p> \[F(\phi,k)=\int_{0}^{\phi} d\theta \, \frac{1}{\sqrt{ 1-k^{2}\sin ^{2} \theta }}, \quad 0\leq \phi\leq \frac{\pi}{2}\] <p>This is the <em>incomplete</em> <code class="language-plaintext highlighter-rouge">Legendre elliptic integral.</code> The complete Legendre elliptic integral is obtained by setting $\phi$ to its maximal value, i.e., $\phi=\pi / 2$ or $\sin \phi=1$.</p> <p>The incomplete elliptic integral of the <em>second kind</em> reads</p> \[E(\phi,k)=\int_{0}^{\phi} d\theta \, \sqrt{ 1-k^{2}\sin ^{2} \theta }.\] <p>or equivalently,</p> \[E(\phi,k)=\int_{0}^{\sin \phi} dt \, \sqrt{ \frac{1-k^{2}t^{2}}{1-t^{2}} } ,\quad 0\leq k^{2}\leq 1.\] <p>Similarly, the complete elliptic integral of the first kink can be obtained by setting $\phi=\pi / 2$.</p> <p>As an example of the Jacobian elliptic function $sn$ we can write</p> \[u(x=\sin \phi,k)=F(\phi,k)=\int_{0}^{x} dt \, \frac{1}{\sqrt{ (1-t^{2})(1-t^{2}k^{2}) }}\] <p>then the inverse of $u(x)$ is defined to be</p> \[x = sn (u,k)\] <p>or</p> \[u(x,k)=\int_{0}^{x} dt \, \frac{1}{\sqrt{ (1-t^{2})(1-t^{2}k^{2}) }} .\] <p>While there are 12 different types of Jacobian elliptic functions based on the number of poles and the upper limit on the elliptic integral, the three most popular are the co-polar trio of sine amplitude, $sn(u, k)$, cosine amplitude, $cn(u, k)$ and the delta amplitude elliptic function, $dn(u, k)$ satisfy</p> \[sn^{2}+cn^{2}=1,\quad k^{2}sn^{2}+dn^{2}=1.\] <p>Elliptic integral of the third kind reads</p> \[\Pi(\phi,n,k)=\int_{0}^{\sin \phi} dt \, \frac{1}{(1+nt)^{2}\sqrt{ (1-k^{2})(1-k^{2}t^{2}) }}\] <p>with the same range of $k$. Or equivalently</p> \[\Pi(\phi,n,k)=\int_{0}^{ \phi} d\theta \, \frac{1}{(1+n\sin ^{2}\theta)\sqrt{ 1-k^{2}\sin ^{2}\theta }}.\] <p>As mentioned before, the three standard forms of the Jacobi elliptic functions $sn,cn,dn$ are the sine, cosine and delta amplitude elliptic functions respectively. They are obtained by inverting the elliptic integral of the first kind</p> \[u\equiv u(\phi\mid k)\equiv u(\phi,k) \equiv F(\phi,k)=\int_{0}^{\phi} d \theta \, \frac{1}{\sqrt{ 1-k^{2}\sin ^{2} \theta }} .\] <p>The parameter before $\sin ^{2}\theta$, i.e., $k$ is called the <code class="language-plaintext highlighter-rouge">elliptic modulus</code>, and the upper bound of the integral is called the <code class="language-plaintext highlighter-rouge">Jacobi amplitude</code>, denoted $\text{amp}$. The inverse of $u(\phi)$ is</p> \[\phi = u^{-1}(\phi,k)=:\text{amp}(u,k)\] <p>and we can write the Jacobi elliptic functions in terms of $\phi$,</p> \[\begin{align} sn(u,k)&amp;=\sin \phi\equiv\sin(\text{amp}(u,k)), \\ cn(u,k)&amp;=\cos\phi=\cos(\text{amp}(u,k)), \\ dn(u,k)&amp;=\sqrt{ 1-k^{2}\sin ^{2}\phi }. \end{align}\] <p>These functions are <em>doubly periodic</em> generalizations of the trigonometric functions satisfying</p> \[\begin{align} sn(u,0)&amp;=\sin u, \\ cn(u,0)&amp;=\cos u, \\ dn(u,0)&amp;=1. \end{align}\] <p>since $u=\phi$ at $k=0$ .</p> <hr/> <p>The familiar kink solution in our notation is</p> \[\phi_ {K}(x) = \tanh\left( \frac{x-a}{l_ {K}} \right),\quad l_ {K}=\sqrt{ 2 }.\] <p>where $a$ is the center of the kink and $l_ {K}$ the characteristic size.</p> <p>It is easy using Mathematica to check that this solution satisfies both the second order equation of motion and the first order BPS equation. The anti-kink solution is just $-\phi_ {K}(x)$.</p> <p>We claim without proof that there exists another static solution to the kink equation,</p> \[\phi(t)=\phi_ {0}\, \text{sn}(bx,k),\quad k^{2}=\frac{\phi_ {0}^{2}}{2-\phi_ {0}^{2}},\quad b^{2}=1-\frac{\phi_ {0}^{2}}{2}.\] <hr/> <p>What about a moving kink then? Firstly, the center of the kink will move with velocity $v$ thus we should replace $x-a$ with $x-a-vt$ where $v$ is the kink velocity. Secondly, from special relativistic we know that a moving frame will experience space contraction, thus we should multiply $x-a-vt$ by $\gamma$ factor, which is $\gamma=\frac{1}{\sqrt{ 1-v^{2} }}$ in natural units. Then a right-moving kink can be written as</p> \[\phi_ {K,v}= \tanh\left( \frac{x-a-vt}{\sqrt{ 2(1-v^{2}) }} \right).\] <h3 id="kink-antikink-collisions">Kink-antikink collisions</h3> <p>When the kink and antikink are separated far away from each other, the interaction between them is negligible and the configuration with a kink and a antikink is simply the addition of kink and antikink solutions, up to some additive const to make sure that the field goes to the vacuum at the space boundaries. The center of the kink, for a right moving one, is $-a+vt$ where $v$ is the velocity. The kink-antikink configuration reads</p> \[\phi_ {K \overline{K}}(t,x)= \tanh\left( \frac{x-(-a+vt)}{\sqrt{ 2 }\sqrt{ 1-v^{2} }} \right) +\tanh\left( \frac{x-(a-vt)}{\sqrt{ 2 }\sqrt{ 1-v^{2} }} \right) -1,\tag{1}\] <p>Note the last term $-1$ which is there to make sure the correct boundary condition is satisfied.</p> <p>When the kink is too close to the antikink, the simple configuration Eq.(1) can no longer satisfy the equation of motion, in physical terms there will be non-linear interaction between the kink and the antikink. To find the solution to EOM we unfortunately have to rely on numerical calculation. To be specific, in numerical calculation we</p> <ol> <li>make space-time into 2-dimensional grid, the time grid is usually required to be finer than space grid to make the numerical results more reliable. Set up the initial condition, including the kink-antikink configuration and their initial speed.</li> <li>Time-evolve the initial spate using the equation of motion, make sure the position of the kink and antikink are not at the boundary of the space.</li> <li>Do some consistency checks, for example make sure that the total energy is (reasonably) conserved, or test that the numerical method we used, when applied to a kink at still, will remain a kink at still.</li> </ol> <p>Even without specific calculation we can tell that the kink and antikink can’t just pass each other and keep moving, since if we move the antikink to the left and kink to the right, the field in the between will take value</p> \[\phi(x){\Large\mid}_ {x=0} = -1-1-1=-3\] <p>where the first $-1$ comes from the antikink $\phi_ {\overline{K}}(\infty)=-1$, second from the kink and third form $-1$ in Eq.(1). However $-3$ is not a vacuum configuration! The energy will start to accumulate in between the kink and the antikink until the kinetic energy of them a re exhausted hence they have no other choice then to term back and follow the way they came. Thus they will “scatter” off each other.</p> <p>A closer study of the case reveals that kink and antikink don’t always scatter off each other. During the scatter, the energy will dissipate, so the speed after scatter will decrease, if the initial velocity is too low, below some critical velocity $v_ {\text{cr}}$, there will not be enough energy left for the kink and antikink to escape each other, after collision they will try to separate but can only separate by a finite distance, before they could fully reform into kink and antikink, the energy would be depleted and they would have no choice to return to each other and scatter again, forming an oscillation. This object is often referred to as a <code class="language-plaintext highlighter-rouge">bion</code> or sometimes <code class="language-plaintext highlighter-rouge">oscillon</code>. In this note we will adopt the term bion, referring to the bound state of kink-antikink pair. In $3+1$ dimension, bions are also called quasi-breathers.</p> <p>Note that bion is a quasi-long-lived state, which will eventually decay into trivial vacuum, but the time it takes is so long that we can safely treat it as a stable particle.</p> <p>For $v_ {\text{in}}&gt;v_ {\text{cr}}$, where $v_ {\text{in}}$ is the incoming velocity, kink and antikink always bounce and escape to infinity. Below $v_ {\text{cr}}$ things are more interesting, there exists windows where the kink-antikink pair will scatter once, deposit some energy between them, the deposited energy form a vibrational mode, the kink-antikink pair come back to each other after a little while and bounce again, this time retrieves the deposit energy, and move away from each other to the infinity. The time of bounce needed before they eventually escape each other could be two, three, etc., the corresponding incoming velocity windows are called two-bounce escape windows, three-bounce escape windows, and so on.</p> <h3 id="collective-coordinate-approximation">Collective Coordinate Approximation</h3> <p>Consider again the kink-antikink scatter. Work in the center of mass frame, the position and velocities are symmetric, we need only one parameter, namely the position of the kink as a function of time $t$, to uniquely fix the configuration. Use $a(t)$ to denote the position of the kink. Now the question is, can be write down a (low energy) effective theory in terms of $a(t)$ only? If we can, it would be the collective coordinate approximation (CCA) model.</p> <p>We can substitute the field configuration</p> \[\phi_ {K \overline{K}}=\tanh\left( \frac{x+a(t)}{\sqrt{ 2 }} \right) - \tanh\left( \frac{x-a(t)}{\sqrt{ 2 }} \right) - 1\] <p>into the phi-fourth Lagrangian for $\phi(x,t)$ and obtain an effective Lagrangian in terms of $a(t)$ then <em>integrate over the space</em>. It should adopt the form</p> \[L_ {\text{CCA}} = L_ {\text{CCA}}(a,\dot{a}) = \frac{1}{2} m_ {a}\dot{a}^{2}-V(a)\] <p>where $m_ {a}$ is the effective mass for the kink, it is <em>position-dependent</em> in general.</p> <p>At large separation, we find that the mass parameter $m(a)$ and the effective potential $V(a)$ both approach $2M_ {K}$, the mass of two isolated static kinks. To be specific, we have</p> \[m(a)=I_ {+}(a),\quad V(a) = \frac{1}{2} I_ {-}(a) +\frac{1}{4} \int_{-\infty}^{\infty} dx \, (1-\phi^{2}_ {K \overline{K}})^{2}\] <p>where</p> \[I_ {\pm }= 2M_ {K} \pm \int_{-\infty}^{\infty} dx \, \frac{1}{\cosh ^{2}((x+a) / \sqrt{ 2 })\cosh ^{2}((x-a) / \sqrt{ 2 })} ,\] <p>where the integral goes to zero exponentially as $a$ increases.</p> <p>The effective potential can more or less account for the free bounce and formation of a bion, but can not explain the escape window, or the relativistic effects that might happen when the speed of kinks are high.</p> <h3 id="gluing-static-solutions">Gluing static solutions</h3> <p>Another way to construct the bion configuration is by gluing together three piece, 1) the left half of the kink solution, 2) half a elliptic sine function and 3) the right half of the antikink. Then the numerical methods can be used to evolve the state. However, to start the numerical evolvement, we also need to know the field configuration at the next-to-start time-slice, we can fix it by hand, by shrink the elliptic sine function a little bit, let $\phi_ {0}$ decrease a little bit.</p> <h3 id="kink-impurity-interactions">Kink-impurity interactions</h3> <p>Roughly speaking we have two ways to study the evolution of kinks-antikink states,</p> <ol> <li>Take the superposition of two static solutions, i.e. the kink solution and the antikink solution. It is not strictly speaking the solution of the equation of motion, thus the equation of motion will evolve it in a non-trivial way.</li> <li>Instead, we can start with some exact solution of the equation of motion, but then use a slightly different equation of motion to evolve it. This is the situation encountered in the description of kink interacting with impurities.</li> </ol> <p>The impurities could appear for a couple of reasons. For example, the phi fourth theory is usually the low energy effective theory of some other theory defined at UV, and this “UV completion” of our phi fourth theory might have some impurities, or defects, which can then get passed on to the phi-fourth theory. This impurity could be some defect embedded in the crystal structure, for example. To describe such process, we can modify the phi-fourth potential by</p> \[\frac{1}{4}(\phi^{2}-1)^{2}\to \frac{1}{4} (\phi^{2}-1)^{2}(1-\epsilon \delta(x-x_ {0})).\] <p>When $\epsilon&gt;0$ the defect acts like a potential barrier, if $\epsilon&lt;0$ a well.</p> <p>With this modified potential we can then talk about its equation of motion. In numerical calculation we can approximate the delta function either by a Kronecker delta function, or a Gaussian shape high and narrow.</p> <p>To be more specific, consider a static kink solution starting from $a=6$, moving towards am impurity located at $x_ {0}=0$, with fixed impurity strength $\left\lvert \epsilon \right\rvert=0.5$. The figure below shows the phase diagram.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/phase-480.webp 480w,/img/phase-800.webp 800w,/img/phase-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/phase.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The right panel shows a attractive impurity. If the incoming velocity of the kink is large enough, it will just pass through the impurity and deposit some vibrational energy at the impurity, as shown by the read line. If the velocity is too low then it will be trapped by the attractive impurity, starts to oscillate about the impurity, shown by the blue line. If the velocity is in the resonance window, the kink will bounce back resonantly, shown by the green line. </div> <p>On the left panel a repulsive impurity $\epsilon=-0.5$ is shown, for low velocity the kink will bounce back, as shown by the blue line; for high velocity the kink can overcome the impurity barrier and keep propagating, as shown by the red line.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="QuantumFieldTheory"/><category term="Kink"/><category term="Meson"/><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Representables in Category Theory</title><link href="https://baiyangzhang.github.io/blog/2024/Representables-in-Category-Theory/" rel="alternate" type="text/html" title="Representables in Category Theory"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Representables-in-Category-Theory</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Representables-in-Category-Theory/"><![CDATA[<h3 id="representables">Representables</h3> <p>A category is a world of objects, all looking at one another. Each sees the world from a different viewpoint. Take the category of topological spaces for example, consider the object with only one point, denoted $\star$, given another topological space $T$, a map \(\star\to T\) can be regarded as $\star$ looking at $T$. What does $\star$ see? Since $\star$ itself is a point, the image given by a continuous map (by definitions the morphisms in the category of topological spaces are continuous maps) of $\star$ is another point in $T$, that’s to say, a point can only see points! It can’t see any other structures, limited by what it is. This is similar to what happens in a society with real people in it. A curve, on the other hand, could see much more. It can see a point if it wants, but it can also see another curve in other objects. In the language of category theory, all the things an object could see translates into <em>the set of arrow going out from it</em>.</p> <p>We can also ask the dual question: <em>fixing an object of a category, what are maps into it</em>? Take the category $\text{Set}$ of sets for example. Consider a set with only two elements. Given any set $X$, the maps from $X$ to the two element set is the subset of $X$!</p> <p>In the following we will talk about how each object sees and is seen by the category. This naturally leads to the notion of <code class="language-plaintext highlighter-rouge">representable functors</code>, or just <code class="language-plaintext highlighter-rouge">representables</code>.</p> <hr/> <p>Fix an object $A \in \mathcal{A}$. Consider the <em>totality</em> of maps <em>out of</em> $A$. To each $B\in \mathcal{A}$, there is assigned the set $\mathcal{A}(A,B)$ of maps from $A$ to $B$. This assignation is actually <strong>functorial</strong>, in the sense that to <em>each</em> $B\in\mathcal{A}$, there is a set $A(A,B)$, and to each arrow in $A$, there is another arrow in the codomain of this functorial, which we will define shortly.</p> <p><strong>Definition 1.</strong> Let $\mathcal{A}$ be a locally small (meaning that the arrows from one object to another actually form a set) category and $A\in \mathcal{A}$. Define a functor</p> \[H^{A}: B \mapsto \mathcal{A}(A,B)\] <p>where $\mathcal{A}(A,B)$ are the collection of arrows from $A$ to $B$, here $\mathcal{A}(A,B)$ is regarded as a set. Thus</p> \[H^{A}: \mathcal{A}\to \text{Set}\] <p>where $\text{Set}$ is the category of sets, of which the objects are all kinds of sets and the arrows are function from one set to another. Let $B\in \mathcal{A}$ be an object in $\mathcal{A}$. Obviously $H^{A}$ is a <em>set-valued functor</em> defined on $\mathcal{A}$. For $A’ \in \mathcal{A}$,</p> \[H^{A}(A') := \mathcal{A}(A \to A') \text{ regarded as a set}.\] <p>An easy way to remember the direction of arrow (at least for me) is to think of $A$ in $H^{A}$ standing up high, since it is a superscript, it is standing “upstairs”, as a result $A$ has a pretty good view, allowing it to “see” other objects (say, $B$) in $\mathcal{A}$, and the arrow $A \to B$ represents that $A$ is watching $B$. With this analogy, in novel <em>1984</em> by Orwell, the big brother is watching everyone in the nation, making him the <em>initial object.</em> Similarly, given $A \in \mathcal{A}$, when we need to talk about arrow coming from other objects <em>into</em> $A$ later, we will define the functor $H_ {A}$ where $H_ {A}(B)$ is the set of arrows from $B$ to $A$ this time, for $A$ sits at the bottom and everyone can see $A$.</p> <p>For a map $g: A’ \to A’’$ in $\mathcal{A}$, $H^{A}$ maps $g$ to another map from $H^{A}(A’)$ to $H^{A}(A’’)$ by composition, that is</p> \[H^{A}(A'): A \to A', \quad H^{A}(A'') : A\to A'', \quad H^{A}(g): (A\to A') \to (A\to A'')\] <p>where $H^{A}(g)$ is realized by</p> \[A\to A' \xrightarrow{g} A''\] <p>which is a map from $A$ to $A’’$, hence an element of $H^{A}(A’’)$.</p> <p>To explain it in a different way, consider object $X\in H^{A}(A’)$, $X$ by construction is a map from $A$ to $A’$. Let $Y \in H^{A}(A’’)$, then $Y$ is nothing but a map from $A$ to $A’’$. Now, what is an arrow from $X$ to $Y$? It is something that maps $A\to A’$ to $A \to A’’$, which can be achieved by the composition $g\,\circ\,X$, where $g: A’ \to A’’$.</p> <p>Sometimes $H^{A}(g)$ is written as $g\,\circ\,-$, where $-$ is a commonly used symbol as a place holder; or written as $g_ {\ast}$, reminding us that it is somehow “induced” by $g$. All are frequently used in publications.</p> <hr/> <p>Again, let $A$ be a locally small (the collection of morphisms between any two objects is a set) category. A functor</p> \[X: \mathcal{A} \to \text{Set}\] <p>is <code class="language-plaintext highlighter-rouge">representable</code> if</p> \[X \cong H^{A} \text{ for some } A \in \mathcal{A}.\] <p>$A$ is said to be a <code class="language-plaintext highlighter-rouge">representation</code> of $X$, together with an isomorphism between $H^{A}$ and $X$. In other words, when dealing with a representable functor $X$, identifying a representation for $X$ requires more than just specifying an object $A$; we must also precisely determine how $X$ is isomorphic to $H^A$.</p> <p>Representable functors are sometimes just called <code class="language-plaintext highlighter-rouge">representables</code>. Only set-valued functors (functors with codomain $\text{Set}$) can be representable.</p> <p>Representable functors are important for a few reason in category theory. The Yoneda Lemma, which is the topic of this note, is a fundamental result in category theory that involves representable functors. We will introduce the Yoneda lemma shortly, but shortly put it, it states that <em>every functor</em> is <em>naturally isomorphic</em> to a functor represented by some object in the category. This lemma provides a powerful tool for embedding any locally small category into a category of functors (where the arrows are natural transformations). The Yoneda embedding, which arises from this, embeds a category into a category of presheaves, preserving and reflecting properties of objects and morphisms. If you don’t know (or not interested in) what a presheave is, just ignore it.</p> <p>Representable functors are key in the study of natural transformations. The <code class="language-plaintext highlighter-rouge">naturality condition</code> in the definition of natural transformations can be better understood and characterized using representables. Representables also play a role in the study of adjoints and limits, which are some key-important concepts in category theory. For instance, adjoint functors can often be characterized using representables, and the existence of certain limits and colimits (limits where all the arrows are reversed) can be analyzed through representable functors. Representable functors are also indispensable to sheaf theory and topos theory, providing a link between geometric intuition and abstract category-theoretic formalism. Unfortunately these fascinating results lie outside the scope of this simple note, or for that matter lie outside of my comprehension.</p> <hr/> <p>Since we are already talking about the category of functors, it is perhaps timely to mention two similar but distinct definitions in category theory, namely the category of functors and the so-called $2$-category.</p> <ul> <li> <p><strong>Category of Functors</strong>: This is a construction where the objects are functors and the morphisms between these objects are natural transformations. Specifically, given two categories $\mathcal{C}$ and $\mathcal{D}$, the category of functors, often denoted $\text{Fun}(\mathcal{C}, \mathcal{D})$, has as objects all functors from $\mathcal{C}$ to $\mathcal{D}$ and as morphisms the natural transformations between these functors.</p> </li> <li> <p><strong>$2$-Category</strong>: A $2$-category is a more general and abstract concept. In a $2$-category, there are objects, morphisms between objects (also called <code class="language-plaintext highlighter-rouge">1-morphisms</code>), and morphisms between morphisms (called <code class="language-plaintext highlighter-rouge">2-morphisms</code>), or “arrows between arrows”. This structure introduces a new level of morphisms.</p> </li> </ul> <p>In a certain sense, the category of functors between two categories can be seen as a specific example of a 2-category, where the objects are the categories, the 1-morphisms are the functors between these categories, and the 2-morphisms are the natural transformations between these functors. However, the concept of a 2-category is broader and can be applied to many other contexts beyond just categories and functors.</p> <hr/> <p><strong>Ex.1</strong> Consider the category of sets, denoted $\text{Set}$, let $1$ be the set of only one element. Now, what would $H^{1}$ be? It can be written as</p> \[\text{Mor}(1,-) \text{ or } \text{Hom}(1,-) \text{ or } \text{Set}(1,-),\] <p>they all mean the same thing: the maps from $1$ to something else. Let $S \in Set$, $H^{1}(S)$ would be the collection of the maps from $1$ to $S$, which is itself another set, hence</p> \[H^{1}: \text{Set} \to \text{Set}.\] <p>Since a map from $1$ to a set $S$ amounts to an element of $S$, we have</p> \[H^{1}(S) \cong S \quad \;\forall\; S \in \text{Set}.\] <p>It can be shown (which I will not do here) that this isomorphism is <em>natural</em> in $S$, so $H^{1}$ is naturally isomorphic to the identity functor $\mathbb{1}_ {\text{Set}}$. Hence $\mathbb{1}_ {\text{Set}}$ is representable, by $1$.</p> <hr/> <p>Representability is not a property shared by just any set-valued functor. In fact, rather few functors are representable, consider the total amount of functors we could construct. However, forgetful functors <em>tend to be</em> representable. We state without proof the following proposition.</p> <p><strong>Proposition.</strong> Any set-valued functor with a left adjoint is representable.</p> <hr/> <p>We have defined, for each object $A$ of category $\mathcal{A}$ , a functor $H^{A}\in[\mathcal{A},\text{Set}]$ (given two categories $\mathcal{A}$ and $\mathcal{B}$, $[\mathcal{A},\mathcal{B}]$ is the functor category from the former to the latter). This describes how $A$ sees the world. As $A$ varies, so does the view. On the other hand, it is always the same world being seen, so the different views from different objects are somehow related. Generally speaking, whenever there is a map between objects $A$ and $A’$, there is also a map between $H^{A}$ and $H^{A’}$. Since $H^{A}$ are $H^{A’}$ are both functors (the “view” of $A,A’$), a map between them are potentially natural transformation, potentially since we need to show that this map satisfies the rule of naturality.</p> <p>Precisely, a map</p> \[f: A' \to A,\quad A,A'\in \mathcal{A}\] <p>induces a natural transformation</p> \[H^{f} : H^{A} \to H^{A'}.\] <p>An interactive diagram of this can be found <a href="https://q.uiver.app/#q=WzAsMixbMCwwLCJcXG1hdGhjYWx7QX0iXSxbMywwLCJcXHRleHR7U2V0fSJdLFswLDEsIkheQSIsMCx7ImN1cnZlIjotNH1dLFswLDEsIkhee0EnfSIsMix7ImN1cnZlIjo0fV0sWzIsMywiSF5mIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dXQ==">here</a>.</p> <p>Recall that a natural transformation $\alpha$ between two functors $F$ and $G$, both from category $\mathcal{C}$ to category $\mathcal{D}$, is made up of components. Each component is a morphism in category $\mathcal{D}$.</p> <p>For each object $X$ in category $\mathcal{C}$, the <code class="language-plaintext highlighter-rouge">component</code> of the natural transformation $\alpha$ at $X$ is a morphism in category $\mathcal{D}$:</p> \[\alpha_ X : F(X) \rightarrow G(X)\] <p>These components must satisfy a naturality condition, which states that for every morphism $f: X \rightarrow Y$ in category $\mathcal{C}$, the naturality diagram commutes. The naturality condition must hold for all objects and morphisms in category $C$, making the transformation “natural” in the sense that it works consistently across the entire category.</p> <p>Coming back to $H^{f}$. Let $B\in \mathcal{A}$, what would the component $H^{f}_ {B}$ be? Recall that $f$ maps from $A’$ to $A$, by construction $H^{f}$ maps in the opposite direction, it is the function</p> \[H^{A}(B) \equiv \mathcal{A}(A,B) \to H^{A'}(B)\equiv \mathcal{A}(A',B),\] <p>in terms of the elements, let $p \in \mathcal{A}(A,B)$ we have</p> \[H^{f}: p \mapsto p\,\circ\,f.\] <p>Notice that, each $H^{A}$ is <em>covariant</em> (meaning they preserve the direction of the arrows), however they come together to form a <em>contravariant</em> thing! What exactly is this thing then? To understand it, the following definition is important:</p> <p>Let $\mathcal{A}$ be a locally small category, the functor</p> \[H^{-}: \mathcal{A}^{\text{op}} \to [\mathcal{A},\text{Set}]\] <p>is defined on objects $A$ by $H^{-}(A)=H^{A}$, and on maps $f$ by $H^{-}(f)=H^{f}$.</p> <p>A lot of explain regarding the notations is in order. Apparently the dash $-$ in $H^{-}$ is a placeholder, to be filled by whatever it acts on, no matter if it is an object or an arrow. $\mathcal{A}^{\text{op}}$ is the opposite, or dual category of $\mathcal{A}$, with same objects but reversed arrows (all of them). $\mathcal{A}^{\text{op}}$ is a category, $[\mathcal{A},\text{Set}]$ is another category ( of functors from $\mathcal{A}$ to $\text{Set}$), thus $H^{-}$ is a functor. $H^{-}$ of $A$ is $H^{A}$, which is a set-valued functor on $\mathcal{A}$, hence $H^{A}$ is an object of $[\mathcal{A},\text{Set}]$.</p> <p>All of the definitions presented so far in this chapter can be dualized. At the formal level, this is trivial: just reverse all the arrows! But in our analogy, after dualize it, we are no longer asking what objects see, but <em>how they are seen</em>:</p> <p>Let $\mathcal{A}$ be a <em>locally small</em> category and $A\in \mathcal{A}$. We define a functor $H_ {A}$ as follows,</p> \[H_ {A} := \mathcal{A}(-,A): \mathcal{A}^{\text{op}}\to\text{Set}\] <p>where</p> <ul> <li>for objects $B \in \mathcal{A}$, put $H_ {A}(B) = \mathcal{A}(B,A)$;</li> <li>For maps $g:B’\to B$, define</li> <li> \[H_ {A}(g) = \mathcal{A}(g,A) = g^{\ast } = - \,\circ\,g: \mathcal{A}(B,A)\to\mathcal{A}(b',A)\] </li> </ul> <p>by</p> \[p\mapsto p\,\circ\,g \quad \;\forall\; p: B\to A.\] <hr/> <p>Note that a map $B’\to B$ induces a map in the opposite direction, $H_ {A}(B)\to H_ {A}(B’)$.</p> <p>We now define representability for <em>contravariant set-valued</em> functors.</p> <p>Let $\mathcal{A}$ be a locally small category, and $X$ be a set-valued contravariant functor,</p> \[X: \mathcal{A}^{\text{op}} \to \text{Set}.\] <p>We say $X$ is <strong>representable</strong> is $X \cong H_ {A}$ for some $A\in \mathcal{A}$. A <code class="language-plaintext highlighter-rouge">representation</code> of $X$ is a choice of $A$ and an isomorphism between $X$ and $H_ {A}$.</p> <p>As an example, take the power set (contravariant-)functor $\mathcal{P}$ for example. Recall that the power set $\mathcal{P}(S)$ of a set $S$ is the collection of subsets of $S$. Let $S,S’\in \text{Set}$ be two sets, and $f: S \to S’$ a map (morphism) in the category of sets. Since we are regarding $\mathcal{P}$ as a contravariant functor, we should define $\mathcal{P}(f)$, which is a map from $\mathcal{P}(S’)$ to $\mathcal{P}(S)$, notice the inversed direction. Well, turns out this can be done in a more or less direct way: we define $\mathcal{P}(f)$ to be in a sense the <em>inverse</em> of $f$! Take $U\in\mathcal{P}(S’)$, we define the action on $U$ by $\mathcal{P}(f)$ by $f^{-1}(U)$, where $f^{-1}$ is <strong>not</strong> the inverse of $f$, for we didn’t assume that $f$ is invertible at all, but rather the preimage of $f$,</p> \[f^{-1} (U) := \left\lbrace s\in S \,\middle\vert\, f(s)\in U \right\rbrace .\] <p>On the other hand, the subsets of $S$ can be regarded as a maps from $S$ to $2$, the set with two elements, which we call <code class="language-plaintext highlighter-rouge">true</code> and <code class="language-plaintext highlighter-rouge">false</code>. To see how it works, take $S=\left\lbrace 1,2 ,3\right\rbrace$, the subset $\left\lbrace 1,2 \right\rbrace$ can be regarded as a map $g: S\to \left\lbrace \text{true,false} \right\rbrace$ where $1,2$ are map to true and $3$ is mapped to false. Such maps are sometimes called the characteristic functions. This provides as another way to look at power sets, and confirms the idea that in category theory everything is a morphism!</p> <p>Note that $\chi:=\left\lbrace \text{true,false} \right\rbrace$ is itself an object in $\text{Set}$, so we can talk about the Hom-functor $H_ {\chi}$, defined by maps from other stuff into $\chi$. Maybe not too surprisingly, $H_ {\chi}$ is isomorphic to the power functor $\mathcal{P}$,</p> \[\mathcal{P} \cong H_ {\chi}.\] <p>Try to convince yourself with it, better with some simple examples. Thus we say the power functor $\mathcal{P}$ is representable, and the representation is $\chi$.</p> <hr/> <p>Just as we assembled the covariant representables $H^{A}$s into a big functor $H^{-}$, we can do the same for the contravariant representables. If $f: A \to A’$ is a map in $\mathcal{A}$, there is an induced natural transformation $H_ {f}$:</p> \[H_ {f}: H_ {A} \to H_ {A'},\quad H_ {A,A'}: \mathcal{A}\to\text{Set}.\] <hr/> <p>Let $\mathcal{A}$ be a locally small category. The <code class="language-plaintext highlighter-rouge">Yoneda embedding</code> of $\mathcal{A}$ is the functor</p> \[H_ {-}: \mathcal{A} \to [A^{\text{op}},\text{Set}]\] <p>defined on objects $A \in \mathcal{A}$ as $H_ {-}(A)=H_ {A}$ and arrows $H_ {-}(f)=H_ {f}$.</p> <p>Note that in $[\mathcal{A}^{\text{op}},\text{Set}]$, the objects are functors from $\mathcal{A}^{\text{op}}$ to $\text{Set}$ and the arrows are natural transformations.</p> <p>For each object $A\in\mathcal{A}$, the Yoneda embedding assigns a functor $H_ {A}$, it is sometimes called the Yoneda functor. In a sense, the Yoneda embedding allows as to regard each $A$ as arrows. Or, more precisely, it allows us to represent each $A$ as a set-valued functor. Yoneda embedding is a one-to-one correspondence between objects in $\mathcal{A}$ and functors in $[\mathcal{A},\text{Set}]$. In a sense to be explained, $H_ {-}$ embeds $\mathcal{A}$ into $[\mathcal{A},\text{Set}]$.</p> <hr/> <p>Let $\mathcal{A}$ be a locally small category, the functor \(\text{Hom}_ {\mathcal{A}}: \mathcal{A}^{\text{op}}\times \mathcal{A}\to\text{Set}\) is defined by the following diagram, <img src="/img/hom.png" alt="hom"/></p> <p>This is like a generalization of $\text{Hom}(A,B)$ that we have encountered before. Recall that $\text{Hom}(A,B)$ is the set of the morphisms from $A$ to $B$, now $\text{Hom}_ {\mathcal{A}}$ is generalized such that it can also take two maps $f,g$ as well.</p> <hr/> <p>Given an arbitrary object in an arbitrary category, it is in general meaningless to talk about the “element” of this object since it not necessarily a set. However, in the category of sets, an element is the same thing as a map $1\to A$. This inspires the following definition.</p> <p>Let $A$ be a locally small category. A <code class="language-plaintext highlighter-rouge">Generalized element</code> of $A$ is a map with codomain $A$. A map $S\to A$ is a generalized element of $A$ of shape $S$.</p> <p>For example, a generalized element of a set $S$ of shape $\mathbb{N}$ is nothing but a sequence in $S$. In the category of topological spaces, the generalized elements of shape $1$ (the one point space) are points, and the generalized elements of shape $\mathbb{S}^{1}$ are loops.</p>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Representables]]></summary></entry><entry><title type="html">The Best Way to Write Math Notes</title><link href="https://baiyangzhang.github.io/blog/2023/The-Best-Way-to-Write-Math-Notes/" rel="alternate" type="text/html" title="The Best Way to Write Math Notes"/><published>2023-12-30T00:00:00+00:00</published><updated>2023-12-30T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/The-Best-Way-to-Write-Math-Notes</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/The-Best-Way-to-Write-Math-Notes/"><![CDATA[<h3 id="latex">Latex</h3> <p>Needless to say that LaTeX is the best language so far to write mathematical formula. A user-friendly introduction can be found online called <a href="https://www.dickimaw-books.com/latex/novices/">LaTeX for Complete Novices</a>, which can be read for free. After having gained a pretty good general idea of how to use Latex, other online resource might come in handy in everyday life working with LaTeX, I used to use the famous <em>Latex Companion</em> as a dictionary, but nowadays I found GPT4 to be most helpful.</p> <p>Also I like to edit Latex file on some local editor, such as WinEDT. The best online editor is <a href="https://www.overleaf.com/project">Overleaf</a>.</p> <h3 id="obsidian--markdown">Obsidian + Markdown</h3> <p>Obsidian can be installed online. Make sure you have installed the <strong>Latexsuit</strong> plugin. There you can define your own snippet.</p>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Latex]]></summary></entry><entry><title type="html">Renormalization method in PDF</title><link href="https://baiyangzhang.github.io/blog/2023/Renormalization-method-in-PDF/" rel="alternate" type="text/html" title="Renormalization method in PDF"/><published>2023-12-26T00:00:00+00:00</published><updated>2023-12-26T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Renormalization-method-in-PDF</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Renormalization-method-in-PDF/"><![CDATA[<h3 id="abstract">Abstract</h3> <p>The application of renormalization group method in solving the differential equation in the momentum space, and the error estimation of the solution with finite sized lattice size.</p> <h3 id="introduction">Introduction</h3> <p>The question we want to answer here is very simple: If we solve the PDF in the momentum space with a given cutoff $\Lambda$, how does the solution change with respect to $\Lambda$?</p> <h3 id="first-order-homogeneous-linear-differential-equation">First Order Homogeneous Linear Differential Equation</h3> <p>We want a well behaved function $\mathbb{R} \to \mathbb{R}$ so we begin with Gaussian function $g(t) = e^{-\lambda t^2}$. The equation it solves is</p> \[\dot{g}(t) + 2 \lambda t g(t) = 0, \tag{1}\] <p>which is a homogeneous first order ODE.</p> <p>Imagine that the function is defined on a grid with lattice spacing $a$, then the equation takes the discrete form</p> \[\frac{g(t_ {i+1})-g(t_ i)}{a} + 2 \lambda t g(t_ i) = 0,\quad \forall i \in \text{ lattice},\] <p>the solution will naturally depend on the lattice size, in the $a\to 0$ limit we will recover the continuous solution. We want to know what explicitly the dependence on $a$ looks like, and how to perform the error estimate with small but finite $a$.</p> <p>As the first attempt, in our simplified example, we go to the frequency space by substitute</p> \[g(t) = \frac{1}{\sqrt{2\pi}}\int_ {-\infty}^{\infty} d\omega \tilde{g}(\omega) e^{-i\omega t}.\] <p>The Fourier transformed equation reads</p> \[\int_ {-\infty}^{\infty} \frac{d\omega}{\sqrt{2\pi}} e^{-i\omega t} \left\{ -i \omega \tilde{g}(\omega) - 2i\lambda \frac{d}{d\omega} \tilde{g}(\omega) \right\}.\] <p>A lower bound in the lattice size $a$ corresponds to an upper bound $\Lambda$ in the momentum (exchangeable with frequency in our discussion) space, $a \sim 1/\Lambda$, thus we have</p> \[\begin{align} &amp;\int_ {-\Lambda}^{\Lambda} \frac{d\omega}{\sqrt{2\pi}} e^{-i\omega t} \left\{ -i \omega \tilde{g}(\omega) - 2i\lambda \frac{d}{d\omega} \tilde{g}(\omega) \right\} = 0, \\ \implies &amp; \omega \tilde{g}(\omega) + 2\lambda \frac{d}{d\omega} \tilde{g}(\omega) = 0\, \forall \, |\omega| &lt; \Lambda, \quad 0 \text{ otherwise} \end{align}\] <p>The equation for $\tilde{g}(\omega)$ takes the same form (up to some multiplicative constants) as that for $g(t)$, reflecting the fact that the Fourier transformed Gaussian function takes the same form as the original function.</p> <p>Here comes the key point: what happens if we decrease the momentum cutoff by infinitesimal, $\Lambda \to b\Lambda$, $b = 1-\epsilon$. With new cutoff $b\Lambda$ the equation above still holds trivially, since different modes are entirely independent of each other, we get</p> \[\omega \tilde{g}(\omega) + 2\lambda \frac{d}{d\omega} \tilde{g}(\omega) = 0\, \forall \, |\omega| &lt; (1-\epsilon)\Lambda, \quad 0 \text{ otherwise}.\] <p>In other words, for the modes that survive the renormalization flow, we have the trivial RG equation</p> \[\frac{d}{d\Lambda}\tilde{g}(\omega) = 0, \quad |\omega| &lt; b\Lambda.\] <p>Switch back to the physics space from frequency space, the error estimate is most easily done by subtracting $g^{(\Lambda)}(t)$ from $g^{(\infty)}(t)$, where</p> \[g^{(\Lambda)}(t) \equiv \frac{1}{\sqrt{2\pi}}\int_ {-\Lambda}^{\Lambda} d\omega \tilde{g}(\omega) e^{-i\omega t}\] <p>where the Fourier transform of Gaussian function is</p> \[\mathcal{F}\left\{e^{-\lambda x^2}\right\}(\omega) = \frac{1}{\sqrt{2 \lambda }}e^{-\frac{\omega ^2}{4 \lambda }}\] <p>Define</p> \[\boxed{\Delta g^{(\infty - \Lambda)}(t) \equiv g^{(\infty)}(t) - g^{(\Lambda)}(t)},\] <p>we have</p> \[\begin{align} \notag \Delta g(t) &amp;= \left( \int_ {-\infty}^{-\Lambda} + \int_ {\Lambda}^\infty \right) \left( \frac{d\omega}{\sqrt{2\pi}} \frac{1}{\sqrt{2\lambda}} e^{-\omega^2/4\lambda} e^{-i\omega t} \right) \\\notag &amp;=\frac{1}{\sqrt{\pi\lambda}} \int_ {\Lambda}^\infty d\omega e^{-\omega^2/4\lambda} \cos{\omega t} \\\notag &amp;= \frac{i}{2} e^{-\lambda t^2} \left(-2 i +\text{erfi}\left(\frac{-2 \lambda t+i \Lambda }{2 \sqrt{\lambda }}\right)+\text{erfi}\left(\frac{2 \lambda t+i \Lambda }{2 \sqrt{\lambda }}\right)\right)\\ &amp;= e^{-\lambda t^2} - e^{-\lambda t^2}\text{Re}\,\text{erf}\left( \frac{\Lambda + 2i\lambda t}{2\sqrt{\lambda}} \right) \end{align}\] <p>where we have simplified notations, Re erf is the real part of the error function, and $\text{erfi}(z)$ is the so-called imaginary error function defined by $\text{erfi}(z) = -i \,\text{erf}(iz)$. For more properties of error function, see App.~\ref{sec:error}.</p> <table> <tbody> <tr> <td>Well, the last expression is not super helpful, we can do better by looking at $</td> <td>\Delta g^2</td> <td>$ as an estimate of the overall error. Square the second line in the previous equation we get</td> </tr> </tbody> </table> \[\begin{align} \notag \Delta g(t)^2 &amp;=\frac{1}{4\pi\lambda} \int_ {|\omega_ 1|&gt;\Lambda} d\omega_ 1 \int_ {|\omega_ 2|&gt;\Lambda} d\omega_ 2 \, e^{-\omega_ 1^2/4\lambda - \omega_ 1^2/4\lambda} \cos(\omega_ 1 t) \cos(\omega_ 2 t) \\\notag &amp;=\frac{1}{4\pi\lambda} \int_ {|\omega_ {1,2}|&gt;\Lambda} d^2\omega e^{-\omega^2/4\lambda} \cos(\omega_ 1 t) \cos(\omega_ 2 t) \\ &amp; &lt; \frac{1}{4\pi\lambda} \int_ {|\omega_ {1,2}|&gt;\Lambda} d^2\omega e^{-\omega^2/4\lambda} \end{align}\] <p>where $\omega^2 = \omega_ 1^2 + \omega_ 2^2$. The integral region is shown in the Figure below, the four corners where $\omega_ {1,2}&gt;\Lambda$ corresponds to the integral region. We can extend the region first to $(\mathbb{R}^2 - \text{square})$, then to $(\mathbb{R}^2 - \text{disk})$, each step will increase the error, thus we will get an upper bound. The reason for changing the square to circle is that so we can use the rotation symmetry. Continue with the integral,</p> <p>\(\begin{align} \notag |\Delta g(t)|^2 &amp;&lt; \frac{1}{4\pi\lambda}\int_ {\omega^2&gt;\Lambda^2} d^2\omega e^{-\omega^2/4\lambda}\\\notag &amp;= \frac{1}{4\pi\lambda} \int_ {\omega^2&gt;\Lambda^2} d^2\omega e^{-\omega^2/4\lambda} \\\notag &amp;= \frac{1}{4\pi\lambda}2\pi \int_ {\Lambda}^\infty \int d\omega \, \omega e^{-\omega^2/4\lambda} \end{align}\) where we have used $d^2 \omega = d\omega \omega d\theta$, \(\begin{align} |\Delta g(t)|^2 &amp;&lt; \frac{1}{4\lambda} \int_ {\Lambda}^\infty \int d\omega^2 \, \omega e^{-\omega^2/4\lambda} \\ &amp;= e^{-\Lambda^2/4\lambda}. \end{align}\)</p> <p>The conclusion is that at each $t$, the error $[g^{(\infty)}-g^{(\infty)}]^2 &lt; e^{-\Lambda^2/4\lambda}$.</p> <p><img src="/img/region.png" alt="region"/></p> <p>Out of a more differential point of view, let us consider the change of the function as we vary the cutoff $\Lambda$. We can calculate $\boxed{\frac{d}{d\Lambda} g^{(\Lambda)}(t)}$. Note that sometimes we will neglect the independent variable $t$ to save some space.</p> <p>If we increase $\Lambda$ infinitesimally, we have</p> \[\begin{align} \notag g^{(\Lambda+\epsilon)}(t) &amp; = g^{(\Lambda)} + \frac{1}{\sqrt{\pi\lambda}} \int_ \Lambda^{\Lambda+\epsilon} d\omega e^{-\omega^2/4\lambda} \cos(\omega t)\\ &amp;= g^{(\Lambda)} + \frac{\epsilon}{\sqrt{\pi\lambda}} e^{-\Lambda^2/4\lambda} \cos(\Lambda t), \end{align}\] <p>Thus</p> \[\boxed{ \frac{d}{d\Lambda} g^{(\Lambda)}(t) = \frac{e^{-\Lambda^2 / 4\lambda}}{\sqrt{\pi\lambda}} \cos(\Lambda t) = \text{Re}\,\frac{e^{-\Lambda^2 / 4\lambda}}{\sqrt{\pi\lambda}} e^{i\Lambda t} = \text{Re}\,\frac{e^{-\lambda t^2}}{\sqrt{\pi\lambda}} e^{-\frac{1}{4\lambda} (\Lambda-i2\lambda t)^2}. }\] <p>It can be solved to give,</p> \[g^{(\Lambda)}(t) = C_ 1 - e^{-\lambda t^2} \text{Re} \, \text{erf}\left(i\sqrt{\lambda} t - \frac{\Lambda}{2\sqrt{\lambda}}\right),\] <p>where $C_ 1$ is the constant of integration. To eliminate $C_ 1$, recall that $f^{\infty}(t) = e^{-\lambda t^2}$, thus we have $C_ 1 = 0$. By the end of the day we have</p> \[\boxed{ g^{(\Lambda)}(t) = - e^{-\lambda t^2} \text{Re} \, \text{erf}\left(i\sqrt{\lambda} t - \frac{\Lambda}{2\sqrt{\lambda}}\right) },\] <p>which agrees with the previous equations. The value of $\Delta g(t)$ can also be estimated with the help of Hans Heinrich Burmann’s theorem,</p> \[\text{erf}{x} = \frac{2}{\sqrt{\pi}}\text{sgn}\cdot \sqrt{1-e^{-x^2}} \left( \frac{\sqrt{\pi}}{2}+ \sum_ {k\in \mathbb{Z}^+} c_ k e^{-k x^2} \right), \, c_ 1 = \frac{31}{200},\, c_ 2 = -\frac{341}{8000},\, \cdots.\] <p>In summary, We have obtained the lattice spacing dependence, or equivalently the momentum cutoff dependence, both the error estimate and the RG flow are discussed.</p> <hr/> <h3 id="in-homogeneous-linear-differential-equation">In-homogeneous Linear Differential Equation</h3> <hr/> <h3 id="kink-equation">kink Equation</h3> <hr/> <h3 id="conventions">Conventions</h3> <p>The conventions are chose so be the same as that used by Mathematica.</p> <p>Given a function $f(t):\mathbb{R} \to \mathbb{R}$, the Fourier transform in the symmetrical form is</p> \[\begin{align} \tilde{f} (\omega) &amp;= \frac{1}{\sqrt{2\pi}}\int_ {-\infty}^\infty f(t) e^{i\omega t} dt, \\ f(t) &amp;= \frac{1}{\sqrt{2\pi}}\int_ {-\infty}^\infty \tilde{f}(\omega) e^{-i\omega t} dt \end{align}\] <p>where $\tilde{f}(\omega) \equiv \mathcal{F}\left{ f \right}(\omega)$. Note the factor of $\frac{1}{\sqrt{2\pi}}$ and the signs in the exponent.</p> <hr/> <h3 id="error-function-in-the-complex-plane">Error function in the complex plane</h3> <p>The error function in the complex plane is defined to be</p> \[\operatorname* {erf}{z} = \frac{2}{\sqrt{\pi}} \int_ {\Gamma} d\zeta \, e^{-\zeta^2}\] <p>where $\Gamma$ is any path going from $0$ to $z$. The real and imaginary part of an error function can be estimated by Abramowitz and Stegun.</p> <p>The error function $\text{erf}(z),\, z \in \mathbb{C}$ satisfy symmetry relations</p> \[\begin{align} \text{erf}(z) &amp;= - \text{erf}(-z), \\ \text{erf}(\overline{z}) &amp;= \overline{\text{erf}(z)}. \end{align}\] <p>A possibly useful series expression for numerical calculation is</p> \[\begin{multline} \operatorname* {erf}(x+i y) = \operatorname* {erf}{x} + \frac{e^{-x^2}}{2 \pi x} [(1-\cos{2 x y})+i \sin{2 x y}]\\ + \frac{2}{\pi} e^{-x^2} \sum_ {k=1}^{\infty} \frac{e^{-k^2/4}}{k^2+4 x^2}[f_ k(x,y)+i g_ k(x,y)] + \epsilon(x,y) \end{multline}\] <p>where</p> \[\begin{align*} f_ k(x,y) &amp;= 2 x [1-\cos(2 x y) \cosh(k y)] + k\sin(2 x y) \sinh(k y), \\ g_ k(x,y) &amp;= 2 x \sin(2 x y) \cosh(k y) + k\cos(2 x y) \sinh(k y). \end{align*}\]]]></content><author><name>Baiyang Zhang</name></author><category term="Math"/><category term="Renormalization"/><summary type="html"><![CDATA[Abstract]]></summary></entry><entry><title type="html">Note on The Moral Foundations of Politics</title><link href="https://baiyangzhang.github.io/blog/2023/Note-on-The-Moral-Foundations-of-Politics/" rel="alternate" type="text/html" title="Note on The Moral Foundations of Politics"/><published>2023-12-25T00:00:00+00:00</published><updated>2023-12-25T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Note-on-The-Moral-Foundations-of-Politics</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Note-on-The-Moral-Foundations-of-Politics/"><![CDATA[<h1 id="enlightenment-politics">Enlightenment Politics</h1> <blockquote> <p>f there is a single overarching idea shared in common by adherents to different strands of Enlightenment thinking, it is faith in the power of human reason to understand the true nature of our circumstances and ourselves. Human improvement is measured by the yardstick of <strong>individual rights</strong> that embody, and protect, <strong>human freedom</strong>.</p> </blockquote> <blockquote> <p>Descartes announced that he was in search of propositions that are impossible to doubt. His famous example, known as the <code class="language-plaintext highlighter-rouge">cogito</code>, was ‘‘I think, therefore I am.’’</p> </blockquote> <blockquote> <p>Immanuel Kant defined in <code class="language-plaintext highlighter-rouge">The Critique of Pure Reason</code> (1781), of placing knowledge ‘‘on the secure path of a science.’’</p> </blockquote> <blockquote> <p>These developments in philosophy reflected and reinforced the emergence of modern scientific consciousness.</p> </blockquote> <p>Such ideas, as necessary conditions for the development of natural science (not merely technology), seems to never had appeared in China. Year 1781 is the year 乾隆四十六年 in China, one of the most closed, ignorant, and autocratic era in history.</p> <blockquote> <p>During the seventeenth and eighteenth centuries, when the hallmark of scientific knowledge was indubitable certainty, ethics, political philosophy, and the human sciences were regarded as superior to the natural sciences. This view seems strange from the vantage point of the twenty-first century, when fields like physics, chemistry, astronomy, geology, and biology have all advanced with astonishing speed to discoveries that would have been unimaginable in the eighteenth century.</p> </blockquote> <h2 id="the-workmanship-ideal-of-knowledge">The Workmanship Ideal of Knowledge</h2> <blockquote> <p>The first distinctive feature of the early Enlightenment concerns the range of <code class="language-plaintext highlighter-rouge">a priori knowledge</code>, the kind of knowledge that either follows from definitions or is otherwise deduced from covering principals. This is the kind of knowledge Descartes had in mind when he formulated his cogito and that Kant located in the realm of ‘‘analytic judgments.’</p> </blockquote> <p><strong>Epistemology</strong> is a branch of philosophy that studies the nature, origin, and limits of human knowledge. The term comes from the Greek words “episteme,” meaning knowledge or understanding, and “logos,” meaning study or discourse. Epistemology addresses questions such as:</p> <ul> <li>What is knowledge?</li> <li>How is knowledge acquired?</li> <li>What do people know?</li> <li>How do we know what we know?</li> <li>What are the limits of human knowledge?</li> <li>What makes beliefs justified or rational?</li> </ul> <p>In exploring these questions, epistemology deals with the definition of knowledge and its scope and limits. It often involves debating between different theories of knowledge, such as empiricism (the idea that knowledge comes primarily from sensory experience), rationalism (the idea that reason is the main source of knowledge), and constructivism (the idea that knowledge is constructed by individuals through their interactions with the world).</p> <p>Immanuel Kant distinguished between two types of judgments: <code class="language-plaintext highlighter-rouge">analytic</code> and <code class="language-plaintext highlighter-rouge">synthetic</code>. These distinctions are central to his philosophy, especially in his work “Critique of Pure Reason.”</p> <ol> <li> <p><strong>Analytic Judgments</strong>: An analytic judgment is one where the predicate (the part of the sentence that says something about the subject) is contained within the subject itself. The truth of an analytic judgment is derived from the meanings of the words involved and logical reasoning. They are tautological in nature and do not add any new information about the world. For example, the statement “All bachelors are unmarried” is analytic because the predicate “unmarried” is part of the definition of the subject “bachelor.”</p> </li> <li> <p><strong>Synthetic Judgments</strong>: A synthetic judgment, on the other hand, is one where the predicate adds something to the subject that is not contained within it. The truth of a synthetic judgment is determined through how our concepts relate to the world and cannot be known just by understanding the meanings of the words. They require empirical investigation or intuition. For instance, “The cat is on the mat” is a synthetic judgment because the concept of “the cat” does not inherently include the concept of “being on the mat.”</p> </li> </ol> <p>Kant’s distinction between analytic and synthetic judgments is fundamental to his epistemology, particularly in addressing the question of how human beings can have knowledge about the world. He further introduced the concept of “synthetic a priori” judgments, which are synthetic judgments that are known independently of experience (a priori), like mathematical truths.</p> <hr/> <p>The <code class="language-plaintext highlighter-rouge">creationist</code> or <code class="language-plaintext highlighter-rouge">workmanship</code> theory in political science, often associated with the work of John Locke, is a theory of political obligation. It suggests that political authority and legitimacy derive from the consent of the governed, likening the role of the government or ruler to that of a craftsman or creator who constructs a system with the consent and for the benefit of the people.</p> <p>This theory is rooted in the idea that political and social structures are artificial constructs, made by human beings, unlike natural phenomena. The “creationist” aspect implies that political structures are deliberately created or constructed, rather than organically evolved. The “workmanship” aspect emphasizes the idea that the creators or rulers of these structures have a responsibility to the people they govern, similar to how a craftsman is responsible for the quality and function of their creation.</p> <p>Locke’s theory was revolutionary at its time because it challenged the prevailing notion of the divine right of kings, suggesting instead that political authority is justified only when it serves the interests of the governed and respects their rights. This theory laid the groundwork for modern concepts of democracy, individual rights, and the social contract.</p> <hr/> <p>Thomas Hobbes and John Locke, two prominent philosophers, had distinct views on natural law, reflecting their differing perspectives on human nature and the ideal structure of society.</p> <p>Hobbes, in his work “Leviathan,” presented a rather pessimistic view of human nature. He believed that in the state of nature (a hypothetical condition without government or laws), humans are driven by self-interest and a desire for self-preservation, leading to a “war of all against all” (bellum omnium contra omnes). In this state, life would be “solitary, poor, nasty, brutish, and short.”</p> <p>For Hobbes, natural law is a set of precepts or general rules, <em>discovered by reason</em>, which prohibit anything destructive to one’s own life. <em>It’s based on the right of every individual to preserve their own life</em>, leading to the conclusion that humans should seek peace. This is where his famous concept of the social contract comes into play: individuals surrender some of their freedoms and submit to the authority of a ruler (or a ruling assembly) to ensure their own safety and peace. Thus, Hobbes’s natural law is fundamentally about self-preservation and the avoidance of harm to others as a means of securing one’s own safety.</p> <p>Locke’s view, as articulated in “Two Treatises of Government,” is more optimistic about human nature. He believed that in the state of nature, humans live in a state of equality and freedom, not inherently prone to violence or war. For Locke, the <em>law of nature is a moral guide based on the belief that God has given the world to all people in common</em>. It teaches that, since all are equal and independent, no one ought to harm another in their life, health, liberty, or possessions.</p> <p>Locke’s natural law is grounded in the rights to life, liberty, and property. It includes the idea that people have the obligation to respect the rights of others. His social contract theory suggests that people form governments to protect these natural rights. If a government fails to do so, citizens have the right to overthrow it. This view laid the groundwork for modern democracy and significantly influenced the development of political philosophy in the Western world.</p> <p>So, Hobbes saw natural law as a means of avoiding the brutal state of nature through self-preservation and peace, whereas Locke viewed natural law as a moral guide ensuring equality and the inherent rights of life, liberty, and property.</p> <hr/> <blockquote> <p>A basic issue for Locke and many of his contemporaries was the ontological status of natural law and in particular its relation to God’s will.</p> </blockquote> <p>In this sentence, “ontological status” refers to the fundamental nature or essence of natural law, especially in relation to its existence and its relationship to God’s will. Ontology, in philosophy, is the study of being or existence, and it deals with questions concerning what entities exist or can be said to exist, and how such entities can be grouped, related within a hierarchy, and subdivided according to similarities and differences.</p> <p>So, when discussing the “ontological status of natural law” in the context of John Locke and his contemporaries, the focus is on understanding the very essence of natural law: whether it exists as an objective reality independent of human beings, how it relates to or derives from God’s will, and what its fundamental characteristics are. This was a central topic in the philosophical and theological debates of that era, particularly in the context of determining the basis and legitimacy of moral and legal principles. Locke and many others were engaged in trying to understand whether natural laws were inherent aspects of the universe, ordained by God, or whether they were constructs of human reason and society.</p> <p>“Will-centered” refers to the philosophical position known as voluntarism. This is a theory that emphasizes the role of the will, either divine or human, in various philosophical contexts. In the context of Locke’s moral and political writings, being “will-centered” or a voluntarist means that Locke ultimately leaned towards the view that natural law and moral principles are determined by the will, particularly the will of God, rather than being inherent or objective truths that exist independently of any will.</p> <p>In Locke’s time, the debate about the nature of natural law often centered around whether natural laws were intrinsic to the universe (a position known as intellectualism or rationalism) or whether they were decrees of God’s will (voluntarism). A will-centered or voluntarist approach suggests that moral and legal norms derive their authority from an act of will, particularly the divine will, rather than from reason alone or from the inherent nature of reality. In this view, what is right or wrong, just or unjust, is so because God wills it to be that way, and human beings understand and follow these laws through revelation, religious teachings, or other means of discerning God’s will.</p> <blockquote> <p>Locke distinguished “ectype”’ from “archetype” ideas: ectypes are general ideas of substances, and archetypes are ideas constructed by man.</p> </blockquote> <p>John Locke’s distinction between “ectype” and “archetype” ideas is a crucial aspect of his epistemological theory, which he discusses in his work “An Essay Concerning Human Understanding.” This distinction is part of his broader inquiry into the nature of human knowledge and understanding.</p> <p>In Locke’s philosophy, archetypes are the original models or patterns from which copies are made. They are the fundamental, primary ideas that exist in the mind of God or, in a more secular interpretation, the perfect, abstract forms of things. When Locke refers to archetypes as ideas constructed by man, he means that these are the ideal standards or criteria we hold in our minds for categorizing and understanding the world. They represent our understanding of what the essential characteristics of a particular thing are.</p> <p>For instance, the archetype of a tree would be the idealized concept or mental representation of what a tree is supposed to be. This archetype is not derived from any particular tree but is a kind of composite or abstracted idea of “treeness” that we use to recognize and categorize individual trees.</p> <p>Ectypes, on the other hand, are derivative or secondary ideas. They are the imperfect copies or generalizations that we derive from our experience with individual instances in the world. Ectype ideas are more about the general ideas of substances we form based on our sensory experiences and observations. When we see many individual trees, for example, we form a general idea of what a tree is - this is an ectype. It’s a more practical, experiential idea based on the aggregation of real-world instances.</p> <p>In summary, Locke’s distinction between archetype and ectype ideas can be understood as a differentiation between the idealized, abstract concepts we hold in our minds as standards (archetypes) and the more practical, general ideas we form based on our sensory experience of the world (ectypes). Archetypes are about the essence or ideal form of things, while ectypes are about the general, often imperfect, concepts we derive from actual experiences.</p> <h2 id="the-preoccupation-with-certainty">The Preoccupation with Certainty</h2> <blockquote> <p>The post-Humean Enlightenment tradition has been marked by a fallibilist view of knowledge. All knowledge claims are fallible on this account, and science advances not by making knowledge more certain but by producing more knowledge. Recognizing the corrigibility of all knowledge claims and the possibility that one might always be wrong exemplifies the modern scientific attitude. As Karl Popper (1902-1994) noted, the most that we can say, when hypotheses survive empirical tests, is that they have not been falsified so that we can accept them provisionally.</p> </blockquote> <p><code class="language-plaintext highlighter-rouge">Value judgments</code> are statements or opinions that express an evaluation, typically of something’s worth, beauty, goodness, or morality. Examples include statements like “Lying is wrong,” or “This painting is beautiful.” A.J. Ayer was a key figure in the logical positivist movement, which held that for a statement to be meaningful, it must be either empirically verifiable (i.e., testable by observation or experiment) or analytically true (true by definition, like mathematical or logical statements). In logical positivism, a <code class="language-plaintext highlighter-rouge">proposition</code> is a statement that can be either true or false. It’s a claim about the world that can, <em>at least in principle</em>, be tested and verified or falsified.</p> <p>The Logical Positivist movement, also known as Logical Empiricism, was a philosophical movement that emerged in the early 20th century. It primarily revolved around a group of philosophers associated with the Vienna Circle (<code class="language-plaintext highlighter-rouge">Moritz Schlick</code>, <code class="language-plaintext highlighter-rouge">Hans Hahn</code>, ), along with others like A.J. Ayer in Britain. This movement sought to apply the rigor of scientific methodology to philosophy, with a significant focus on the analysis of language and the verification of statements.</p> <p>Key Features of Logical Positivism include</p> <ol> <li> <p><strong>Verification Principle</strong>: The central tenet of Logical Positivism is the verification principle. This principle asserts that a statement is only meaningful if it can be empirically verified or is analytically true (true by virtue of its meaning, like “All bachelors are unmarried”). The idea was to eliminate metaphysical and abstract discussions that couldn’t be supported by empirical evidence or logical reasoning.</p> </li> <li> <p><strong>Empiricism and Science</strong>: Logical Positivists emphasized the importance of empirical evidence and scientific methods in acquiring knowledge. They viewed science as the model for all true knowledge.</p> </li> <li> <p><strong>Rejection of Metaphysics</strong>: They were critical of metaphysics and other traditional philosophical endeavors, which they saw as meaningless since such statements couldn’t be empirically verified. They believed that many philosophical problems arose from misunderstandings of language and could be resolved by clarifying the language used.</p> </li> <li> <p><strong>Language and Meaning</strong>: A significant focus was placed on the analysis of language, particularly the language of science. They aimed to clarify how language is used in scientific theories and to distinguish between meaningful and meaningless statements.</p> </li> <li> <p><strong>Influence of Wittgenstein</strong>: Although not officially part of the Vienna Circle, Ludwig Wittgenstein’s early work, especially his “Tractatus Logico-Philosophicus,” significantly influenced Logical Positivism. Wittgenstein argued that <em>much of philosophy consists of nonsensical propositions and that the role of philosophy should be to clarify thought and language</em>.</p> </li> <li> <p><strong>Ethical and Aesthetic Statements</strong>: Logical Positivists generally considered ethical and aesthetic statements to be expressions of emotions or subjective preferences, rather than statements that could be true or false.</p> </li> </ol> <p>The “positivism” component is linked to the movement’s commitment to a scientific and empirical approach to knowledge. Positivism, as a philosophical stance, argues that knowledge should be based on positive, observable facts and their logical and mathematical treatment. It rejects introspection and intuition as sources of knowledge and instead emphasizes empirical evidence obtained through observation and experimentation. Logical Positivists extended this approach by asserting that statements must be empirically verifiable (or analytically true) to be meaningful.</p> <hr/> <p>Somewhat to my surprise, Karl Popper is not a member of the Vienna circle even though they shared many intellectual engagements. Furthermore, Karl Popper is even critically oppositional. The Vienna Circle advocated for the verification principle, which held that a statement is meaningful only if it can be empirically <em>verified</em>. Popper challenged this view, proposing <em>falsificationism</em> instead. According to Popper, scientific theories cannot be conclusively verified but can be falsified. He argued that a theory is scientific if it is testable and can potentially be refuted by evidence. This approach places a greater emphasis on the role of empirical refutation rather than verification.</p> <p>Also, Popper was critical of what he called <code class="language-plaintext highlighter-rouge">historicism</code> – the belief that <em>history unfolds according to deterministic laws or principles</em>. He argued that such theories, which <em>were often used to justify authoritarian regimes</em>, are fundamentally flawed. He believed that historicism led to totalitarianism because it promoted the idea that certain individuals or groups had access to inevitable truths about societal development, thus justifying their absolute rule. Popper advocated for what he termed an <code class="language-plaintext highlighter-rouge">open society</code>. An open society, in his view, is characterized by a democratic government, individual freedoms, and a critical attitude towards tradition and authority. It allows for change and improvement through rational and critical discourse, as opposed to the unquestioning acceptance of dogmatic principles.</p> <p>Just as Popper applied the <em>principle of falsifiability</em> to scientific theories, he suggested that political policies should also be subjected to critical scrutiny and should be alterable in the face of new evidence or arguments. He was wary of any political theory or system that claimed to have absolute or final answers.</p> <hr/> <p>According to Ayer, the expression of a value judgment is not a proposition since it can not be judged by right and wrong, the question of truth or falsehood does not here arise.</p> <p>Regarding ethics, Ayer points out that many theorists in ethics tend to treat statements about the causes and characteristics of our ethical feelings as if these statements were definitions of ethical concepts. For example, a theory might claim that an action is good if it promotes happiness. Here, the cause of the ethical feeling (happiness) is used to define the ethical concept (good). Ayer argues that ethical concepts are <em>pseudo-concepts</em>, since ethical concepts, in his view, is neither empirically verifiable or analytically correct.</p> <p>Ayer’s stance is closely associated with <code class="language-plaintext highlighter-rouge">emotivism</code>, a meta-ethical view that suggests <em>ethical statements do not assert propositions but express emotional attitudes</em>. According to emotivism, saying “Stealing is wrong” is akin to expressing one’s disapproval of stealing, rather than making an objective claim about the nature of stealing.</p> <h2 id="the-centrality-of-individual-rights">The Centrality of Individual Rights</h2> <blockquote> <p>In addition to faith in science, the Enlightenment’s central focus on individual rights differentiates its political philosophy from the ancient and medieval commitments to order and hierarchy. This focus brings the freedom of the individual to the center of arguments about politics. This move was signaled in the natural law tradition by a shift in emphasis from the logic of law to the idea of natural right.</p> </blockquote> <p>Hobbes contended that it was customary to conflate “Jus and Lex, law and right”. Yet he made the distinction that right, consisted in liberty to do, or to forbeare, whereas law, determines and binds to one of them. Similarly by Locke.</p> <p>John Locke’s oppinion on natural law is as the following. In his work <em>Essays on the Law of Nature</em>, Locke argues a moral law inherent in the world and discoverable through reason.</p> <p>Key points of Locke’s argument include:</p> <ol> <li> <p><strong>Natural Law and Reason:</strong> Locke posits that natural law is an aspect of the natural world, similar to physical laws. According to him, this <em>moral law can be discovered through the use of reason, without the need for divine revelation</em>.</p> </li> <li> <p><strong>Moral Obligations:</strong> He argues that <em>natural law imposes moral obligations on individuals</em>. These moral principles are universal and apply to all people, regardless of their culture or society.</p> </li> <li> <p><strong>Rights and Duties:</strong> Locke’s view of natural law is closely tied to his ideas about individual rights and duties. He believes that natural law forms the basis for understanding human rights, especially the right to life, liberty, and property.</p> </li> <li> <p><strong>Foundation for Political Theory:</strong> These essays lay the groundwork for Locke’s later political theories, particularly those presented in his famous works, “Two Treatises of Government.” He uses the concept of natural law to argue for the rights of individuals and the limitations of governmental power.</p> </li> <li> <p><strong>Human Equality:</strong> Locke emphasizes the inherent equality of all human beings, derived from their natural state. This idea is a critical aspect of his argument against absolute monarchy and for the formation of governments based on the consent of the governed.</p> </li> <li> <p><strong>Religious Tolerance:</strong> Although not as explicitly developed in these essays as in his later works, Locke’s concept of natural law also leads to his advocacy for religious tolerance, seeing religious belief as a matter of individual conscience.</p> </li> </ol> <p>In summary, Locke’s “Essays on the Law of Nature” propose that there is a moral law inherent in the natural world, understandable through human reason, and that this law underpins human rights and forms the basis for just and ethical governance.</p> <hr/> <p>John Locke’s <code class="language-plaintext highlighter-rouge">voluntarist theology</code> reflects his views on the nature of God and the relationship between divine will and moral law. The emphasis is on <em>the will will (voluntas in Latin, hence the name) of God of God as the primary or sole source of moral law</em>. Locke’s voluntarism posits that <em>moral laws are decrees of God’s will</em>. In this view, what is morally right or wrong is so because God wills it, and not necessarily because it aligns with any intrinsic moral truths or rational principles independent of God’s will. Locke emphasizes the <em>absolute freedom</em> and <em>omnipotence</em> of God. He argues that God’s will is not bound by any external standards or principles. Therefore, moral laws are a product of God’s free choice.</p> <p>While Locke is a proponent of reason and believes that human beings can discover moral truths through rational inquiry, he also upholds the importance of divine revelation. In his voluntarist theology, revelation plays a crucial role in imparting knowledge of God’s will, which might not be entirely accessible through reason alone. Locke’s voluntarism is tied to his rejection of innate ideas, a concept he famously critiques in his “Essay Concerning Human Understanding.” He argues against the notion that <em>moral principles are innately known</em>, instead positing that our understanding of moral laws comes from experience, reason, and revelation. Locke’s voluntarist approach suggests that moral obligations are ultimately grounded in obedience to God’s will. This perspective can lead to a form of ethical subjectivism, where moral truths depend on the decrees of a divine authority.</p> <hr/> <blockquote> <p>In Locke’s formulation, natural law dictates that man is subject to divine imperatives to live in certain ways, but, within the limits set by the law of nature, men can act in a godlike fashion. Man as maker has a maker’s knowledge of his intentional actions, and a natural right to dominion over man’s products. … Provided we do not violate natural law, we stand in the same relation to the objects we create as God stands to us; we own them just as he owns us.</p> </blockquote> <h2 id="tensions-between-science-and-individual-rights">Tensions Between Science and Individual Rights</h2> <p>The two enlightenment values, the preoccupation of science and the commitment to individual rights, seem to be in contradiction with each other. Science is deterministic, concerned with discovering the laws that govern the universe, with human being included. This has potential for conflict with an ethic that emphasizes individual freedom, for now the freedom has to be subjugated to the laws (of nature, of God).</p> <p>In Locke’s theory, the freedom to comprehend natural law by one’s own lights supplied the basis of Locke’s right to resist, which could be invoked against the sovereign. No one is in a higher position to monopolize the right to interpret the scripture.</p> <blockquote> <p>We will see this tension surface repeatedly in the utilitarian, Marxist, and social contract traditions, without ever being fully resolved.</p> </blockquote> <h1 id="classical-utilitarianism">Classical Utilitarianism</h1> <p>Jeremy Bentham famously wrote that</p> <blockquote> <p>Nature has placed mankind under the governance of two sovereign masters, <em>pain</em> and <em>pleasure</em>. It is for them alone to point out what we ought to do, as well as to determine what we shall do. On the one hand the standard of right and wrong, on the other the chain of causes and effects, are fastened to their throne. They govern us in all we do, in all we say, in all we think: every effort we can make to throw off our subjection, will serve but to demonstrate and confirm it. In words a man may pretend to abjure their empire: but in reality he will remain subject to it all the while. The principle of utility recognizes this subjection, and assumes it for the foundation of that system, the object of which is to rear the fabric of felicity by the hands of reason and law. Systems which attempt to question it, deal in sounds instead of senses, in caprice instead of reason, in darkness instead of light.</p> </blockquote> <p>The <code class="language-plaintext highlighter-rouge">principle of utility</code>, as Bentham explains, ‘‘approves or disapproves of every action whatsoever, according to the tendency which it appears to have to augment or diminish the happiness of the party whose interest is in question: or, what is the same thing in other words, to promote or to oppose that happiness.’’</p>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Enlightenment Politics]]></summary></entry><entry><title type="html">Introduction to Higher Form Symmetry</title><link href="https://baiyangzhang.github.io/blog/2023/Introduction-to-Higher-Form-Symmetry-Lecture-3/" rel="alternate" type="text/html" title="Introduction to Higher Form Symmetry"/><published>2023-12-21T00:00:00+00:00</published><updated>2023-12-21T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Introduction-to-Higher-Form-Symmetry%20Lecture%203</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Introduction-to-Higher-Form-Symmetry-Lecture-3/"><![CDATA[<p>For conventions used in this note, see my other blog <a href="https://www.mathlimbo.net/blog/2022/Conventions-and-Formula/">here</a>.</p> <p>In lecture 2 we talked about classic symmetry and their re-interpretation in the language of differential (exterior) form. We have made the connection between the so-called symmetry defect operator (SDO) and a charged, point (0-dimensional) operator. In this note we try to generalized this concept to charged operators defined on manifolds of dimension more than zero, such as a line or a surface, etc.</p> <p>Let’s start with the ordinary symmetry once again on a $D$-dimensional manifold. We first upgraded the global symmetry parametrized by $\epsilon$ to a local symmetry parametrized by $\epsilon(x)$, and write the action variation as \(\delta S = \int d^{D}x \, J^{\mu}\partial_ {\mu}\epsilon(x) \tag{1}\) under $e^{ iQ_ {\Sigma} }$ the charged operators with non-trivial linking $\text{Link}(\Sigma,x)$ transform as \(\phi(x) \to \epsilon(x) \Delta \phi(x).\) In our convention, $\Delta$ stands for a small but finite change while $\epsilon(x)$ stands for an infinitesimal parameter. Eq. (1) can be regarded as the definition of the Noether current $J^{\mu}$, which tells us how much the action changed under the transformation in question. But, being a symmetry of the system, of course the action must remains unchanged under the transformation, thus we have the Noether current \(\partial_ {\mu}J^{\mu} = 0 \Longleftrightarrow d\star J=0.\)</p> <p>In terms of differential forms, function $\epsilon(x)$ is a $0$-form and constant function $\epsilon$ is a closed form. The variation of action reads \(\delta S = \int_ {M^{(D)}} (\star J)\wedge d\epsilon, \tag{2}\) where $\star J$ is a $(D-1)$-form, $d \epsilon$ is a $1$-form (since $\epsilon$ is a zero form), hence their wedge product is a $D$-form, something can be integrated over $D$-dimensional manifold $M$ (whose boundary is $\Sigma$).</p> <hr/> <p>The advantage of Eq. (2) is that it can be generalized to higher forms. Assume now the symmetry is parametrized by a $1$-form $\xi = \xi_ {\mu}dx^{\mu}$. Then $d \xi$ is a 2-form, as a result $\star J$ is a $(D-2)$-form thus $J$ is a $2$-form. The conservation law becomes \(d \star J = 0 \to \partial_ {\mu} J^{\mu \nu}=0.\) Since $(D-2)$-form can be integrated over a $(D-2)$ manifold, we can define the charge operator as \(Q(\Sigma_ {D-2}):= \int_ {\Sigma} \, \star J.\)</p>]]></content><author><name>Baiyang Zhang</name></author><category term="PureMath"/><category term="Notes"/><summary type="html"><![CDATA[For conventions used in this note, see my other blog here.]]></summary></entry><entry><title type="html">Introduction to Resurgence and Transseries 4</title><link href="https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-Lecture-4/" rel="alternate" type="text/html" title="Introduction to Resurgence and Transseries 4"/><published>2023-12-20T00:00:00+00:00</published><updated>2023-12-20T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-Lecture-4</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-Lecture-4/"><![CDATA[<h3 id="introduction">Introduction</h3> <p>This part follows from a lecture by Maxim Kontsevich.</p> <p>There are roughly speaking three perspectives of resurgence,</p> <ul> <li>Borel plane,</li> <li>Exponential integrals,</li> <li>Ray-crossing in the complex plane.</li> </ul> <p><strong>Simple resurgence package.</strong> Consists of</p> <ol> <li>A discrete subset of complex plane, $\left{ z_ {\alpha} \right}\in\mathbb{C}$, finite countable.</li> <li>Formal power series,</li> <li>A collection of integers $n_ {\alpha \beta}\in\mathbb{Z}$, called Stokes integers, usually anti-symmetric, $n_ {\alpha \beta}=-n_ {\beta \alpha}$.</li> </ol> <p>There is an axiom. Consider function $\phi_ {\alpha}(\zeta)$,</p> \[\phi_ {\alpha}(\zeta) := \sum_ {k\geq 0} \frac{c_ {\alpha,k}}{k!} (\zeta-z_ {\alpha})^{k}.\] <p>It is analytic germ at $z_ {\alpha}$, Meaning it converges at some small disk centered at $z_ {\alpha}$. This extends analytically to star-shaped domain</p> \[\mathbb{C} - \bigcup_ {\alpha \neq \beta} (z_ {\beta} + \mathbb{R}_ {+}(z_ {\beta}-z_ {\alpha})).\] <p>This is hard to explain it with words but I am too lazy to draw a picture and include it to my note. The best way to describe it is to regard $z_ {\alpha}$ as the sun, radiating heat and light, and consider $z_ {\beta}$ as planets, all lying on the complex plane, then the star-shaped manifold is the area where the light from $z_ {\alpha}$ reaches. And we want to describe how the functions jumps at the ray of shades.</p> <p>The jumps are controlled by the numbers $n_ {\alpha \beta}$, in the following fashion. The function of interested $\phi_ {\alpha}$ is not holomorphic at $z_ {\beta}$’s, but it can be separated into holomorphic and singular part, roughly as</p> \[\phi_ {\alpha}(\zeta){\Large\mid}_ {z_ {\beta}} = \text{holomorphic part} + \frac{n_ {\alpha \beta}}{2\pi i} \log(\zeta-z_ {\beta})\times \text{something}.\] <hr/> <p>A <code class="language-plaintext highlighter-rouge">formal series</code> is an infinite formal sum that is considered independently from any notion of <em>convergence</em>, and can be manipulated with the usual algebraic operations on series, such as addition, multiplication, division, partial sum, etc.</p> <p>A <code class="language-plaintext highlighter-rouge">formal power series</code> is a special case of formal series, whose terms are of form $ax^{n}$ where $n\in\mathbb{Z}^{+}$ is the power of the variable $x$. $a$ is the coefficient of that term. They can be viewed as a generalization of polynomials, where the number of terms is allowed to be finite, with no requirement of convergence. One of the biggest difference between <em>formal</em> power series and power series is that the operation <code class="language-plaintext highlighter-rouge">evaluation</code> is not defined for formal power series but is for regular power series, which can thus be identified as a function, at least within the radius of convergence. In formal power series, in a term such as $a x^{5}$, $x^{5}$ is merely a position holder, used to tell the position of $a$ is a tuple of coefficients.</p> <p>It is the fact that we don’t need to bother about convergence that made the ring of formal power series so useful in our discussion. Doing arithmetic is actually simpler with formal power series, since you can just pretend it is a power series without worrying about <em>absolute, conditional</em> and <em>uniform convergence</em>.</p> <p>In the previous notes we have introduced the (complex) formal power series of $z^{-1}$ without constant term, denoted \(z^{-1}\mathbb{C}[[ z^{-1} ]].\)</p> <p>The <code class="language-plaintext highlighter-rouge">formal Borel transformation</code> is defined to be a linear map from $z^{-1}\mathbb{C}[[ z^{-1} ]]$ to $\mathbb{C}[[\zeta]]$ as \(\mathcal{B}: \tilde{\phi} = \sum_ {0}^{\infty} a_ {n} z^{-n-1} \mapsto \hat{\phi} = \sum_ {0}^{\infty } \frac{a_ {n}}{n!} \zeta^{n}\)</p> <p>The reason for this definition is that we hope the introduction of extra $1 / n!$ factor in the coefficients can turn the original formal power series into a convergent power series, which we can then identify to a function. The change of variable from $z^{-1}$ to $\zeta$ seems out of nowhere, like, where does this $\xi$ came from? One way to explain it, without mathematical rigor but quite intuitive, is to say that it comes from writing the power of $z$ to the integral form,</p> \[x^{n+1} = \frac{1}{n!} \int_{0}^{\infty} d\xi \, \xi^{n} e^{ -\xi / x } , \quad x=\frac{1}{z},\] <p>which is a generalized form of the Euler integral. Substitute it to $\tilde{\phi}$ and re-arrange the order of integral and summation (which is not allowed! But we do it anyway) we find the mysterious $\xi$.</p> <p>For the formal power series in $\mathbb{C}[[z^{-1}]]$ (note that we have put constant terms back in to make the case most general) which are actually convergent at infinity ($z\to \infty$) with positive radius of convergence, we denote the collection of them</p> \[\mathbb{C}\left\{ z^{-1} \right\}\] <p>and the ones without constant terms are again denoted</p> \[z^{-1}\mathbb{C}\left\{ z^{-1} \right\} .\] <p><strong>Lemma 1.</strong> Let</p> \[\tilde{\phi}\in z^{-1}\mathbb{C}[[z^{-1}]],\] <p>then</p> \[\tilde{\phi}\in z^{-1}\mathbb{C}\left\{ z^{-1} \right\}\] <p>iff its formal Borel transform</p> \[\hat{\phi}=\mathcal{B}\tilde{\phi}\] <p>has infinite radius of convergence and defines an entire function (functions that are finite except at infinite points) of bounded exponential type, i.e. there exists $A,c&gt;0$ such that</p> \[\left\lvert \hat{\phi}(\zeta) \right\rvert \leq A e^{ c\left\lvert \zeta \right\rvert } \text{ for all } \zeta.\] <p><strong>Proof.</strong> Let</p> \[\tilde{\phi}=\sum_ {n\geq 0}a_ {n}z^{-n-1}.\] <p>It is convergent iff there exists $A,c&gt;0$ such that $\left\lvert a_ {n} \right\rvert\leq Ac^{n}$ for all $n\in\mathbb{N}$. If it is so, then</p> \[a_ {n}\zeta^{n} / n! \leq \frac{A}{n!} \left\lvert c\zeta\right\rvert^{n}\] <p>and the conclusion follows.</p> <p>The converse can be proofed with the help of Cauchy inequality, which we will not list here.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="PureMath"/><category term="CategoryTheory"/><category term="Notes"/><summary type="html"><![CDATA[Introduction]]></summary></entry></feed>