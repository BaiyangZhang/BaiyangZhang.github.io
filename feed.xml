<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://baiyangzhang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://baiyangzhang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-25T12:18:19+00:00</updated><id>https://baiyangzhang.github.io/feed.xml</id><title type="html">Baiyang Zhang</title><subtitle>A place dedicated to sharing insights and reflections on mathematics, physics, and social sciences. </subtitle><entry><title type="html">Introduction to Transseries Lecture 2</title><link href="https://baiyangzhang.github.io/blog/2023/Transseries-Lecture-2/" rel="alternate" type="text/html" title="Introduction to Transseries Lecture 2"/><published>2023-11-24T00:00:00+00:00</published><updated>2023-11-24T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Transseries-Lecture-2</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Transseries-Lecture-2/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>In history, formal power series are used extensively for finding the resolution of differential equations. If the resulting power series is convergent, it gives rise to a germ which can be analytically continued to (multi-valued) functions on a Riemann surface. However, very often, the power series we found from solving a differential equation is divergent, then it is not clear <em>a prior</em> how to attach reasonable sums to them.</p> <p>The modern theory of <code class="language-plaintext highlighter-rouge">resummation</code> was developed systematically by Stieltjes, Borel and Hardy, who invented some resummation methods which <em>are stable under the common operators of analysis</em>. Later, Poincare established the equivalence between computations with formal power series and asymptotic expansions. Newton, Borel and Hardy were all aware of the systematic aspects of their theories and they consciously tried to complete their framework so as to capture as much of analysis as possible. The great unifying theory nevertheless had to wait until the late 20-th century and Ecalle’s work on transseries and Dulac’s conjecture.</p> <hr/> <p>Transseries have found significant applications in various areas of physics, particularly in high-energy physics. They are employed as algebraic tools to investigate self-consistent Dyson–Schwinger equations, which are integral equations that arise in the field of quantum field theory, specifically in Yukawa theory and quantum electrodynamics <a href="https://www.sciencedirect.com/science/article/pii/S0003491616300793">1</a>. These equations are pivotal in understanding the interactions of particles and fields at a fundamental level.</p> <p>In the realm of general relativity, transseries are applied to asymptotic analysis. General relativity stands as one of the cornerstones of modern physics, governing the laws of gravitation and the dynamics of large-scale structures in the universe . By applying transseries in this domain, researchers can gain insights into the asymptotic behavior of gravitational fields and the dynamics of spacetime.</p> <p>Furthermore, transseries are used in the <em>extraction of non-perturbative physics from perturbation theory through resurgence and alien calculus</em>. Perturbation theory is a fundamental tool in quantum mechanics and quantum field theory, allowing for the approximation of complex systems. The non-perturbative effects are those that cannot be captured by perturbation theory alone, and transseries help to identify and understand these effects <a href="https://www.sciencedirect.com/science/article/pii/S0003491619301691">2</a>..</p> <p>Additionally, in the context of integrable, asymptotically free field theories, transseries have applications in studying the free energy of such systems when coupled to a conserved charge. These studies are significant in high-energy physics, particularly in understanding the thermodynamics and statistical mechanics of particle systems <a href="https://link.springer.com/article/10.1007/JHEP08%282022%29279">3</a>.</p> <p>These examples showcase the versatility and importance of transseries in advancing the understanding of fundamental physics, from the microscale of particle interactions to the macroscale of cosmic phenomena.</p> <p>I hope the information provided has sparked your interest in transseries. Now, let’s delve into the subject itself.</p> <hr/> <p>Define a ordered group ${\frak G}$ (frak G) of transmonomials. Define a differential field $\mathbb{T}$ of <code class="language-plaintext highlighter-rouge">transseries</code>. Transmonomials are generalizations of monomials in polynomials, by including exponential and logarithmic. In this note and that follows, we will consider the limit where $x\to \infty$.</p> <p>Let’s start with exponents first.</p> <p><strong>Log-free transmonomials.</strong> They are of form \(x^{b}e^{ L },\quad b\in \mathbb{R},\; L \in \text{large log-free transseries.}\)</p> <p>For example, the following are all log-free transmonomials, \(x^{-1},\; x^{\pi}x^{x^{\sqrt{ 2 }}-3x},\; e^{ \sum_ {i}x^{-1}e^{ x } },etc.\)</p> <p>The multiplication is defined in the obvious way. The group identity is just $1$.</p> <p>We define a binary relation $\gg$, read “far larger than”. Keep in mind that we assumed $x\to \infty$. So how does this “far larger than” work? We compare the exponents $e^{ L }$ first, whichever with the largest exponent $L$ is far larger than others; if they have same exponents, then we compare the power of $x$, namely $x^{b}$, whichever with larger $b$ is far larger then others. To be specific, \(x^{b_ {1}}e^{ L_ {1} } \gg x^{b_ {2}}e^{ L_ {2} }\quad \text{ if } L_ {1} &gt; L_ {2} \;\lor\; (L_ {1}=L_ {2}\;\land\; b_ {1}&gt;b_ {2} ),\) where $\lor$ is logic or. For example, $x^{-5}\gg x^{20}e^{ -x }$ since $x^{-5}=x^{-5}e^{ 0 }$ and $0&gt;-x$.</p> <p><strong>Log-free transseries.</strong> A log-free transseries $T$ is a formal sum of log-free monomials ${\frak g}$, \(T = \sum_ {i} c_ {i} {\frak g}_ {i},\quad c_ {i} \in \mathbb{R} .\) We require the order of transmonomials be such that, each ${\frak g_ {i}}$ is far smaller than all previous terms, namely they appear in descending orders. This is similar to the case of regular polynomials where we usually put the highest powers at first.</p> <p>The transseries $T$ is said to be <code class="language-plaintext highlighter-rouge">purely large</code> if all transmonomials ${\frak g}_ {i}$ are far larger than $1$ (not $0$), namely ${\frak g_ {i}}\gg 1 \;\forall i$. $T$ is said to be <code class="language-plaintext highlighter-rouge">small</code> if all ${\frak g}_ {i}\ll 1$ (why isn’t it called purely small?). The largest (in the sense of far larger than) transmonomial is called the <code class="language-plaintext highlighter-rouge">dominant term</code>, let’s call it $c_ {0}{\frak g}_ {0}$. If the dominant term has positive coefficients, $c_ {0}&gt;0$, then $T$ is said to be positive. This enables us to compare the size of two transseries $S,T$, we say $S&gt;T$ if $S-T&gt;0$. So we just need to compare their dominant terms.</p> <hr/> <p>We consider only transmonomials and transseries of “finite exponential height”. For example, we don’t want \(e^{ x^{x^{x\dots}} }.\)</p> <p>The <code class="language-plaintext highlighter-rouge">differentiation</code> of $T$ with respect to $x$ is defined the usual way.</p> <hr/> <p>Next let’s include logarithmic. $\log$ acting $m$ times is denoted $\log_ {m}x$ or $\log_ {(m)}x$, namely \(\log_ {(m)}x = \log \dots \log x,\quad m\; \log .\)</p> <p>A general transseries is obtained by substitution of some $\log_ {m}x$ for $x$ in a log-free transseries.</p> <p><em>Every nonzero transseries has a multiplicative inverse.</em> This is similar to formal power series.</p> <p><em>A lot of functions can now be regarded as a transseries</em>. For example, e hyperbolic sine is a two-term transseries.</p> <h2 id="formal-constructions">Formal Constructions</h2> <p>In mathematics, the move towards higher levels of formality entails adopting rigorous and precise language, definitions, and proofs, which brings clarity and precision, ensuring that mathematical concepts are universally understood and applied correctly. It allows for the development of solid, gap-free proofs, having a deeper understanding of mathematical structures and providing a robust foundation for complex theories. This precision in communication is critical in a global context, where scientists from different fields rely on universally recognized formalisms to understand each other effectively.</p> <p>However, this precision comes at a cost. It can make the subject less accessible to beginners (like myself), potentially hindering educational and interdisciplinary work. A focus on stringent formalism might even inhibit creative thinking, as the rigidity of formal proofs could constrain the exploratory, intuitive processes that often drive mathematical discovery. Moreover, the lengthy and detailed nature of formal proofs can make mathematical work less efficient, both in terms of personal understanding and communication with others. There’s also the risk of diminishing intuition, which is a crucial aspect of mathematical thought, particularly in the preliminary stages of research. It is definitely crucial to have a balance between concrete examples and general formalism, what is I hope to achieve in this note.</p> <hr/> <p>The set of monomials ${\frak G}$ form a field, which is also a group if we focus on multiplication alone. ${\frak G}$ is <em>not</em> finitely generated, to see this consider the finitely generated group with generator \(\mu_ {1},\mu_ {2},\dots,\mu_ {n},\) the generated group has elements of form \(\left\{ \mu_ {1}^{k_ {1}}\times \mu_ {2}^{k_ {2}}\times \dots \times \mu_ {n}^{k_ {n}} \,\middle\vert\, k_ {1},\dots,k_ {n} \in \mathbb{Z} \right\} .\) Note that the exponents must be integers.</p> <p>Let’s use capital letters to denote a set of indices, for example define \(K := (k_ {1},k_ {2},\dots,k_ {n})\) then \(\mu_ {1}^{k_ {1}}\dots \mu_ {n}^{k_ {n}} =: \mu^{K}.\)</p> <p>This will save some writing. The problem is that $\mu^{K}$ can also be interpreted as $\mu^{k_ {1}k_ {1}\dots k_ {n}}$, but it should be clear from the context.</p> <p>We will assume that all the generator $\mu \ll 1$. We will think of these as “ratios” between one term of a series and the next. A <code class="language-plaintext highlighter-rouge">ratio set</code> is a finite set of small monomials.</p> <p>Let $k \in \mathbb{Z}^{n}$ be an $n$-tuple of integers, it form a group under addition. Let $p$ be another such $n$-tuple, one say \(k \leq p \quad \text{ iff } k_ {i} \leq p _ {i} \;\forall\; i,\) where $k_ {i}$ is the $i$-th component of $k$.</p> <p>$J_ {m}$ is a partially ordered set. To be specific, a partially ordered set (or poset) is a set equipped with a binary relation that captures a certain level of order or precedence among its elements. This binary relation is denoted by $\leq$ and must satisfy the following properties for any elements $a, b$, and $c$ in the set:</p> <ol> <li><em>Reflexivity</em>: For all elements a in the set, $a\leq a$. In other words, every element is related to itself;</li> <li><em>Antisymmetry</em>: If $a \leq b$ and $b \leq a$, then $a = b$. This property ensures that <em>no two distinct elements are related in both directions</em>;</li> <li><em>Transitivity</em>: If $a \leq b$ and $b \leq c$, then $a \leq c$. This property means that if there’s an order relationship between $a$ and $b$, and another between $b$ and $c$, there’s also an order relationship between $a$ and $c$.</li> </ol> <p>A partially ordered set <strong>does not</strong> require every pair of elements to be comparable; that is, it’s possible for $a$ and $b$ to be in the set without $a\leq b$ or $b \leq a$ being true. This distinguishes partially ordered sets from <code class="language-plaintext highlighter-rouge">totally ordered sets</code>, where <strong>every pair of elements is comparable</strong>.</p> <p>For $m\in \mathbb{Z}^{n}$, define \(J_ {m} := \left\lbrace k \in \mathbb{Z}^{n} \,\middle\vert\, k\geq m \right\rbrace .\) Apparently $m \in J_ {m}$. The sets $J_ {m}$ will be used to define <code class="language-plaintext highlighter-rouge">grids</code> of monomials. For example, if \(\mu_ {1} = \frac{1}{x},\quad \mu_ {2}=e^{ -x }\) comprise the ratio group (recall that each element of a ratio group is required to be small), then we can define a <code class="language-plaintext highlighter-rouge">grid</code> (about which we will say more later) \(\left\lbrace \mu^{k} \,\middle\vert\, k\in J_ {(-1,2)} \right\rbrace\) which is the same as \(\left\lbrace \mu^{k}=\mu_ {1}^{k_ {1}} \cdot \mu_ {2}^{k_ {2}} \,\middle\vert\, (k_ {1},k_ {2})\geq (-1,2) \right\rbrace .\)</p> <p>In our convention, the set of natural numbers $\mathbb{N}$ include zero.</p> <hr/> <h3 id="dicksons-lemma">Dickson’s lemma</h3> <p>It turns out that the set $J_ {m}$ is <code class="language-plaintext highlighter-rouge">well-partially-ordered</code>, sometimes called <code class="language-plaintext highlighter-rouge">Noetherian</code>. A partially ordered set (poset) is said to be well-partially-ordered if it satisfies two conditions:</p> <ul> <li>It contains no <em>infinite strictly descending sequences</em>. This means there cannot be an infinite sequence of elements $a_1, a_2, a_3, \ldots$ in the set such that $a_1 &gt; a_2 &gt; a_3 &gt; \ldots$.</li> <li>It contains no <em>infinite antichains</em>. An <code class="language-plaintext highlighter-rouge">antichain</code> is a subset of the poset in which no two distinct elements are comparable. In a well-partially-ordered set, there cannot be an infinite set of elements where none are comparable to each other.</li> </ul> <p>On the other hand, a poset is called Noetherian if it satisfies the <strong>descending chain condition</strong> (<strong>DCC</strong>), which states that every descending sequence of elements eventually stabilizes. In other words, there cannot be an infinite strictly descending sequence of elements in the set.</p> <p>The primary difference between the two concepts is that being well-partially-ordered is a stronger condition than being Noetherian. While both require the absence of infinite strictly descending sequences (the Noetherian property), being well-partially-ordered also requires the absence of infinite antichains. Therefore, every well-partially-ordered set is Noetherian, but not every Noetherian set is well-partially-ordered.</p>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Introduction to Resurgence Lecture 2</title><link href="https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-Lecture-2/" rel="alternate" type="text/html" title="Introduction to Resurgence Lecture 2"/><published>2023-11-23T00:00:00+00:00</published><updated>2023-11-23T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence--Lecture-2</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-Lecture-2/"><![CDATA[<h3 id="an-example-by-poincare">An example by Poincare</h3> <p>To get some feeling about resurgence, let’s start with an example first given by Poincare. This example shows <strong>how an divergent series emerges from a function.</strong></p> <p>Fix $w\in \mathbb{C}$ and $\left\lvert w \right\rvert&lt;1$. Consider the series of functions of the complex variable $t$, \(\phi_ {k}(t) := \frac{w^{k}}{1+kt},\quad \phi(t):= \sum_ {k\geq 0} \phi_ {k}(t).\) This series is uniformly convergent on \(U:=C^{\ast } - \left\{ -1,-\frac{1}{2},-\frac{1}{3},\dots \right\} .\) Hence the sum $\phi$ is <code class="language-plaintext highlighter-rouge">holomorphic</code> in $U$. Actually $\phi$ is meromorphic on $\mathbb{C}^{\ast}$ (not on $\mathbb{C}$ since the origin would be a limiting point of the poles) with simple poles at $1 / \mathbb{N}$.</p> <p>We now show how this function $\phi$ gives rise to a divergent formal series when $t$ approaches $0$. The idea is to expand each $\phi_ {k}$ first in terms of $t$. For each $k \in \mathbb{N}$, we have a <em>convergent</em> Taylor expansion at $t=0$, \(\phi_ {k}(t) = w^{k}\sum_ {n\geq 0}(-1)^{n}(kt)^{n}, \quad \left\lvert t \right\rvert&lt; \frac{1}{k} .\)</p> <p>One might be tempted to recombine the (convergent) Taylor expansion of $\phi_ {k}$ to give $\phi(t)$. It amounts to considering the well-defined <strong>formal series</strong> \(\tilde{\phi}(t) := \sum_ {n\geq 0}(-1)^{n} b_ {n} t^{n}, \quad b_ {n}:= \sum_ {k\geq 0}k^{n} w^{k}.\) We see that $b_ {n}$ is convergent since \(\lim_{ k \to \infty } \frac{(k+1)^{n}w^{k+1}}{k^{n}w^{k}} = w &lt;1 \text{ by construction}.\)</p> <p>However, it turns out that <strong>this formal series is divergent!</strong></p> <p>To see this, make the substitution $w = e^{ s }$. Then, since $\text{Re }w &lt;1$, we have \(b_ {0}=(1-w)^{-1} = (1-e^{ s })^{-1}\) and \(b_ {n} = \left( w \frac{d}{dw} \right)^{n}b_ {0} = \left( \frac{d}{ds} \right)^{n} b_ {0}.\) There is an easy way to tell if a series has non-zero radius of convergence, by some kind of a “dominance criterion”. If the series of study $a_ {n}$ is dominated by $AB^{n}$ where $A,B$ are real and $A,B&gt;0$, namely for all but finite $n$ we have $\left\lvert a_ {n} \right\rvert \leq AB^{n}$. Then the formal series \(F(\xi) := \sum(-1)^{n} a_ {n} \frac{\xi^{n}}{n!}\) would have infinite radius of convergence. <strong>$F$ can be seen as a map of the formal series to a function of $\xi$, note that we have inserted a factor of $1 / n!$ into the sum to make is more convergent</strong>. In our case of $b_ {n}$, we see that \(F(\xi) = \sum(-1)^{n} b_ {n} \frac{\xi^{n}}{n!} = \sum(-1)^{n} \frac{\xi^{n}}{n!}\left( \frac{d}{d s} \right)^{n} b_ {0}(s) = b_ {0}(s-\xi) = \frac{1}{1-e^{ s-\xi }} .\) This functions has finite radius of convergence, since the last expression in the equation above diverges at $\xi=s+2\pi i \mathbb{Z}$. The radius of convergence is not infinite! Thus $\tilde{\phi}$ must have zero radius of convergence.</p> <hr/> <p>Now the question is to understand the relation between $\tilde{\phi}$ and $\phi$. We shall see in this note that the <code class="language-plaintext highlighter-rouge">Borel-Laplace</code> summation is a way of going from the divergent formal series $\tilde{\phi}$ to the finite function $\phi$. $\tilde{\phi}$ is actually the <code class="language-plaintext highlighter-rouge">asymptotic expansion</code> of $\phi(t)$ at $t=0$. We shall explain what it means next.</p> <p>We can already observe that the moduli of the coefficients $b_ {n}$ satisfy \(\left\lvert b_ {n} \right\rvert &lt;AB^{n} n! ,\quad n \in \mathbb{N}\) for some $A,B&gt;0$. Such inequalities are called <code class="language-plaintext highlighter-rouge">1-Gevrey estimates</code> for the formal series $\tilde{\phi}(t)=\sum b_ {n}t^{n}$.</p> <p>We remark that, since the original function $\phi(t)$ is not holomorphic (nor meromorphic) in any neighborhood of 0, because of the accumulation at the origin of the sequence of simple poles $- \frac{1}{k}$. Thus it would be very surprising to find a positive radius of convergence for $\tilde{\phi}$.</p> <hr/> <p>Resurgence theory can also be used to study power series of the form \(\sum_ {i} \left( \sum_ {j} a_ {ij}t^{j} \right) e^{ -c_ {j} / t }\) note that the variable $t$ appears at two places, once in the series and once in the exponent. The exponent term is the small correction that is invisible to Taylor expansion at $t=0$, and the formal series in the parenthesis diverges.</p> <p>There are many examples of such series in physics. For example, the series could represent the solution of an ordinary differential equation, or the value of some integral, or the perturbative results. In the below is a list of where you might find series like this:</p> <ul> <li>Normal forms for dynamical systems</li> <li>Gauge theory of singular connections</li> <li>Quantization of symplectic and Poisson manifolds</li> <li>Floer homology and Fukaya categories</li> <li>Knot invariants</li> <li>Wall-crossing and stability conditions in algebraic geometry</li> <li>Spectral networks</li> <li>WKB approximation in quantum mechanics</li> <li>Perturbative expansions in quantum field theory (QFT).</li> </ul> <p>There has been some recent work in the physics literature suggesting the possibility that the divergent series obtained from the perturbative expansion may have more information about the true nature of the QFT that one might naively expect.</p> <p>In the next note we will dive into the details of resurgence theory, beginning with the differential algebra $(\mathbb{C}[[1 / z]],\partial)$.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="PureMath"/><category term="CategoryTheory"/><category term="Notes"/><summary type="html"><![CDATA[An example by Poincare]]></summary></entry><entry><title type="html">Introduction to Resurgence Lecture 3</title><link href="https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-Lecture-3/" rel="alternate" type="text/html" title="Introduction to Resurgence Lecture 3"/><published>2023-11-23T00:00:00+00:00</published><updated>2023-11-23T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-Lecture-3</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-Lecture-3/"><![CDATA[<h3 id="the-differential-algebra">The differential algebra</h3> <p>It will be convenient for us to set $z = 1/t$ in order to “work at $\infty$” rather than at the origin, since we will often talk about compactified spaces. This means that we shall deal with expansions involving <em>non-positive</em> integer powers of the indeterminate. We denote the set of all the <code class="language-plaintext highlighter-rouge">formal power series</code>, i.e., polynomials in $1 / z$ by \(\mathbb{C}[\![z^{-1}]\!] = \left\{ \phi=\sum_ {n\geq 0}a_ {n}z^{-n} \,\middle\vert\, a_ {i} \in \mathbb{C} \right\}.\) This is a vector space with basis $1, z^{-1},z^{-2}$, etc. It is also an algebra when we take into account the Cauchy product \(\left( \sum a_ {n}z^{-n} \right) \left( \sum b_ {n} z^{-n} \right) = \sum c_ {n} z^{-n}, \quad c_ {n} = \sum_ {p+q=n} a_ {p} b_ {q}.\)</p> <p>The derivation \(\partial = \frac{d}{d z}\) further makes it a <em>differential algebra</em>, which simply means $\partial$ is a linear map which satisfied the Leibniz rules.</p> <p>This is the derivative in terms of $z$, it is natural to ask what is the derivative in terms of $t$. The answer is straightforward, \(\partial = \frac{d}{d z} = \frac{d}{d t^{-1}} = \frac{d}{-t^{-2}dt} =-t^{2} \frac{d}{d t} .\) Then, in mathematical terminology, there is an isomorphism of differential algebra between $(\mathbb{C}[[z^{-1}]],\partial)$ and $(\mathbb{C}[[t]],\partial)$.</p> <hr/> <p>The <code class="language-plaintext highlighter-rouge">standard valuation</code>, or sometimes called the <code class="language-plaintext highlighter-rouge">order</code>, on $\mathbb{C}[[z^{-1}]]$ is the map \(\text{val}: \mathbb{C}[\![z^{-1}]\!] \to \mathbb{N} \cup \infty\) defined by $\text{val }(0)=\infty$ and \(\boxed{ \text{val }(\phi) := \text{min } \left\{ n\in \mathbb{N} \,\middle\vert\, a_ {n}\neq 0 \right\} ,\quad \phi =\sum a_ {n} z^{-n} \neq 0. }\)</p> <p>For $\nu \in\mathbb{N}$, we will use the notation \(z^{-\nu}\mathbb{C}[\![z^{-1}]\!] = \left\{ \sum_ {n\geq \nu} a_ {n}z^{-n} \,\middle\vert\, a_ {\nu},a_ {n+1},\dots \in \mathbb{C} \right\}.\)</p> <p>This is the set of all the complex polynomials in $z^{-1}$ such that the standard valuation is no less than $\nu$.</p> <p>From the viewpoint of the ring structure, ${\frak I} = z^{-1}\mathbb{C}[[z^{-1}]]$ is the maximal ideal of the ring $\mathbb{C}[[z^{-1}]]$. It is often referred to as the <em>formal series without constant term</em>.</p> <p>It is obvious that \(\text{val }(\partial \phi) \geq \text{val }(\phi)+1\) with equality iff there is no constant term.</p> <hr/> <p>With the help of the standard valuation, we can introduce the concept of <code class="language-plaintext highlighter-rouge">distance</code> into the ring of the formal series. Define \(d(\phi,\psi) := 2^{-\text{val }(\phi-\psi)},\quad \phi,\psi \in \mathbb{C}[\![z^{-1}]\!]\) as the distance between $\phi$ and $\psi$. It can only take discrete values, such as $1, 1 / 2, 1 / 4,$ etc.</p> <p>With the definition of distance, $\mathbb{C}[[z^{-1}]]$ becomes a <code class="language-plaintext highlighter-rouge">complete metric space</code>. The topology induced by this distance is called the <code class="language-plaintext highlighter-rouge">Krull topology</code> or the <code class="language-plaintext highlighter-rouge">topology of the formal convergence</code> (or the ${\frak I}$-adic topology). It provides a simple way of using the language of topology to describe certain algebraic properties.</p> <p>We mention that a sequence $\phi_ {n}$ of formal series is a Cauchy sequence iff for each $i\in\mathbb{N}$, the $i$-the coefficient is stationary, namely the $i$-th coefficient of $\phi_ {n}$ becomes a constant when $n$ is larger than certain natural number.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="PureMath"/><category term="CategoryTheory"/><category term="Notes"/><summary type="html"><![CDATA[The differential algebra]]></summary></entry><entry><title type="html">Note-on-Cutoff-Kinks</title><link href="https://baiyangzhang.github.io/blog/2023/Note-on-Cutoff-Kinks/" rel="alternate" type="text/html" title="Note-on-Cutoff-Kinks"/><published>2023-11-23T00:00:00+00:00</published><updated>2023-11-23T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Note-on-Cutoff-Kinks</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Note-on-Cutoff-Kinks/"><![CDATA[<p>Let $H’$ be the regularized Hamiltonian in the Kink sector, $H$ be that in the vacuum sector. Then $D_ {f}$ is the Morphism that maps from $H’$ to $H$. It should be invertible since there is no loss of information in the process, namely there should exist another map from $H$ to $H’$. Regard different sectors as objects in a category, this category is defined by a (classical) Lagrangian with a quantization functor (maybe), together with a lattice, or equivalently a momentum cutoff $\Lambda$. The map from $H$ to $H’$ is given by \(\boxed { H' = \mathcal{D}_ {f}^{\dagger} H \mathcal{D}_ {f}, }\) where $\mathcal{D}_ {f}$ is the shift operator defined by a function $f$, which usually corresponds to certain classical solitonic solutions.</p> <p>The</p>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Let $H’$ be the regularized Hamiltonian in the Kink sector, $H$ be that in the vacuum sector. Then $D_ {f}$ is the Morphism that maps from $H’$ to $H$. It should be invertible since there is no loss of information in the process, namely there should exist another map from $H$ to $H’$. Regard different sectors as objects in a category, this category is defined by a (classical) Lagrangian with a quantization functor (maybe), together with a lattice, or equivalently a momentum cutoff $\Lambda$. The map from $H$ to $H’$ is given by \(\boxed { H' = \mathcal{D}_ {f}^{\dagger} H \mathcal{D}_ {f}, }\) where $\mathcal{D}_ {f}$ is the shift operator defined by a function $f$, which usually corresponds to certain classical solitonic solutions.]]></summary></entry><entry><title type="html">Introduction to Resurgence Lecture 1</title><link href="https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-and-Transseries-1/" rel="alternate" type="text/html" title="Introduction to Resurgence Lecture 1"/><published>2023-11-22T00:00:00+00:00</published><updated>2023-11-22T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-and-Transseries-1</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Introduction-to-Resurgence-and-Transseries-1/"><![CDATA[<h3 id="motivation">Motivation</h3> <p>Why do I want to spend time on this subject? Because they are super interesting!</p> <p>But I should maybe say more about it, so that in the future if I were to apply for some research grant, when someone who knows absolutely nothing about resurgence and its application but who decides whether to give me the money, asks me why is this project important, what use does it have and, eventually, why should I give you the money, then I can come back here and just copy the answer. I would say that god knows I have already wasted too much time on grant applications… but thank god I am atheist.</p> <p>The following is an incomplete list of the potential applications of resurgence theory.</p> <ul> <li>Normal forms for dynamical systems</li> <li>Gauge theory of singular connections</li> <li>Quantization of symplectic and Poisson manifolds</li> <li>Floer homology and Fukaya categories</li> <li>Knot invariants</li> <li>Wall-crossing and stability conditions in algebraic geometry</li> <li>Spectral networks</li> <li>WKB approximation in quantum mechanics</li> <li><strong>Perturbative expansions in quantum field theory (QFT)</strong></li> </ul> <p>The most surprising result, at least for me, of resurgence theory in QFT is that one can uncover the non-perturbative results from perturbative expansion alone! Usually to find the non-perturbative results one need to use anything but perturbative results, such as the topology of the vacuum manifold, the homotopy of the solutions to the equation of motion (instanton solutions, etc.), on and on. But resurgence theory lets us to get the non-perturbative results, for instance the contribution of instantons, from analytical continuation of the perturbative results! On the one hand, it is like black magic; on the other hand, I guess I shouldn’t be too surprised since if we know all the perturbative expansions then we know everything about the equation of motion, which eventually contains all the non-perturbative results, so in principal the perturbative expansion should be able to generate the non-perturbative results. But that is only in principal. It is still jaw-dropping to see it actually happen.</p> <p>And I guess it is impossible to make sense out of perturbation theory <strong>without</strong> knowing some of the resurgence theory. After all, is we consider enough terms in perturbative expansion, the power series in coupling actually diverges, so why would it make any sense to just consider the first few terms? Claiming they give the dominant results would also be ridiculous. The answer lies in resurgence theory.</p> <hr/> <p>H. Poincare mentions the so-called “a kind of misunderstanding between geometers and astronomers about the meaning of the word convergence”, He proposed a simple example, the two series \(\sum \frac{1000^{n}}{n!} \text{ and }\sum \frac{n!}{1000^{n}},\) Poincare says that for geometers, namely mathematicians in his time, the first one converges because at large $n$ the terms gets smaller and smaller. But for astronomers the first one is as good as divergent since the next terms doesn’t get smaller until $n$ is larger than $1000$. For them the second series diverges because the first $1000$ terms decreases quickly.</p> <p>He then proposes to reconcile both points of view by clarifying the role that divergent series (in the sense of geometers) can play in the approximation of certain functions. This is the origin of the modern theory of asymptotic expansion.</p> <hr/> <p>In this note we shall focus on <code class="language-plaintext highlighter-rouge">formal power series</code>, such as the Stirling series. Thus the previous example should be written as \(\sum \frac{1000^{n}}{n!}t^{n} \text{ and }\sum \frac{n!}{1000^{n}}t^{n}\) where the first one has <strong>infinite</strong> <strong>radius of convergence</strong> while the second one has <strong>zero radius of convergence</strong>. For us, <code class="language-plaintext highlighter-rouge">divergent series</code> will usually mean a formal power series with zero radius of convergence.</p> <p>First we will speak of the <code class="language-plaintext highlighter-rouge">Borel-Laplace sumamtion</code>, which obtains a function from a divergent formal series. The relation between the obtained function and the original power series is an example of <code class="language-plaintext highlighter-rouge">asymptotic expansion of Gevrey type</code>. We shall also introduce the phenomenon for which J. Ecalle coined the name <code class="language-plaintext highlighter-rouge">resurgence</code> at the beginning of the 1980s.</p> <hr/> <h3 id="analytic-continuation-and-monodromy">Analytic Continuation and Monodromy</h3> <p><code class="language-plaintext highlighter-rouge">Formal power series</code> is a generalization of normal power series, or polynomial, in the sense that we consider a power series of infinite order and don’t care if it is convergent or not. Provided a ring $R$, consider the set of formal power series in $X$, denoted by $R[[X]]$, is another ring, in the same sense that all the polynomials over $R$ forms another ring (for example, multiply one polynomial to another gives as another polynomial). It is called the <strong>ring of formal power series in the variable $X$ over $R$</strong>.</p> <p>We say a complex-valued function $f:\Omega \to \mathbb{C}$ is <code class="language-plaintext highlighter-rouge">analytic</code> if $f$ is represented by a convergent power series expansion on a neighborhood around every point $a\in\Omega$.</p> <p>We say a complex-valued function $f:\Omega \to \mathbb{C}$ is <code class="language-plaintext highlighter-rouge">holomorphic</code> iff it satisfied Cauchy-Riemann relation, which is equivalent to $\partial f/\partial \overline{z}=0$ . If we regard $z$ and $\overline{z}$ as independent variables, a holomorphic function $f$ is only a function of $z$ not $\overline{z}$.</p> <p>A differential manifold is a topological space (given by closed sets and all that stuff) with differential structure, which practically means that you can find a way to do derivatives on the manifold. A n-Dimensional real (Complex) manifold is locally homeomorphic to $\mathbb{R}^N (\mathbb{C}^n)$, plus the condition that the transition from one chart (coordinate system) to another is <code class="language-plaintext highlighter-rouge">homeomorphic (holomorphic)</code> and vice versa.</p> <p>An <code class="language-plaintext highlighter-rouge">open disk</code> of radius $r$ around $z_0$ is the set of points $z$ on $\mathbb{C}$ that satisfies \(|z-z_0| &lt; r.\) A <strong>open deleted disk of radius $r$ around $z_0$</strong> is the set of points with \(0 &lt; |z-z_0| &lt; r.\) a deleted disk is also called a punctured disk.</p> <p>A <code class="language-plaintext highlighter-rouge">complex atlas</code> on a 2-dimensional manifold is a set of holomorphically compatible charts which cover the manifold. Two complex charts $\mathfrak{U}$, $\mathfrak{U}’$ are said to be <code class="language-plaintext highlighter-rouge">analytically equivalent</code> if any atlas in $\mathfrak{U}$ is holomorphically compatible with any other atlas in $\mathfrak{U}’$.</p> <p>By a <code class="language-plaintext highlighter-rouge">complex structure</code> on a manifold, we mean an equivalent class of analytically equivalent complex atlases on the manifold. If we give a manifold a complex atlas, then we have given it a complex structure.</p> <p>A Riemann surface is a pair $(X,\Sigma)$ where $X$ is a connected 2-dimensional manifold and $\Sigma$ is a complex structure on $X$. The simplest Riemann surface is the complex plane itself.</p> <hr/> <ul> <li>$\mathbb{C} P^n$ Model: The (n+1)-tuple $z = (z^0,\cdots,z^n)$ defines a vector in space $\mathbb{C}^{n+1}$. Define a equivalence relation $\sim$ between two vectors, \((u^0,\cdots,u^n) \sim (v^0,\cdots,v^n) \text{ if } \exists \lambda\neq 0 \in \mathbb{C} \text{ so that } \mathbf{u} = \lambda \mathbf{}{v}\) then \(\mathbb{C} P^{n} \equiv (\mathbb{C}^{n+1}-\{0\})/\sim,\) and the $n+1$ numbers are call <code class="language-plaintext highlighter-rouge">homogeneous coordinates</code> and is denoted by $[z^0,\cdots,z^n]$. We can make one of them constantly equal to 1, then only the rest are really coordinates, it is called <code class="language-plaintext highlighter-rouge">inhomogeneous coordinates</code>.</li> </ul> <p><code class="language-plaintext highlighter-rouge">Meromouphic functions</code> are functions holomorphic except at poles.</p> <p>A <code class="language-plaintext highlighter-rouge">domain</code> in $\mathbb{C}$ is a connected non-empty open subset of $\mathbb{C}$.</p> <hr/> <p><strong>Riemann Sphere</strong></p> <p>There are two ways to think of $\overline{C} \equiv \mathbb{C} \cup {\infty}$, i.e. the complex plane compactified, by adding a point called infinity, $\infty$ is not included in $\mathbb{C}$.</p> <ul> <li>complex projective plane $\mathbb{C}P^1$.</li> <li>a 2D sphere $\mathbb{S}^2$. The coordinates is given by the stereographic projection, except for the north pole $N$, $\pi : \mathbb{S}^2-{N} \to \mathbb{C}$.</li> </ul> <p>The space $\overline{\mathbb{C}}$ has the structure of e Riemann surface and it is called the <code class="language-plaintext highlighter-rouge">Riemann sphere</code>. We can introduce two charts on the Riemann sphere, \(\mathfrak{U}_1 = \mathbb{C},\quad \mathfrak{U}_2 = \mathbb{C}^\ast \cup \{\infty\}\) where $\mathbb{C}^\ast$ is the punctured complex plane, $\mathbb{C}^\ast \equiv \mathbb{C} - {0}$.</p> <p><strong>Theorem.</strong> A function is meromorphic on $\mathbb{C}$ iff its restriction on $\mathbb{C}$ is a rational function.</p> <p>By the restriction of a function, we mean that to restrict the domain so that the it is well defined, no singularities. For example, the function $f:x\to 1/x$ has a singularity at $x=0$, then if we want something which is just like $f$ but has no singularity, we can just restrict the domain to $\mathbb{R} - {0}$, which is said to be a restriction of $f$.</p> <p>A <code class="language-plaintext highlighter-rouge">germ</code> of functions at a point $\mathbb{C}$ is a set of function defined in the neighborhood of $a$ which all have the same Taylor expansion. A more mathematical definition is as following.</p> <p>Use $\mathcal{O}(a)$ to denote the set of functions which are defined in a neighborhood of $a$ and is holomorphic at $a$. Define an equivalence relation $\sim$ so that if $f\sim g$ for $f,g \in \mathcal{O}(a)$, then $f,g$ are identical on some neighborhood of a. The equivalence class is called a germ of holomorphic functions at $a$.</p> <p>Intuitively, the germ of a function tells us how a function behaves locally at point $a$.</p> <hr/> <p>The <code class="language-plaintext highlighter-rouge">Fundamental Uniqueness Theorem (FUT)</code> for holomorphic functions:</p> <p><strong>Theorem.</strong> If $f,g$ are holomorphic functions on a domain $D\in\mathbb{C}$ and $f \sim g$ for some point $a\in D$, namely f and g are in the same germ at a, then f is identical to g on $D$.</p> <p>The germ of $f$ will be denoted by $\overline{f}$, if there is no ambiguity about around which point it is defined.</p> <hr/> <p><strong>Analytic Continuation, Monodromy</strong></p> <p>First we introduce the analytic continuation in a different way, more formal and more mathematical. We begin by defining <code class="language-plaintext highlighter-rouge">pairs</code>. The idea is that, a function is not only defined by the values but also the domain on which it is defined.</p> <p>A <code class="language-plaintext highlighter-rouge">pair</code> $(U,f)$ is a non-zero open disk $U\subset \mathbb{C}$ (why does it has to be open? I don’t know.) and a function, holomorphic on $U$, such that the radius of $U$ is the maximum radius of convergence of the series expansion of $f$. The center of the pair is the center of $U$. Usually $U$ will stop at some singular point.</p> <p>Another concept is adjacency, two pairs $(U,f)$ and $(V,g)$ are said to be <code class="language-plaintext highlighter-rouge">adjacent</code> if $U\cap V \neq 0$ and $f \equiv g$ on $U\cap V$.</p> <p>If there is a <code class="language-plaintext highlighter-rouge">finite</code> sequence of pairs $(U_i,f_i),\quad i = 0,1,\cdots, n$ so that for all $i$, $(U_i,f_i)$ is adjacent to $(U_{i\pm 1},f_{i\pm 1})$, then $(U_0,f_0)$ is said to be the analytical continuation of $(U_n,f_n)$.</p> <p>We can define a analytical continuation along a curve $\gamma: [0,1] \to \mathbb{C}$. The definition is kind of intuitive so I will skip it here. Now the question is, is the analytical continued function $(U_n,f_n)$ dependent on the path? The answer is the monodromy theorem:</p> <p><strong>Theorem.</strong> If the two path are homotopic, then the analytical continuation results to the same functions.</p> <p>If in any doubt, just think of the $\ln{z}$ function.</p> <hr/> <p><strong>Linear Differential System</strong></p> <p>A <code class="language-plaintext highlighter-rouge">linear system</code> is short for a complex linear ordinary differential system. A linear system of order p is a system with p first order ordinary differential equations.</p> <p>\(\frac{dy(x)}{dx} = A(x) y(x),\quad y(x) = \begin{pmatrix} y_1(x)\\ \vdots \\ y_p(x) \end{pmatrix}\) where $y(x)$ is a column vector of functions, and $A$ is the $p\times p$ coefficient matrix. The system is referred to as $(S)$.</p> <p>We used $\mathbb{C}(x)$ to denote the field of complex rational functions, and $\mathscr{M}(D)$ the field of meromorphic functions on domain $D$, and $\mathscr{O}(D)$ the ring of holomorphic functions on domain $D$.</p> <p>A <code class="language-plaintext highlighter-rouge">fundamental solution</code> of $(S)$ is a $p\times p$ matrix whose columns are $\mathbb{C}$-linear independent solutions to $(S)$.</p> <p>The <code class="language-plaintext highlighter-rouge">Wronskian</code> for $n$ functions are defined to be \(W(f_1,\cdots, f_n)(x) \equiv \begin{vmatrix} f_1(x) &amp; \cdots &amp; f_n(x)\\ f'_1(x)&amp; \cdots &amp; f'_n(x)\\ \cdots \\ f^{(n-1)}(x) &amp; \cdots &amp; f^{(n-1)}(x) \end{vmatrix}.\)</p> <p>Let $\Sigma= { a_1,\cdots,a_n }\subset \overline{\mathbb{C}}$ be the set of singular points of $(S)$. Let $U_\Sigma \equiv \overline{\mathbb{C}}\backslash \Sigma$.</p> <p>Recall a nice property of Wronskian: Let $\mathscr{D}$ a domain in $U_\Sigma$, $W$ a $p\times p$ solution of $(S)$, the following are equivalent:</p> <ul> <li>W is a fundamental solution of $(S)$</li> <li>$\det{W(x)}\neq 0$ for some $x \in \mathscr{D}$</li> <li>$\det{W(x)}\neq 0$ for all $x \in \mathscr{D}$</li> </ul> <p>In other words, the Wronskian is either nonzero on the entire domain, or identically zero.</p> <hr/> <p><strong>Differential Galois Theory</strong></p> <p>A <code class="language-plaintext highlighter-rouge">differential field</code> $(k,\partial)$ is a field $k$ with derivation. A \hl{differential homomorphism} $\phi:(k_1,\partial)\to(k_2,\partial)$ from $k_1$ to $k_2$ is a field homomorphism that commutates with $\partial$. A triple $(k_1, \phi, k_2)$ is called a differential extension. $k_2$ is also called a differential extension of $k_1$.</p> <p>A differential system \(\partial y = A y\) where $A$ is a $p \times p$ matrix.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="Math"/><category term="Transseries"/><category term="Notes"/><summary type="html"><![CDATA[Motivation]]></summary></entry><entry><title type="html">Categorical Equivalence and the Renormalization Group</title><link href="https://baiyangzhang.github.io/blog/2023/Categorical-Equivalence-and-the-Renormalization-Group/" rel="alternate" type="text/html" title="Categorical Equivalence and the Renormalization Group"/><published>2023-11-18T00:00:00+00:00</published><updated>2023-11-18T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Categorical-Equivalence-and-the-Renormalization-Group</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Categorical-Equivalence-and-the-Renormalization-Group/"><![CDATA[<p><em>Disclaimer: Nothing in this note is original.</em></p> <p>A short introduction about sheaf can be found <a href="https://www.mathlimbo.net/blog/2023/Basic-Algebraic-Geometry-6/">here</a>.</p> <h4 id="gauged-linear-sigma-model">Gauged linear sigma model</h4> <p>A gauged linear sigma model (GLSM) is a type of quantum field theory that incorporates both gauge symmetry and a set of scalar fields which interact with each other through a potential that is usually taken to be a function of the sum of the squares of the scalar fields. These models are a generalization of the linear sigma models that were originally introduced to describe the dynamics of pions in particle physics.</p> <p>The term “linear” in this context refers to the fact that the potential energy function for the scalar fields is quadratic, at least around the vacuum of the theory. This means that the interactions can be written in terms of fields and their derivatives in a polynomial form that does not exceed second degree when expanded about the vacuum expectation value.</p> <p>Often, GLSMs are discussed in the context of supersymmetry. This means that for every boson (like the scalar fields and gauge fields in the model), there is a corresponding fermion. Supersymmetric GLSMs are particularly interesting for string theory and the study of Calabi-Yau manifolds.</p> <p>In essence, the gauged linear sigma model allows for the study of a wide array of phenomena including spontaneous symmetry breaking, phase transitions, and the dynamics of topological defects. By gauging a symmetry, you add a rich structure to the model that includes interactions mediated by gauge bosons and the possibility of incorporating richer topological properties.</p> <p>A key feature of GLSMs is that they can have a “Higgs phase,” where the gauge symmetry is spontaneously broken and the gauge bosons acquire mass via the Higgs mechanism, and a “Coulomb phase,” where the gauge symmetry is unbroken and the gauge bosons remain massless. Transitions between these phases can often be studied using GLSMs, providing insights into non-perturbative aspects of quantum field theories.</p> <h4 id="toric-variety">Toric variety</h4> <p>We all know what a variety is. So what is a toric variety?</p> <p>A toric variety is a type of variety that is built from combinatorial objects known as fans, which are collections of cones. Toric varieties are particularly nice because they provide a bridge between algebraic geometry and combinatorics, and they are also rich in geometric properties.</p> <p><strong>Algebraic Torus.</strong></p> <p>Start with an algebraic torus $( \mathbb{C}^* )^n$, which is the product of $n$ copies of the multiplicative group $\mathbb{C}^* = \mathbb{C} \setminus {0}$. This group acts on itself by multiplication, and this action can be extended to act on other algebraic varieties.</p> <p><strong>Fans and Cones.</strong></p> <p>A fan is a set of cones (not in the usual sense of solid geometry, but in the sense of vector spaces). These cones are generated by a set of vectors in $\mathbb{R}^n$ that satisfy certain combinatorial conditions – they must be strongly convex (no line can be contained in a cone), and the intersection of any two cones in the fan must be a face of each. The dimension of the toric variety is equal to the dimension of the space where the fan lives.</p> <p><strong>Construction of Toric Varieties.</strong></p> <p>Each cone in the fan corresponds to an affine variety that is invariant under the action of a subtorus of $( \mathbb{C}^* )^n$. The toric variety is constructed by “gluing” these affine varieties together in a way that corresponds to how their cones intersect.</p> <p><strong>Divisors and Line Bundles.</strong> Toric varieties are also interesting because there is a correspondence between the combinatorial data of the fan and the divisor class group of the variety. This makes the calculation of certain cohomological and geometric properties much simpler than in general varieties.</p> <p>A key feature of toric varieties is that they come with a lot of symmetry – namely, the action of the torus. This symmetry makes them easier to study and gives them a rich structure. Toric varieties have applications in many areas of mathematics, including combinatorics, symplectic geometry, and mirror symmetry in string theory. They serve as local models in the Minimal Model Program and are also used in the study of singularities.</p> <p>For a concrete example, consider the complex projective space $\mathbb{CP}^n$, which is a toric variety. The fan for $\mathbb{CP}^n$ consists of cones that correspond to the origin and the standard basis vectors in $\mathbb{R}^n$, as well as all their faces. The rich interplay between the algebraic and combinatorial structures of toric varieties makes them a fascinating subject of study in modern algebraic geometry.</p> <h4 id="stacks">Stacks</h4> <p>Let $\mathcal{T}$ be the category of topological spaces, where the objects are topological spaces and the morphisms are continuous maps.</p> <p>A <strong>groupoid fibration,</strong> or a category fibered <em>in</em> groupoids, over $\mathcal{T}$ is another category (which is a groupoid) $\mathcal{X}$, together with a functor \(F: \mathcal{X} \to \mathcal{T}\) such that there exists a pullback and the pull back is unique. First, some terminologies. If the functor maps $X \in \mathcal{X}$ to $T \in \mathcal{T}$ then we say that $X$ lies over $T$, or that $X$ is a $\mathcal{X}$-family parametrized by $T$, and we write $X / T$. If the morphism $\eta: X \to Y$ is mapped by $F$ to $f: T\to S$ then we say that $\eta$ lies over $f$, or $\eta$ <em>covers</em> $f$. The requirement of pullback essentially says that for every $\mathcal{X}$-family $X / T$ and a morphism $T’ \to T$ there exists another $\mathcal{X}$-family $X’ / T’$ such and such. And this pullback is essentially unique. $X’ / T’$ is said to be the pullback of $X / T$ via the continuous map $f$. We use notations \(X' = f^{\ast } X \text{ or } X' = X \mid _ {T'}.\)</p> <p>Groupoid fibration captures two notions at once:</p> <ul> <li>isomorphism of families. By the arrows in $\mathcal{X}$ (Since $\mathcal{X}$ is a groupoid).</li> <li>pullback.</li> </ul>]]></content><author><name>Baiyang Zhang</name></author><category term="Geometry"/><category term="Frankel"/><summary type="html"><![CDATA[Disclaimer: Nothing in this note is original.]]></summary></entry><entry><title type="html">Homotopy, Extension, and some topology of SU(N)</title><link href="https://baiyangzhang.github.io/blog/2023/Homotopy-Extension-SU(N)/" rel="alternate" type="text/html" title="Homotopy, Extension, and some topology of SU(N)"/><published>2023-11-18T00:00:00+00:00</published><updated>2023-11-18T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Homotopy-Extension-SU(N)</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Homotopy-Extension-SU(N)/"><![CDATA[<p><em>Disclaimer: Nothing in this note is original.</em></p> <h2 id="homotopies-and-extensions">Homotopies and Extensions</h2> <p>The problem of extension in homotopy typically deals with the following question: given a continuous map defined on a subspace of a topological space, can it be extended to a continuous map on the entire space? Take the extension of a function on a sphere for example. Let $\mathbb{S}^{1}$ be the equator of a $\mathbb{S}^{2}$, and a continuous map $f$ define on $\mathbb{S}^{1}$: \(f: \mathbb{S}^{1} \to \mathbb{R}.\) The extension problem would be, can you find a function \(F: \mathbb{S}^{2} \to \mathbb{R}\) such that the restriction of $F$ on $\mathbb{S}^{1}$ gives $f$? The ability to extend $f$ depends on its homotopy properties. For instance, if $f$ represents a simple loop around the equator, it may or may not be extendable based on how it “wraps around” the sphere. Certain topological features of the function $f$, such as its winding number or degrees, can serve as <strong>obstructions</strong> to extending it over the entire sphere. In this particular example, $f$ is extendable to the whole sphere if it has zero winding, otherwise the non-zero winding will cause some singularity when extending it to the whole $\mathbb{S}^{2}$.</p> <hr/> <p>Now, consider a sphere of arbitrary dimension $n$, and consider it as the boundary of some $n+1$ dimensional disk $\mathbb{D}^{n+1}$ (a ball if $n&gt;0$). Let $M$ be a $n$ dimensional manifold. We have the following simple observation.</p> <p><strong>Extension Theorem.</strong> The function \(f:\mathbb{S}^{k} \to M^{n}\) is homotopic to a constant map iff $f$ can be extended to a map of the ball \(F: \mathbb{D}^{k+1} \to M.\) The proof is rather intuitive, just think of the homotopy as shrinking $\mathbb{S}^{k}$ all the way to the center of the circle.</p> <p>The extension theorem is important when discussing <strong>defects</strong>.</p> <hr/> <h2 id="covering-homotopy">Covering homotopy</h2> <p>Let $\pi: E \to M$ be a vector bundle and $f: W \to E$ be a map of a space $W$ into the bundle space $E$. Then the composition \(W \xrightarrow{f}E \xrightarrow{\pi} M\) defines a map $\overline{f}$ from $W$ to $M$, \(\overline{f} := \pi \,\circ\, f.\)</p> <p>Now, let $\overline{F}: \overline{f}\to \overline{f_ {1}}$ be a homotopy (a series of continuous functions parametrized by $t$ from $\overline{f}$ to $\overline{f_ {1}}$), we claim that we can <strong>cover the homotopy</strong> $\overline{F}$ by a homotopy of the original map $F: f\to f_ {1}$. That is, there is a map \(F: W\times [0,1] \to E\) such that for $w \in W$, \(F(w,0)=f(w),\quad F(w,1)=f_ {1}(w).\) The trick to prove the existence of covering of a homotopy is to find a way to lift the homotopy from $M$ to $E$. To be specific, consider a fixed point $w \in W$ and look at the curve \(\overline{C}:t \in [0,1] \to \overline{F}(w,t)\) in $M$. We need to find a unique lifting of $\overline{C}$ to a curve $C$ in $E$. The way to achieve that is to endow the bundle a connection $\omega$, then require $C$ to be the <strong>horizontal lift</strong>.</p> <p><em>Note that if $\overline{f}$ is homotopic to a constant map $p_ {0}$, it need not be that $f$ will be homotopic to a constant map</em>.</p> <p>What we have said for a vector bundle can also be shown to hold for a principal fiber bundle.</p> <p>It turns out that one can cover homotopies in <strong>any</strong> fiber bundle, without any use of a connection. In fact, one generalizes the notion of a fiber bundle to that of a <code class="language-plaintext highlighter-rouge">fiber space</code>. This is a space $P$ equipped with a map $\pi: P\to M$ such that <strong>homotopies can always be covered</strong>. Such spaces need not be local products.</p> <h2 id="some-topology-of-sun">Some Topology of $SU(n)$</h2> <p>$SU(n)$ is represented by $N \times N$ complex matrices acting on $\mathbb{C}^{n}$. Since each $g \in SU(N)$ is unitary, $SU(N)$ sends the unit sphere $\mathbb{S}^{2N-1} \subset \mathbb{C}^{n}$ \(\mathbb{S}^{2N-1} = \left\lbrace z \in \mathbb{C}^{N} \,\middle\vert\, \left\lvert z_ {1} \right\rvert^{2} + \dots + \left\lvert z_ {N} \right\rvert^{2}=1 \right\rbrace\) into itself. The action is also transitive (meaning any two points on $\mathbb{S}^{2N-1}$ can be connected by some group action). The isometry group for the point $(1,0,\dots,0)$ is clearly \(\begin{bmatrix} 1 &amp; 0 \\ 0 &amp; SU(N-1) \end{bmatrix}\) which we shall briefly denote simply by $SU(N-1)$.</p> <p>We have \(\mathbb{S}^{2N-1} \cong \frac{SU(N)}{SU(2N-1)}.\)</p> <p>and in fact $SU(N)$ is a principal $SU(N − 1)$ bundle over $\mathbb{S}^{2N-1}$, with fiber at each point $p\in M$ being the little group of $p$. Thus we write \(SU(N-1)\to SU(N) \to \mathbb{S}^{2N-1}\) <strong>Theorem.</strong> If $F\to P \to M$ is a fiber bundle with connected $M$ and connected $F$, then $P$ is also connected.</p> <p>As a corollary, $SU(N)$ is connected. To see that, note $SU(1)$ is a single point, $SU(2)$ is a $3$-sphere and is connected, as are all $k$-spheres for $k\geq 3$. From \(SU(2) \to SU(3) \to \mathbb{S}^{5}\) we see that $SU(3)$ is connected. The connectness of higher $SU$ groups follow from induction.</p> <p>Another example of the above theorem is the <code class="language-plaintext highlighter-rouge">Hopf fibration</code>. The Hopf fibration is a fiber bundle where the total space $P$ is $\mathbb{S}^{3}$, the base space $M$ is $\mathbb{S}^{2}$ and the fiber $F$ is $\mathbb{S}^{1}$.</p> <hr/> <p>Recall that we say that $M$ is simply connected provided every map of a circle into $M$ is homotopic to a constant map. During the homotopy, the closed curve gets “contracted” or “deformed” to the point.</p> <p><strong>Theorem.</strong> Let $F\to P \to M$ be a fiber bundle whose fiber and base space are both simply connected. Then $P$ is simply connected.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="Geometry"/><category term="Frankel"/><summary type="html"><![CDATA[Disclaimer: Nothing in this note is original.]]></summary></entry><entry><title type="html">Higher Homotopy Groups</title><link href="https://baiyangzhang.github.io/blog/2023/Higher-Homotopy-Groups/" rel="alternate" type="text/html" title="Higher Homotopy Groups"/><published>2023-11-18T00:00:00+00:00</published><updated>2023-11-18T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Higher-Homotopy-Groups</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Higher-Homotopy-Groups/"><![CDATA[<h2 id="pi_-km">$\pi_ {k}(M)$</h2> <p>All maps considered in this chapter are supposed to be continuous.</p> <p>Consider a map $f$ from $k$-sphere to $n$-dimensional manifold $M$. We shall always ask that some distinguished point on the sphere , the “north pole”, be sent into a distinguished base point, written $\ast$ in $M^{n}$.</p> <p>For technical reasons we consider the $k$-sphere to be the $k$-cube, denoted $\mathbb{I}^{k}$. In other words \(\mathbb{I}^{k} := [0,1] \times \dots \times [0,1],\quad k\text{ of them}.\) <strong>The entire boundary $\partial \mathbb{I}^{k}$ identified with a single point</strong>, the north pole. This choice of cubic make it much easier to talk about, for example, the composition of two maps.</p> <p>We assume the reader is already familiar with the basic concepts of homotopy group, such as how we compose two elements of a homotopy group, etc.</p> <p>The commutivity that two elements of homotopy group is shown in the figure below.</p> <p><img src="/img/homotopyCommute.png" alt="commutivity"/></p> <p>Note that this procedure will not work in the case $n = 1$; there is no room to maneuver. This is why the fundamental group <strong>$\pi_ {i}$ can be nonabelian</strong>.</p> <h2 id="homotopy-groups-of-spheres">Homotopy Groups of Spheres</h2> <p>Now let’s talk about $\pi_ {k}(\mathbb{S}^{n})$. First consider the case $k&lt;N$.</p> <p>It seems evident that $f(\mathbb{S}^{k})$ cannot cover all of $\mathbb{S}^{n}$ if $k &lt; n$ but this is actually false since we <strong>do not require our maps to be smooth</strong>! Peano constructed a curve, a <strong>continuous</strong> map of the interval $[0, 1]$, whose image filled up an entire square $[0, 1] \times [0, 1]$!</p> <p>It is a fact that a continuous map of a sphere into an $M^{n}$ is homotopic (via approximation) to a smooth one. To be specific, the <strong>approximation Theorem</strong> states that any <em>continuous</em> map between <em>smooth manifolds</em> can be approximated arbitrarily closely by a smooth map. In more technical terms, for any continuous map $f$ and any $\epsilon&gt;0$, there exists a smooth map $g$ such that the distance between $f(x)$ and $g(x)$ is less than $\epsilon$ for all $x$. Hence a continuous map $f: \mathbb{S}^{k} \to M$ can be approximated by a smooth map $g$. Moreover, $f$ and $g$ are homotopic, as there exists a continuous deformation (homotopy) from $f$ to $g$. This homotopy essentially ‘smoothens’ out the irregularities in $f$ to transition it into the smooth map $g$.</p> <p>Hence we may assume that $f (\mathbb{S}^{k})$ does not cover all of $\mathbb{S}^{n}$ when $k &lt; n$. Suppose then the south pole is not covered, then we can push the image from the south pole, we can push the entire image to the north pole. We have deformed the map into a constant map. Thus \(\pi_ {k}(\mathbb{S}^{n}) =0 \text{ if } k&lt;n.\)</p> <p>Consider the case $k=n$. We know that homotopic maps of an $n$-sphere into itself have the same degree. A theorem of Heinz Hopf says in fact that maps of any <em>connected, closed, orientable</em> $n$-manifold $M$ into an $n$-sphere $\mathbb{S}^{n}$ are homotopic <em>if and only if they have the same degree</em> (the proof is nontrivial). Thus \(\pi_ {n}(\mathbb{S}^{n}) = \mathbb{Z}.\)</p> <h2 id="exact-sequences-of-groups">Exact Sequences of Groups</h2> <p>A sequence of groups and homomorphisms \(\dots \to F \xrightarrow{f} G \xrightarrow{g} H \to \dots\) are said to be <code class="language-plaintext highlighter-rouge">exact</code> at $G$ if the kernel of $G$ coincides with the image of $f$, \(\text{ker }g = \text{img }f.\) In particular, we must have that the composition $g\,\circ\,f$ is the trivial homeomorphism sending all of $F$ into the identity element of $H$. The entire sequence is said to be exact if it is exact at each group. $0$ will denote the group consisting of just the identity (if the groups are <em>not abelian</em> we usually use $1$ instead of $0$).</p> <p><strong>Some Examples.</strong></p> <p>If \(0\xrightarrow{f} H \xrightarrow{g} G\) is exact at $H$ then the image of $f$ coincides with the kernel of $g$. However the image of $0$ is the identity in $H$ alone, it means that the kernel of $g$ is the identity, nothing else. Then $g$ is injective, namely $1:1$. And since $g$ is $1:1$, we may identify $H$ with its image; in other words, we may consider $H$ to be a <em>subgroup</em> of $G$! We would simply write \(0 \to H \xrightarrow{g} G.\)</p> <p>If \(H\xrightarrow{h}G\xrightarrow{g} 0\) is exact then the image of $h$ is the kernel of $g$, which is the whole $G$. So $h$ is onto. Again we would forget about $g$.</p> <p>If \(0 \to G\xrightarrow{h}H \to{}0\) is exact, $h$ is both $1:1$ and <em>onto</em>, then $G \cong H$.</p> <p>Consider an exact sequence of three nontrivial abelian groups, the so-called <code class="language-plaintext highlighter-rouge">short exact sequence</code> \(0 \to F \xrightarrow{f}G \xrightarrow{g}H \to 0\) then the kernel of $g$ is the image of $f$, which is considered the subgroup of $G$, \(F \cong f(F) \subset G\) and $g$ is onto. Then \(H \cong \frac{G}{F}.\) <img src="/img/shortExactSequence.png" alt=""/></p> <p>If the homomorphisms involved are understood, we frequently will omit them. For example, the exact sequence \(0 \to 2 \mathbb{Z} \to \mathbb{Z} \to \mathbb{Z}_ {2} \to 0\) says that the even integers form a subgroup of the integers and \(\mathbb{Z}_ {2} \cong \mathbb{Z} / 2\mathbb{Z}.\) The exact sequence \(0 \to \mathbb{Z} \to \mathbb{R} \to \mathbb{S}^{1} \to 0\) where $\mathbb{R} \to \mathbb{S}^{1}$ is the exponential homomorphism \(r\in \mathbb{R} \mapsto \exp(i 2\pi r)\) onto the unit circle in the complex plane. Then the circle is a coset space \(\mathbb{R}^{1} \cong \mathbb{R} / \mathbb{Z}.\)</p> <p>In brief, a short exact sequence of abelian groups is always of the form \(0 \to H \to G \to G / H \to 0.\)</p> <h2 id="the-homotopy-sequence-of-a-bundle">The Homotopy Sequence of a Bundle</h2> <p>For simplicity only, we shall consider a fiber bundle with connected fiber and base.</p> <p><strong>Theorem.</strong> If the fiber $F$ is <em>connected</em>, we have the exact sequence of <em>homotopy groups</em> \(\dots \to \pi_ {k}(F)\to \pi_ {k}(P)\to \pi_ {k}(M)\xrightarrow{\partial} \pi_ {k-1}(F)\to\dots\) \(\dots \xrightarrow{\partial}\pi_ {1}(F) \to\pi_ {1}(P) \to\pi_ {1}(M)\to 1\) The homomorphism from $\pi(F)$ to $\pi(P)$ is defined by the induced map of the inclusion map $i: F \to P$. It should be clear that a continuous map $f: V \to M$ that sends base points into base points will induce a homomorphism $f_ {\star}: \pi (V)\to \pi(M)$, since a sphere that gets mapped into $V$ can then be sent into $M$ by $f$. The map from $\pi(P)$ to $\pi(M)$ is the induced map of $\pi$ the projection. The remaining <code class="language-plaintext highlighter-rouge">boundary homomorphism</code> \(\partial: \pi_ {k}(M) \to \pi_ {(k-1)}(F)\) is illustrated in the following figure for the case $k=2$.</p> <p>Consider $f:\mathbb{S}^{2} \to M$, defining an element of $\pi_ {2}(M)$. The entire boundary is mapped to $x_ {0}$.</p> <p><img src="/img/boundaryHomo.png" alt=""/></p> <p>Consider the homotopy cover of $f(\mathbb{I}^{2})$ on the bundle $P$.</p> <p><img src="/img/boundaryMap.png" alt=""/></p> <p>The above figure shows our assignment \(\partial: \pi_ {2}(M) \to \pi_ {1}(F).\) Briefly speaking, the lift of a $k$-sphere in $M$ yields a $k$-disc in $P$ whose boundary is a $(k − 1)$-sphere in $F$.</p> <p>We shall not prove exactness. Just mention that at the last stage, $\pi_ {1}(P)\to \pi_ {1}(M)$ is onto because $F$ has been assumed connected. A circle on $M$ can be lifted to a curve in $P$ whose endpoints lie in $F$ and since $F$ is connected, these endpoints can be joined in $F$ to yield a closed curve in $P$ that projects down to the original circle.</p> <h2 id="the-relation-between-homotopy-and-homology-groups">The Relation Between Homotopy and Homology Groups</h2> <p>Let $\pi_ {1}(M)$ be the fundamental group of a connected manifold $M$, we know that this group is not always abelian. A good example of this is the so-called figure-eight space, also known as the wedge sum of two circles, where the fundamental group $\pi_1$ is not abelian. The figure-eight space can be visualized as two circles touching at a single point. Let’s denote these circles as $A$ and $B$, and the point where they meet as $x_0$. The fundamental group of the figure-eight space is generated by two loops: one that goes around circle $A$ and returns to $x_0$, and another that goes around circle $B$ and returns to $x_0$. We can denote these loops as $a$ and $b$, respectively. To show that this group is not abelian, we need to demonstrate that the order in which you traverse $a$ and $b$ matters. Specifically, we need to show that $ab$ is not homotopic to $ba$, where $ab$ represents traversing loop $a$ followed by loop $b$, and $ba$ represents traversing $b$ followed by $a$. Loop $ab$ first goes around $A$ and then around circle $B$. Loop $ba$ first goes around circle $B$ and then around circle $A$. The way these loops are concatenated makes a difference. Since these loops cannot be continuously deformed into each other without breaking and rejoining at $x_0$, they represent different elements in the fundamental group. The fundamental group $\pi_1(\text{Figure-Eight}, x_0)$ is actually isomorphic to the free group on two generators, denoted $F(a, b)$. In a free group, the generators $a$ and $b$ (and their inverses) can be combined in any sequence, but there is no relation like $ab = ba$ to simplify that sequence. Therefore, the group is non-abelian.</p> <p>The key point here is that the paths $ab$ and $ba$ cannot be homotopically deformed into each other within the space of the figure-eight, making the fundamental group non-abelian.</p> <p>Let $[\pi_ {1},\pi_ {1}]$ be the subgroup of $\pi_ {1}$ generated by commutators (elements of form $bab^{-1}a^{-1}$). Then the quotient group \(\frac{\pi_ {1}}{[\pi_ {1},\pi_ {1}]} \cong H_ {1}(M,\mathbb{Z})\) where $H_ {1}(M,\mathbb{Z})$ is the first homology group.</p> <p>For the higher homotopy groups we have the <code class="language-plaintext highlighter-rouge">Hurewicz theorem</code> (Hurewicz was the inventor of these groups):</p> <p>For the higher homotopy groups we have the Hurewicz theorem (Hurewicz was the inventor of these groups), which predicts the first non-vanishing homology group from the first non-vanishing homotopy group, and vise versa.</p> <p><strong>Theorem.</strong> Let $M$ be simply connected, $\pi_ {1}=0$. Let $\pi_ {j}$ be the first non-vanishing homotopy group. Then $H_ {j}(m;\mathbb{Z})$ is the first non-vanishing homology group and those two groups are isomorphic, \(\pi_ {j}(M) \cong H_ {j}(M;\mathbb{Z}).\)</p> <p>The proof is difficult, we will just mention an example. We know $\mathbb{S}^{n}$ is simply connected for $n&gt;1$. Also, we know $H_ {j}(\mathbb{S}^{n};\mathbb{Z})$ is zero for $j&lt;n$, and $H_ {n}(\mathbb{S}^{n};\mathbb{Z})\cong\mathbb{Z}$. Thus \(\pi_ {j}(\mathbb{S}^{n}) = 0,\quad j&lt;n\) and \(\pi_ {n}(\mathbb{S}^{n})\cong \mathbb{Z}.\)</p>]]></content><author><name>Baiyang Zhang</name></author><category term="Geometry"/><category term="Frankel"/><summary type="html"><![CDATA[$\pi_ {k}(M)$]]></summary></entry><entry><title type="html">Curvature and Winding Number</title><link href="https://baiyangzhang.github.io/blog/2023/Curvature-and-Winding-Number/" rel="alternate" type="text/html" title="Curvature and Winding Number"/><published>2023-11-16T00:00:00+00:00</published><updated>2023-11-16T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Curvature-and-Winding-Number</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Curvature-and-Winding-Number/"><![CDATA[<p><em>Disclaimer: Nothing in this note is original.</em></p> <p>We will assume that the Yang-Mills potential $\omega_ {U}$ in patch $U$ has no singularity.</p> <p>Let $\theta$ be the two-form curvature, we have the following observation for any vector bundle over all base manifolds, \(\theta \wedge \theta = (d\omega+\omega \wedge \omega)\wedge (d\omega+\omega \wedge \omega) ,\) using \(\mathrm{Tr}\,(\omega \wedge \omega \wedge d\omega) = \mathrm{Tr}\,(d\omega \wedge \omega \wedge \omega)\) and \(\mathrm{Tr}\,(\omega \wedge \omega \wedge \omega \wedge \omega)=0\) we have eventually \(\mathrm{Tr}\,(\theta \wedge \theta) = d\, \mathrm{Tr}\,\left( \omega \wedge d\omega+\frac{2}{3}\omega \wedge \omega \wedge \omega \right)\) thus $\mathrm{Tr}\,(\theta \wedge\theta)$ is <em>locally exact</em>, it is locally the differential of a $3$-form, called the <code class="language-plaintext highlighter-rouge">Chern-Simons</code> $3$-form. $\omega$ is not usually globally defined.</p> <p>Coming back to the case of instanton, outside the instanton the curvature vanishes but the connection does not, hence we have \(\int_ {U} \, \mathrm{Tr}\,(\theta \wedge \theta) = \int_ {\partial U = \mathbb{S}^{3}} \, \left( -\frac{1}{3} \right)\mathrm{Tr}\,(\omega \wedge \omega \wedge \omega).\) This allows us to write the winding number in terms of curvature, by applying some kind of Stokes theorem \(\frac{1}{24\pi^{2}}\int_ {\mathbb{S}^{3}} \, \mathrm{Tr}\,(\omega_ {U}\wedge \omega_ {U}\wedge \omega_ {U}) = - \frac{1}{8\pi^{2}} \int_ {\mathbb{R}^{4}} \, \mathrm{Tr}\,(\theta \wedge \theta).\)</p> <p>Note that $\theta \wedge\theta$ is <em>not</em> the Lagrangian, which is $\mathrm{Tr}\,(\theta \wedge\star \theta)$. We have \(\theta \wedge \theta = (\theta \wedge \theta)_ {0123}\,dt\wedge dx\wedge dy\wedge dz\propto \epsilon^{ijkl}F_ {ij}F_ {kl}\) while \(\theta \wedge \star \theta \propto F_ {ij}F^{ij}.\)</p> <h3 id="the-chern-form-for-a-un-bundle">The Chern form for a $U(n)$ bundle</h3> <p>The topological significance of $\mathrm{Tr}\,(\theta \wedge\theta)$, generalizing Poincare’s theorem for closed surfaces (which says the sum of indices times multiplicity equal to the Euler characteristic), is developed by Chern. $\mathrm{Tr}\,(\theta \wedge\theta)$ is but one of a whole family of significant integrands, called the Chern forms. But before going into details, let’s review what is <code class="language-plaintext highlighter-rouge">exterior power space</code> shortly.</p> <p>Given a vector space $V$ over a field $F$ (like the real numbers $\mathbb{R}$), the exterior algebra is an algebraic structure that extends the concept of scalars and vectors to higher-dimensional analogs. It is denoted as $\bigwedge V$. The $k$-th <code class="language-plaintext highlighter-rouge">exterior power</code> of $V$, denoted as $\Lambda^k(V)$ or $\bigwedge^{k} V$, is a vector space that consists of all alternating $k$-linear forms on $V$. For example, in $\Lambda^1(V)$, elements are just vectors. An exterior differential form of degree $k$ (or a $k$-form) on a differentiable manifold $M$ is a smooth section of the $k$-th exterior power of the cotangent bundle of $M$. In simpler terms, a $k$-form is a mathematical object that can be integrated over $k$-dimensional submanifolds of $M$. These forms are crucial in defining integrals over manifolds and in the formulation of Stokes’ theorem.</p> <p>The exterior power space $\Lambda^k(V)$ provides the algebraic structure that underlies the concept of $k$-forms. When you consider a manifold $M$ with a tangent space at each point that is a vector space $V$, the exterior power $\Lambda^k(T^\ast M)$ (where $T^\star M$ is the cotangent bundle of $M$) is the space in which exterior differential forms live. This means that each $k$-form is an element of $\Lambda^k(T^\star M)$ at each point of $M$.</p> <p><strong>Example. 1</strong></p> <p>Considering the exterior powers of a three-dimensional complex vector space $V = \mathbb{C}^3$, with basis $\lbrace v_ {1},v_ {2},v_ {3} \rbrace$. We explore the spaces formed by taking the exterior powers of $V$. These spaces are constructed using the wedge product as follows:</p> <p><em>Zeroth Exterior Power</em>, $\Lambda^0(V)$: This is the space of scalars. It is isomorphic to the field over which the vector space is defined, in this case, the complex numbers $\mathbb{C}$. The dimension of this space is one.</p> <p><em>First Exterior Power, $\Lambda^1(V)$</em>: This is just the vector space $V$ itself, with dimension three (since $V = \mathbb{C}^3$). The basis are simply $\left\lbrace v_ {1},v_ {2},v_ {3} \right\rbrace$.</p> <p><em>Second Exterior Power, $\Lambda^2(V)$</em>: This space consists of all skew-symmetric bilinear forms on $V$. It can be visualized as the space of oriented planes in $V$. It has dimension<br/> \(\binom{3}{2} = 3, \text{ since there are 3 ways to choose pairs from 3 elements.}\) The basis are $\left\lbrace v_ {1}\wedge v_ {2},v_ {1}\wedge v_ {3},v_ {2}\wedge v_ {3} \right\rbrace$.</p> <p><em>Third Exterior Power, $\Lambda^3(V)$</em>: This is the space of 3-vectors in $V$. It represents the oriented volume elements in $V$. The dimension is $\binom{3}{3} = 1$ (there is only one way to choose triples from 3 elements). The basis is $v_ {1}\wedge v_ {2}\wedge v_ {3}$.</p> <p><em>Higher Exterior Powers, $\Lambda^k(V)$ for $k &gt; 3$</em>: For any $k$ greater than the dimension of $V$ (which is 3 in this case), the exterior power $\Lambda^k(V)$ is the trivial vector space {0}, as there are no non-zero $k$-vectors in a 3-dimensional space for $k &gt; 3$.</p> <hr/> <p>Let $V=\mathbb{C}^{N}$ be $N$-dimensional complex vector space. Let $A$ be a $N\times N$ complex matrix that acts on $V$ in the usual way. Consider the<code class="language-plaintext highlighter-rouge"> characteristic (eigenvalue) polynomial</code> of $A$, \(\det(\lambda I-A) = (\lambda-\lambda_ {1})(\lambda-\lambda_ {2})\dots(\lambda-\lambda_ {N})\) where $\lambda_ {1},\dots,\lambda_ {N}$ are the eigenvalues of $A$. Putting $\lambda=-1$ we have \(\begin{align*} \det(I+A) &amp;= (1+\lambda_ {1})(1+\lambda_ {2})\dots(1+\lambda_ {N}) \\ &amp;= 1 + \sum_ {i}\lambda_ {i} + \sum_ {i&lt;j} \lambda _ {i} \lambda _ {j} +\dots+\prod_ {i=1}^{N}\lambda_ {i} \\ &amp;= 1 + \mathrm{Tr}\,A + \mathrm{Tr}\, \bigwedge^{2}A +\dots+\mathrm{Tr}\,\bigwedge^{N}A \end{align*} \tag{1}\) where the big wedges are called the <code class="language-plaintext highlighter-rouge">elementary symmetric functions</code> of he eigenvalues of $A$. The reason for this notation is as follows. Since \(A: V \to V\) is a linear transformation on $V$, we may let $A$ act on each of the <em>exterior power spaces</em> $\Lambda^{p} (A)$ by the so-called <em>exterior power operation</em> \(\bigwedge^{p}A: \; v_ {1}\wedge \dots \wedge v_ {p} \mapsto (Av_ {1})\wedge (Av_ {2})\wedge \dots \wedge (Av_ {p} ).\) Let’s take $p=N$ for example. $\Lambda^{N}(V)$ is one dimensional and \(\left( \bigwedge^{N}A \right)(v_ {1}\wedge \dots \wedge v_ {n} ) = \det A\, (v_ {1}\wedge \dots \wedge v_ {n} ).\) Thus justifies the definition shown in the last term in Eq. (1). Let’s take a look at other terms, for example, at $\Lambda^{2}A$. We treat $A$ as diagonal matrix $\text{diag}(\lambda_ {1},\dots,\lambda_ {N})$ to simplify the calculation, and we can consider \(\bigwedge^{2}(v_ {i}\wedge v_ {j})\) as the component of the exterior power operator on basis $v_ {i}\wedge v_ {j}$. Then the trace of $\Lambda^{2}(A)$ is simply the sum total of all its components. We have \(\bigwedge^{2}(v_ {i}\wedge v_ {j}) = A_ {im} A_ {jn}(v_ {m} \wedge v_ {n} ) = (\lambda _ {i} \lambda _ {j})\, v_ {i} \wedge v_ {j}\) where $i&lt;j$ implicitly. Then the total sum is \(\mathrm{Tr}\,\bigwedge^{2} A = \sum_ {i&lt;j}\lambda _ {i} \lambda _ {j} .\)</p> <hr/> <p>It turns out we can further simplify $\Lambda^{p}A$. Note that \(\lambda_ {1}^{p} + \lambda_ {2}^{p} + \dots + \lambda _ {N}^{p} = \mathrm{Tr}\,(A^{p}),\quad A = \text{diag}(\lambda_ {1},\dots,\lambda_ {N}).\)</p> <p>Take $p=2$ for example, \(\bigwedge^{2} A = \sum _ {i&lt;j} \lambda _ {i} \lambda _ {j} = \frac{1}{2} \sum_ {ij} \lambda _ {i} \lambda _ {j} - \frac{1}{2} \lambda _ {i} \lambda _ {i} = \frac{1}{2}(\mathrm{Tr}\,A)^{2} - \frac{1}{2} \mathrm{Tr}\,A^{2}.\)</p> <p>Turns out all the exterior power operators can be expressed as a <em>polynomial</em> in terms of $\mathrm{Tr}\, A^{n}$ and $(\mathrm{Tr}\,A)^{m}$ for some $m$ and $n$.</p> <hr/> <p>Now, let $E\to M$ be a complex $\mathbb{C}^{N}$ bundle with structure group $U(N)$. Let the connection be $\omega$. The corresponding $2$-form curvature is still denoted by $\theta$.</p> <p>Let’s <em>formally</em> replace $A$ in Eq. (1) with $i\theta / 2\pi$, replace multiplication with wedge product. To be exact, we work with <strong>polynomial expression</strong> of $\Lambda^{p}A$, and perform these substitutions. Since $\theta$ is a $2$-form there will be no problem with ordering. Regarding $\theta$ as a matrix means that the $(\alpha,\beta)$-th entry of the matrix is $\theta^{\alpha}_ {\;\; \beta}$. Now similar to Eq. (1) we have \(\begin{align*} \det \left( I+\frac{i\theta}{2\pi} \right) &amp;= I + \mathrm{Tr}\,\frac{i\theta}{2\pi} + \dots \\ &amp;= I + c_ {1}(E) + c_ {2}(E) + \dots \end{align*}\) where $c_ {1}(E)$ is a 2-form on $U\subset M$, $c_ {r}(E)$ is a $2r$-form on $U$. It’s called the $r$-th <code class="language-plaintext highlighter-rouge">Chern form</code>.</p> <p>To be specific, the form $c_ {1}$ is \(c_ {1} = \frac{i}{2\pi} \mathrm{Tr}\,\theta = \frac{i}{2\pi} \mathrm{Tr}\,\theta^{\alpha}_ {\;\; \alpha}.\) For $c_ {2}$ we have \(c_ {2} = -\frac{1}{8\pi^{2}}[\mathrm{Tr}\,\theta \wedge \mathrm{Tr}\,\theta-\mathrm{Tr}\,(\theta \wedge \theta)].\)</p> <p>Suppose the bundle has $SU(N)$ structure group rather than $U(N)$. The Lie algebra ${\frak su}(N)$ are traceless, anti-hermitian (mathematical convention) matrices, thus we have $\mathrm{Tr}\,\theta=0$ (recall that both the connection and curvature are ${\frak g}$-valued forms). Then $c_ {1}(E)$ vanishes but $c_ {2}$ does not, \(c_ {2}(E) = \frac{1}{8\pi^{2}} \mathrm{Tr}\,(\theta \wedge \theta),\) which is precisely the 4-form appearing in the winding number of an $SU(2)$ instanton! Just now we have $SU(N)$ instead.</p> <p>Recall that the curvature $\theta_ {U}$ is locally defined on open patches $U$, under a change of basis the curvature changes as \(\theta_ {V} = c_ {VU} \theta_ {U} c_ {UV}^{-1} ,\) thanks to the property of determination we have \(\det\left( I+ \frac{i \theta_ {V}}{2\pi} \right) = \det\left( I+ \frac{i\theta_ {U}}{2\pi} \right).\) It means that each <em>Chern form</em> is <strong>globally define</strong> $2r$-form on all of $M^{n}$.</p> <p>With the help of Bianchi identity, it is possible to show that $c_ {1}$ is closed.</p> <p>For $SU(2)$ bundle, the second Chern form is <em>locally</em> the differential of Chern-Simons form.</p> <p>We present without proof the</p> <p><strong>Theorem of Chern and Weil:</strong> Each $c_ {r}$ is a <em>closed</em> $2r$-form thus defines a (real) de Rham class. Furthermore, different connections for the $U(N)$ bundle will yield Chern form that differs by an exact form, and hence define the same de Rham cohomology class.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="Geometry"/><category term="Frankel"/><category term="#Topology"/><summary type="html"><![CDATA[Disclaimer: Nothing in this note is original.]]></summary></entry><entry><title type="html">Note on Numerical Methods in Solving ODE</title><link href="https://baiyangzhang.github.io/blog/2023/Notes-on-Numerical-Methods-in-Solving-ODE/" rel="alternate" type="text/html" title="Note on Numerical Methods in Solving ODE"/><published>2023-10-31T00:00:00+00:00</published><updated>2023-10-31T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2023/Notes-on-Numerical-Methods-in-Solving-ODE</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2023/Notes-on-Numerical-Methods-in-Solving-ODE/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>In my line of work I sometimes need to solve unsolvable ODEs and PDEs, unsolvable in the sense that it is impossible to get an analytical solution. What we do is to turn to numerical methods for help. For instance, just recently I need to solve a modified version of the Skyrme equation (the equation of motion resulted from the Skyrme model). I thought it would be helpful to summarize what I’ve learnt here.</p> <p>Various numerical methods have been developed to tackle different types of ODEs (initial value problems, boundary value problems, linear, nonlinear, etc.). Here are some of the most popular numerical methods for solving ODEs:</p> <ol> <li><strong>Euler’s Method</strong>: <ul> <li>This is the simplest one-step method.</li> <li>It’s based on a linear approximation of the solution.</li> <li>While straightforward and instructive for educational purposes, it’s rarely used in practice due to its low accuracy and stability issues.</li> </ul> </li> <li><strong>Runge-Kutta Methods</strong>: <ul> <li>These are a family of iterative methods.</li> <li>The 4th order Runge-Kutta (often called RK4) is particularly popular due to its balance between accuracy and computational cost.</li> </ul> </li> <li><strong>Leapfrog (or Midpoint) Method</strong>: <ul> <li>A second-order method that is particularly useful in cases where energy conservation is crucial, such as in molecular dynamics simulations.</li> </ul> </li> <li><strong>Predictor-Corrector Methods</strong>: <ul> <li>These methods predict a solution using an explicit method and then correct it with an implicit method.</li> <li>Examples include the Adams-Bashforth (predictor) and Adams-Moulton (corrector) methods.</li> </ul> </li> <li><strong>Backward Differentiation Formulas (BDF)</strong>: <ul> <li>These are implicit multi-step methods.</li> <li>Commonly used for stiff ODEs.</li> </ul> </li> <li><strong>Multistep Methods</strong>: <ul> <li>These methods use values at multiple previous time steps.</li> <li>Examples include the Adams methods.</li> </ul> </li> <li><strong>Symplectic Integrators</strong>: <ul> <li>These are used for Hamiltonian systems where preserving the symplectic structure (related to conservation of energy) is essential.</li> </ul> </li> <li><strong>Implicit Methods</strong>: <ul> <li>Used frequently for stiff equations where explicit methods require prohibitively small time steps.</li> <li>Examples include the backward Euler method and the trapezoidal rule.</li> </ul> </li> <li><strong>Shooting Method</strong>: <ul> <li>Primarily used for boundary value problems (BVPs).</li> <li>Converts a BVP into an initial value problem (IVP) and then solves the IVP.</li> </ul> </li> <li><strong>Relaxation Methods</strong>: <ul> <li>Also for boundary value problems.</li> <li>Iteratively refines an initial guess to the solution.</li> </ul> </li> <li><strong>Finite Difference Method</strong>: <ul> <li>Converts differential equations into <em>difference</em> equations, which can then be solved algebraically.</li> <li>Often used for both ODEs and PDEs.</li> </ul> </li> <li><strong>Collocation Methods</strong>: <ul> <li>This approach seeks an approximate solution by considering values at specific points (collocation points).</li> </ul> </li> <li><strong>Continuation method</strong>, which we will go to detail later.</li> </ol> <hr/> <p>These methods can be adapted or combined in various ways depending on the specific problem at hand. Moreover, the choice of method often depends on the nature of the ODE (e.g., stiffness), desired accuracy, computational cost considerations, and the specific properties that need to be preserved (e.g., conservation laws).</p> <p>Many modern computational packages and software (like MATLAB, Mathematica, and SciPy in Python) provide built-in functions that implement these methods, which makes it easier for users to solve ODEs without delving deeply into the numerical intricacies of each method.</p> <p><strong>Stiffness.</strong></p> <p>Imagine you’re on a winding road with both smooth curves and sharp turns. If you’re driving a car along this road at a constant speed, the smooth curves can be navigated quite easily, but the sharp turns require more caution and precision.</p> <p>Similarly, in the context of differential equations, there can be parts of the solution that change very slowly (smooth curves) and others that change extremely rapidly (sharp turns). When a differential equation has solutions with widely differing rates of change over its domain, we say that the equation is “stiff.” When you’re solving a stiff differential equation using numerical methods (like the Euler method or the Runge-Kutta method), you’ll notice that the rapid changes require very small step sizes for accurate solutions. However, the slow-changing parts don’t need such small steps. If you choose a step size suitable for the rapidly changing sections (very small), the computation can become inefficient because you’re using more steps than necessary for the slow-changing sections. On the other hand, if you choose a larger step size suitable for the slow-changing sections, the solution can become unstable or highly inaccurate in the rapidly changing sections.</p> <p>To efficiently and accurately solve stiff differential equations, specialized numerical methods have been developed, known as “stiff solvers.” These solvers are designed to adaptively handle the challenges posed by stiffness, allowing for stable and efficient computation.</p> <h2 id="numerical-values-of-parameters">numerical values of parameters</h2> <p>I collected the following values from the Adkins:Nappi:1984 paper<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>,<br/> \(m_ {\pi} = 108 \text{ MeV}, \quad e=4.82,\quad F_ {\pi} = \frac{m_ {\pi}}{0.263 e}\) which gives us \(\begin{align} m_ {1} &amp;= 0.526, \\ m_ {2} &amp;= 1.052. \end{align}\)</p> <p>In the chiral case, pion is massless and we have \(\begin{align} m_ {1} &amp;= 0, \\ m_ {2} &amp;= 1.052. \end{align}\)</p> <h2 id="the-shooting-method">The shooting method</h2> <p>The shooting method is a numerical technique used to solve boundary value problems (BVPs) for ordinary differential equations (ODEs). <em>It’s especially useful for second-order ODEs, but can be applied to higher-order equations as well</em>.</p> <p>Here’s a basic overview of the shooting method:</p> <p><strong>The Problem:</strong> Suppose you have a second-order ODE given as: \(y''(x) = f(x, y, y'),\) with boundary conditions: \(y(a) = y_ a\) \(y(b) = y_ b\)</p> <p><strong>The Challenge:</strong> Directly solving the BVP using typical ODE solvers is difficult because standard solvers require initial conditions (values of $y$ and $y’$ at a starting point), rather than boundary conditions at two separate points.</p> <p><strong>The Shooting Method’s Approach:</strong></p> <ol> <li> <p><strong>Guess an Initial Slope</strong>: Choose an initial guess for the derivative $y’(a)$, let’s call it $y’_ a$.</p> </li> <li> <p><strong>Solve as an IVP</strong>: Using the known value $y(a) = y_ a$ and the guessed $y’(a) = y’_ a$ then solve the ODE as an initial value problem (IVP) over the interval $[a, b]$ using standard techniques, like the Runge-Kutta method.</p> </li> <li> <p><strong>Check the Endpoint</strong>: Once you’ve solved the ODE using your initial guess, check the value of $y(b)$ from this solution. Compare it to the desired boundary condition $y_ b$.</p> </li> <li> <p><strong>Adjust the Guess</strong>: If $y(b)$ from your solution is close to $y_ b$, then you’re done. If not, adjust your guess for $y’(a)$ and solve the IVP again. This is typically done using a root-finding algorithm like Newton’s method or the secant method.</p> </li> <li> <p><strong>Iterate</strong>: Repeat steps 2-4 until $y(b)$ from your solution is sufficiently close to $y_ b$, or until a set number of iterations have been reached.</p> </li> </ol> <p>The method’s name comes from the idea that you’re “shooting” from one boundary towards the other. Your first “shot” might miss the target (the second boundary condition). By adjusting your aim (the initial derivative guess) and shoot again, you try to hit the target. The process is repeated until you’re close enough to the target, similar to adjusting one’s aim when firing at a target in marksmanship.</p> <p>While the shooting method can be effective, it’s not guaranteed to work for all BVPs, especially when the underlying ODEs are highly nonlinear or when appropriate initial guesses are hard to ascertain. Unfortunately, the solving of the modified Skyrme equation seems to fall in the category, as I am about to go to details right now.</p> <p>With the parameters listed in the previous chapter, I tried to solve the equation of motion using shooting method with the following codes</p> <div class="language-matlab highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bc1</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">Pi</span><span class="p">;</span>
<span class="n">bc2</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="mi">50</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">;</span>

<span class="n">approximateSolution</span> <span class="o">=</span> <span class="n">Pi</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Tanh</span><span class="p">[</span><span class="n">r</span><span class="p">]);</span>

<span class="n">initialGuessY</span> <span class="o">=</span> 
  <span class="n">approximateSolution</span> <span class="p">/</span><span class="o">.</span> 
   <span class="n">r</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">;</span>  <span class="p">(</span><span class="o">*</span><span class="n">Evaluate</span> <span class="n">approximate</span> <span class="n">solution</span> <span class="n">at</span> <span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="p">)</span>
<span class="n">initialGuessYPrime</span> <span class="o">=</span> 
  <span class="n">D</span><span class="p">[</span><span class="n">approximateSolution</span><span class="p">,</span> <span class="n">r</span><span class="p">]</span> <span class="p">/</span><span class="o">.</span> <span class="n">r</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">;</span>  <span class="p">(</span><span class="o">*</span><span class="n">Evaluate</span> <span class="n">derivative</span> <span class="n">at</span> <span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="o">*</span><span class="p">)</span>

<span class="n">shootingMethod</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"Shooting"</span><span class="p">,</span> 
   <span class="s2">"StartingInitialConditions"</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">initialGuessY</span><span class="p">,</span> 
   <span class="n">f</span><span class="o">'</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">initialGuessYPrime</span><span class="p">}};</span>

<span class="n">solutionTest1</span> <span class="o">=</span> <span class="n">Module</span><span class="p">[{</span><span class="err">$$</span><span class="n">Eta</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">m1</span> <span class="o">=</span> <span class="mf">0.526</span><span class="err">`</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="mf">1.052</span><span class="err">`</span><span class="p">},</span>
	 <span class="n">shootingMethod</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"Shooting"</span><span class="p">,</span> 
    <span class="s2">"StartingInitialConditions"</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">Pi</span><span class="p">,</span> <span class="n">f</span><span class="o">'</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">6</span><span class="p">}};</span>
  <span class="n">NDSolve</span><span class="p">[{</span><span class="n">eom</span><span class="p">,</span> <span class="n">bc1</span><span class="p">,</span> <span class="n">bc2</span><span class="p">},</span> <span class="n">f</span><span class="p">,</span> <span class="p">{</span><span class="n">r</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">},</span> <span class="n">PrecisionGoal</span> <span class="o">-&gt;</span> <span class="mi">7</span><span class="p">,</span> 
   <span class="n">AccuracyGoal</span> <span class="o">-&gt;</span> <span class="mi">7</span><span class="p">]]</span>
</code></pre></div></div> <p>where eom is short for the equation of motion, given by \(\begin{align} \text{eom} =&amp;-2 r^4 f''(r)-4 \eta r^2 f''(r) \sin ^2(f(r))+4 \eta r^3 f'(r)^3-4 r^3 f'(r)^3-4 r^3 f'(r)-2 \eta r^2 f'(r)^2 \sin (2 f(r)) \\ &amp;+6 \eta r^4 f'(r)^2 f''(r)-6 r^4 f'(r)^2 f''(r)+2 \text{m1}^2 r^4 \sin (f(r))+2 \text{m2}^2 r^4 \sin (f(r)) \\ &amp;-\text{m2}^2 r^4 \sin (2 f(r))+2 r^2 \sin (2 f(r))+\sin (2 f(r))-\sin (2 f(r)) \cos (2 f(r)) \\ &amp;==0. \end{align}\) However the computation takes a long time and yields a nonsensical result, <img src="/img/eom.png" alt=""/></p> <p>which doesn’t make any sense.</p> <hr/> <p>For the following discussions, I found paper <a href="https://arxiv.org/abs/1309.1313">arXiv:1309.1313</a> to be most helpful. Below are some approximation we can adopt at $r\to 0$, \(\frac{\sin(f(r))}{r} \to f'(0), \quad \frac{1}{4}-\frac{\sin^2(f(r))}{r^2} -(f'(r))^2 \to \frac{1}{4}\) \(\frac{r^2}{4} + 2\sin^2(f(r)) = \frac{r^2}{4}\left( 1+8\frac{\sin^2(f(r))}{r^2} \right) \to \frac{r^2}{4}(1+8f'(0)).\)</p> <p>Maybe we can make it work by providing a super accurate initial condition? With this hope I try to solve the equation at the origin, close to $r=0$. Expand $f(r)$ about the origin we get \(f(r) = f(0) + r f'(r) = \pi + rg(r),\quad g(r) := f'(r)\) where we have made use of the initial condition that $f(0)=\pi$, and $r$ is supposed to be very small. Take this to the equation of motion, with some manipulation we get \(\left(-4 r^4 g^{2}(r)-2 r^4\right) g'(r)-2 m_ 1^2 r^5 g(r)-4 m_ 2^2 r^5 g(r)-4 r^3 g^{3}(r) =0\) keep the leading order and NLO in $r$ we have \(\left(2 r g^{2}(r)+r\right) g'(r)+2 g^{3}(r)=0\) In paper arXiv:hep-ph/0106150v2, Ponchiano etc. adopted Pade approximation and it seems to be working good. But it’s not directly useful to me.</p> <p>Well let’s move on to the next method.</p> <h2 id="the-continuation-homotopy-embedding-method">The continuation (homotopy, embedding) method</h2> <p>The core idea behind the “continuation method” is that, instead of trying to solve a super-hard problem right away, we start with a simpler version of it that we can solve. Then, we “continue” from that solution, making small changes step by step, until we reach the solution of the original, harder problem.</p> <ol> <li><strong>Start Simple</strong>: Begin with a version of the problem that’s easy to solve.</li> <li><strong>Make Small Changes</strong>: Adjust the problem little by little, using the solution from the last step as the starting point for the next.</li> <li><strong>Reach the Target</strong>: Continue this process until you’ve transformed your simple problem’s solution into a solution for your original, harder problem.</li> </ol> <p>Let us apply the aforementioned philosophical ideas into practice. Suppose we wish to solve a system of $N$ non-linear equations in $N$ variables, say \(F(x) = 0,\quad F: \mathbb{R}^{n} \to \mathbb{R}^{n}.\) We assume $F$ is $C^{\infty}$. Suppose that we don’t know a lot about the initial value of the derivative, then we can’t effectively adopt the shooting method. As a possible remedy, define a homotopy or deformation $H(x,t)$ which deforms from some simpler equations $G(x)$ to $F(x)$ when $t$ smoothly changes, to be specific define \(H(x,0) = G(x),\quad H(x,1) = F(x).\) Everything is required to be smooth here. Typically, one can choose a so-called <code class="language-plaintext highlighter-rouge">convex homotopy</code> such as \(H(x,t) = t\,F(x) + (1-t)\, G(x).\) $H(x,t)$ is the function we are trying to solve. Our job is to find $G(x)$ with known solution, then the PDE that $H(x,t)$ satisfies, offer the initial condition, then try to solve it.</p> <p>Let’s look at an example. Let’s solve the following non-linear partial differential equation, which is a simplified version of the Ginzburg-Landau equation, a fundamental equation in superconductivity theory: \(\frac{\partial u}{\partial t} = \nabla^2 u + \lambda u - u^3\)</p> <p>Here, $u(x, y, t)$ is the field we want to solve for, $\nabla^2 u$ is the Laplacian operator, $\lambda$ is a parameter, and $t$ represents time.</p> <p>Let’s consider a square domain $[0, L] \times [0, L]$ with periodic boundary conditions. We will solve this equation using the continuation method by gradually increasing the parameter $\lambda$ and using the solution from the previous value of $\lambda$ as the initial condition for the next one.</p> <p>This following code defines the PDE and its boundary conditions, then solves it using <code class="language-plaintext highlighter-rouge">NDSolve</code> for a range of values of $\lambda$, starting from $\lambda = 0$ and going up to $\lambda = 1$. The solution for each value of $\lambda$ is used as the initial condition for the next one. Finally, it plots the solution for $\lambda = 1$.</p> <p>Here is the Mathematica code:</p> <div class="language-mathematica highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">(* Define the domain size *)</span><span class="w">
</span><span class="nv">L</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="o">;</span><span class="w">

</span><span class="c">(* Define the grid size *)</span><span class="w">
</span><span class="nv">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="o">;</span><span class="w">
</span><span class="nv">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="o">;</span><span class="w">

</span><span class="c">(* Define the time step and final time *)</span><span class="w">
</span><span class="nv">dt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.01</span><span class="o">;</span><span class="w">
</span><span class="nv">tmax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">;</span><span class="w">

</span><span class="c">(* Define the initial condition *)</span><span class="w">
</span><span class="nv">u0</span><span class="p">[</span><span class="nv">x</span><span class="o">_,</span><span class="w"> </span><span class="nv">y</span><span class="o">_</span><span class="p">]</span><span class="w"> </span><span class="o">:=</span><span class="w"> </span><span class="nb">Sin</span><span class="p">[(</span><span class="nb">Pi</span><span class="o">*</span><span class="nv">x</span><span class="p">)</span><span class="o">/</span><span class="nv">L</span><span class="p">]</span><span class="w"> </span><span class="nb">Sin</span><span class="p">[(</span><span class="nb">Pi</span><span class="o">*</span><span class="nv">y</span><span class="p">)</span><span class="o">/</span><span class="nv">L</span><span class="p">]</span><span class="o">;</span><span class="w">

</span><span class="c">(* Define the PDE *)</span><span class="w">
</span><span class="nv">pde</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">D</span><span class="p">[</span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">t</span><span class="p">]</span><span class="o">,</span><span class="w"> </span><span class="nv">t</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nb">D</span><span class="p">[</span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">t</span><span class="p">]</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="m">2</span><span class="p">}]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">D</span><span class="p">[</span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">t</span><span class="p">]</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="m">2</span><span class="p">}]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">λ</span><span class="o">*</span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">t</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">t</span><span class="p">]</span><span class="o">^</span><span class="m">3</span><span class="o">;</span><span class="w">

</span><span class="c">(* Solve the PDE using the continuation method *)</span><span class="w">
</span><span class="err">λ</span><span class="nv">values</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Range</span><span class="p">[</span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="m">1</span><span class="o">,</span><span class="w"> </span><span class="m">0.1</span><span class="p">]</span><span class="o">;</span><span class="w">
</span><span class="nv">usol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{}</span><span class="o">;</span><span class="w">
</span><span class="nv">uinit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">u0</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="p">]</span><span class="o">;</span><span class="w">
</span><span class="nb">For</span><span class="p">[</span><span class="nv">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">,</span><span class="w"> </span><span class="nb">Length</span><span class="p">[</span><span class="err">λ</span><span class="nv">values</span><span class="p">]</span><span class="o">,</span><span class="w"> </span><span class="err">λ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">λ</span><span class="nv">values</span><span class="p">[[</span><span class="nv">i</span><span class="p">]]</span><span class="o">;</span><span class="w">
  </span><span class="nv">sol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">NDSolve</span><span class="p">[{</span><span class="nv">pde</span><span class="o">,</span><span class="w"> </span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="m">0</span><span class="p">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nv">uinit</span><span class="o">,</span><span class="w"> 
    </span><span class="nb">PeriodicBoundaryCondition</span><span class="p">[</span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">t</span><span class="p">]</span><span class="o">,</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="nb">TranslationTransform</span><span class="p">[{</span><span class="nv">L</span><span class="o">,</span><span class="w"> </span><span class="m">0</span><span class="p">}]]</span><span class="o">,</span><span class="w">
    </span><span class="nb">PeriodicBoundaryCondition</span><span class="p">[</span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">t</span><span class="p">]</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="nb">TranslationTransform</span><span class="p">[{</span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="nv">L</span><span class="p">}]]}</span><span class="o">,</span><span class="w">
   </span><span class="nv">u</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="nv">L</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="nv">L</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">t</span><span class="o">,</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="nv">tmax</span><span class="p">}</span><span class="o">,</span><span class="w"> 
   </span><span class="nb">Method</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">{</span><span class="s">"MethodOfLines"</span><span class="o">,</span><span class="w"> </span><span class="s">"SpatialDiscretization"</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">{</span><span class="s">"TensorProductGrid"</span><span class="o">,</span><span class="w"> </span><span class="s">"MaxPoints"</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">{</span><span class="nv">nx</span><span class="o">,</span><span class="w"> </span><span class="nv">ny</span><span class="p">}}}]</span><span class="o">;</span><span class="w">
  </span><span class="nb">AppendTo</span><span class="p">[</span><span class="nv">usol</span><span class="o">,</span><span class="w"> </span><span class="nv">sol</span><span class="p">]</span><span class="o">;</span><span class="w">
  </span><span class="nv">uinit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">tmax</span><span class="p">]</span><span class="w"> </span><span class="o">/.</span><span class="w"> </span><span class="nv">sol</span><span class="o">;</span><span class="w">
</span><span class="p">]</span><span class="o">;</span><span class="w">

</span><span class="c">(* Plot the solution for λ = 1 *)</span><span class="w">
</span><span class="nv">sol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">usol</span><span class="p">[[</span><span class="o">-</span><span class="m">1</span><span class="p">]]</span><span class="o">;</span><span class="w">
</span><span class="nb">Plot3D</span><span class="p">[</span><span class="nb">Evaluate</span><span class="p">[</span><span class="nv">u</span><span class="p">[</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="nv">tmax</span><span class="p">]</span><span class="w"> </span><span class="o">/.</span><span class="w"> </span><span class="nv">sol</span><span class="p">]</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">x</span><span class="o">,</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="nv">L</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">y</span><span class="o">,</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="nv">L</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nb">AxesLabel</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">{</span><span class="s">"x"</span><span class="o">,</span><span class="w"> </span><span class="s">"y"</span><span class="o">,</span><span class="w"> </span><span class="s">"u"</span><span class="p">}]</span><span class="w">
</span></code></pre></div></div> <p>But before getting our hands dirty let’s consider another similar but different method, for reasons I’ll explain later.</p> <h2 id="the-relaxation-method">The relaxation method</h2> <p>The term “relaxation” refers to the idea that an initial guess at the solution is iteratively refined or “relaxed” until it converges to the true solution.</p> <p><strong>Introduction to the Relaxation Method:</strong></p> <p>The relaxation method is often used for solving elliptic PDEs, such as Laplace’s equation and Poisson’s equation. The general approach of the relaxation method is as follows:</p> <ol> <li>Discretize the domain of the PDE into a grid or mesh.</li> <li>Make an initial guess for the solution at each grid point.</li> <li>Iteratively update the solution at each grid point using a numerical approximation of the PDE.</li> <li>Repeat step 3 until the solution converges to within a specified tolerance.</li> </ol> <p>Let’s consider an example of solving Laplace’s equation on a rectangular domain $[0, a] \times [0, b]$ with Dirichlet boundary conditions.</p> <p>Laplace’s equation is given by: \(\nabla^2 u(x, y) = 0\)</p> <p>Where $u(x, y)$ is the function we are trying to solve for, and $\nabla^2$ is the Laplacian operator.</p> <p>For simplicity, let’s consider the case where $a = b = 1$, and the boundary conditions are: \(u(0, y) = 0, \quad u(1, y) = 0, \quad u(x, 0) = 0, \quad u(x, 1) = \sin(\pi x)\)</p> <p>Here are the steps to solve this problem using the relaxation method in Mathematica:</p> <div class="language-mathematica highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">(* Define the domain size *)</span><span class="w">
</span><span class="nv">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">;</span><span class="w">
</span><span class="nv">b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">;</span><span class="w">

</span><span class="c">(* Define the grid size *)</span><span class="w">
</span><span class="nv">nx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="o">;</span><span class="w">
</span><span class="nv">ny</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="o">;</span><span class="w">

</span><span class="c">(* Define the boundary conditions *)</span><span class="w">
</span><span class="nv">u</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Table</span><span class="p">[</span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">}]</span><span class="o">;</span><span class="w">
</span><span class="nb">Do</span><span class="p">[</span><span class="nv">u</span><span class="p">[[</span><span class="m">1</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">j</span><span class="o">,</span><span class="w"> </span><span class="nv">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">}]</span><span class="o">;</span><span class="w">
</span><span class="nb">Do</span><span class="p">[</span><span class="nv">u</span><span class="p">[[</span><span class="nv">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">j</span><span class="o">,</span><span class="w"> </span><span class="nv">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">}]</span><span class="o">;</span><span class="w">
</span><span class="nb">Do</span><span class="p">[</span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="m">1</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">}]</span><span class="o">;</span><span class="w">
</span><span class="nb">Do</span><span class="p">[</span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">ny</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Sin</span><span class="p">[</span><span class="nb">Pi</span><span class="o">*</span><span class="p">(</span><span class="nv">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">)</span><span class="o">/</span><span class="nv">nx</span><span class="p">]</span><span class="o">,</span><span class="w"> </span><span class="p">{</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">nx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">}]</span><span class="o">;</span><span class="w">

</span><span class="c">(* Define the relaxation parameter *)</span><span class="w">
</span><span class="nv">omega</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.5</span><span class="o">;</span><span class="w">

</span><span class="c">(* Define the tolerance for convergence *)</span><span class="w">
</span><span class="nv">tol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">10</span><span class="o">^</span><span class="p">(</span><span class="o">-</span><span class="m">6</span><span class="p">)</span><span class="o">;</span><span class="w">

</span><span class="c">(* Perform the relaxation iteration *)</span><span class="w">
</span><span class="nv">iteration</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="o">;</span><span class="w">
</span><span class="nv">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">;</span><span class="w">
</span><span class="nb">While</span><span class="p">[</span><span class="nv">error</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nv">tol</span><span class="o">,</span><span class="w">
  </span><span class="nv">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="o">;</span><span class="w">
  </span><span class="nb">For</span><span class="p">[</span><span class="nv">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="o">,</span><span class="w"> </span><span class="nv">i</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="nv">nx</span><span class="o">,</span><span class="w"> </span><span class="nv">i</span><span class="o">++,</span><span class="w">
    </span><span class="nb">For</span><span class="p">[</span><span class="nv">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="nv">ny</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="o">++,</span><span class="w">
      </span><span class="nv">old</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="p">]]</span><span class="o">;</span><span class="w">
      </span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="p">]]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="m">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nv">omega</span><span class="p">)</span><span class="o">*</span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="p">]]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">omega</span><span class="o">*</span><span class="m">0.25</span><span class="o">*</span><span class="p">(</span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="p">]]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="p">]]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="m">1</span><span class="p">]]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="m">1</span><span class="p">]])</span><span class="o">;</span><span class="w">
      </span><span class="nv">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Max</span><span class="p">[</span><span class="nv">error</span><span class="o">,</span><span class="w"> </span><span class="nb">Abs</span><span class="p">[</span><span class="nv">u</span><span class="p">[[</span><span class="nv">i</span><span class="o">,</span><span class="w"> </span><span class="nv">j</span><span class="p">]]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nv">old</span><span class="p">]]</span><span class="o">;</span><span class="w">
    </span><span class="p">]</span><span class="o">;</span><span class="w">
  </span><span class="p">]</span><span class="o">;</span><span class="w">
  </span><span class="nv">iteration</span><span class="o">++;</span><span class="w">
</span><span class="p">]</span><span class="o">;</span><span class="w">

</span><span class="c">(* Display the result *)</span><span class="w">
</span><span class="nv">u</span><span class="w">
</span></code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">u</code> matrix contains the approximate solution to the PDE at each grid point. The <code class="language-plaintext highlighter-rouge">While</code> loop continues iterating until the maximum change in the solution at any grid point is less than the specified tolerance <code class="language-plaintext highlighter-rouge">tol</code>.</p> <p>The relaxation method is a powerful and widely used numerical technique for solving PDEs. It is particularly well-suited for solving elliptic PDEs, such as Laplace’s equation and Poisson’s equation, which arise in various physical applications. The method is relatively simple to implement and can be easily adapted to different types of PDEs and boundary conditions.</p> <p>However, it’s important to note that the convergence of the relaxation method can be sensitive to the choice of the relaxation parameter <code class="language-plaintext highlighter-rouge">omega</code> and the grid size. In some cases, it may be necessary to experiment with different values of these parameters to achieve a satisfactory solution.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1" role="doc-endnote"> <p>Nuclear Physics B233 (1984) 109-115, doi: 10.1016/0550-3213(84)90172-x <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Introduction]]></summary></entry></feed>