<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://baiyangzhang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://baiyangzhang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-10-13T12:09:03+00:00</updated><id>https://baiyangzhang.github.io/feed.xml</id><title type="html">Baiyang Zhang</title><subtitle>A place dedicated to sharing insights and reflections on mathematics, physics, and social sciences. </subtitle><entry><title type="html">Calculating States Using Diagrams</title><link href="https://baiyangzhang.github.io/blog/2024/Calculating-States-Using-Diagrams/" rel="alternate" type="text/html" title="Calculating States Using Diagrams"/><published>2024-10-13T00:00:00+00:00</published><updated>2024-10-13T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Calculating-States-Using-Diagrams</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Calculating-States-Using-Diagrams/"><![CDATA[<h1 id="rules-for-hamiltonians">Rules for Hamiltonians</h1> <h2 id="rules-for-h_-3-">Rules for $H_ {3}^{(-)}$</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/H3Rules-480.webp 480w,/img/kink/H3Rules-800.webp 800w,/img/kink/H3Rules-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/H3Rules.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.1. Rules for various components of $H_3$. I regard them as vertices. The meaning of graphical elements are explain later. </div> <h2 id="rules-for-h_-4-">Rules for $H_ {4}^{(-)}$</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/H4Rules-480.webp 480w,/img/kink/H4Rules-800.webp 800w,/img/kink/H4Rules-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/H4Rules.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.2. Rules for various components of $H_4$. </div> <h2 id="rules-for-h_-5-">Rules for $H_ {5}^{(-)}$</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/H5Rules-480.webp 480w,/img/kink/H5Rules-800.webp 800w,/img/kink/H5Rules-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/H5Rules.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.3. Rules for various components of $H_5$. The coefficients $C_ {5,3}$ and $C_ {5,1}$ are made of counter terms. In specific we have $C_ {3}= \frac{m\delta g}{\sqrt{2}} +\frac{g \delta m_ {1}^{2}}{2\sqrt{2}m} - \frac{m^{2}\delta m_ {1}^{4}}{2\sqrt{2}g}$ and $C_ {1}= m^{2}\delta v_ {3}-\frac{3gm\mathcal{I}_ {1}}{\sqrt{2}}+\frac{m^{3}\delta g^{2}}{\sqrt{2}g^{3}}-\frac{m \delta g\delta m_ {1}^{2}}{2\sqrt{2}g^{2}} -\frac{\delta m_ {1}^{4}}{8\sqrt{2}gm}$. </div> <h1 id="diagrams-for-states">Diagrams for States</h1> <h2 id="leading-order">Leading Order</h2> <p>At leading order there is one vacuum state correction and two momentum eigenstate corrections, their diagrammatic expressions are given in the figure below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/LOStates-480.webp 480w,/img/kink/LOStates-800.webp 800w,/img/kink/LOStates-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/LOStates.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.4. States at leading order. The first panel gives the leading order correction to the vacuum state, while the second and third panel gives the leading order correction to momentum states. </div> <h2 id="next-leading-order">Next Leading Order</h2> <p>The fundamental diagrams for $\left\lvert \vec{p} \right\rangle_ {2}^{(-)}$ are shown in the below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/p2Fundamental-480.webp 480w,/img/kink/p2Fundamental-800.webp 800w,/img/kink/p2Fundamental-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/p2Fundamental.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig. 5. Fundamental diagrams of $g^2$ corrections to $\left\lvert \vec{p} \right\rangle_ {2}^{(-)}$ States. By fundamental I mean the diagrams directly built up block-by-block by Hamiltonians and lower order states. Fundamental diagrams are good for study the cancelation between loops and counter terms. After the renormalization procedure is done, based on the number of extarnal legs, the fundamental diagrams can ben summed over to give more concise, summarized diagrams. </div> <p>Let’s number the diagrams left to right, top to bottom. The contributions are</p> \[\begin{align*} (1) :\;&amp; H_ {4}^{(4)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} = \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \left\lvert \vec{p},\vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0} , \\ (2) :\;&amp; H_ {3}^{(3)} \left\lvert \vec{p} \right\rangle_ {1}^{(2)} = \frac{3g^{2}m^{2}}{4\omega_ {p}}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}-\vec{p}_ {3}, \vec{p}_ {1,2,3,-1-2} \right\rangle_ {0}}{\omega _ {p}-\omega_ {3}-\omega_ {p-p_ {3}}} , \\ (3) :\;&amp; H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} = -\frac{m^{2}g^{2}}{2} \int \frac{d^{3}p_ {1,2,3,4}}{(2\pi)^{12}} \, \frac{\left\lvert \vec{p},\vec{p}_ {1,2,3,4,-1-2,-3-4} \right\rangle_ {0}}{\omega_ {1}+\omega_ {2}+\omega_ {1+2}}, \\ (4) :\;&amp; H_ {3}^{(1)} \left\lvert \vec{p} \right\rangle_ {1}^{(4)} \supset - \frac{3g^{2}m^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{3\left\lvert \vec{p},\vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{\omega_ {2+3}(\omega_ {1}+\omega_ {2+3}+\omega_ {1+2+3})} , \\ (5) :\;&amp; H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} = - \frac{9g^{2}m^{2}}{4\omega_ {p}} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}-\vec{p}_ {1}-\vec{p}_ {2},\vec{p}_ {1,2} \right\rangle_ {0}}{\omega_ {1+2}(-\omega _ {p} +\omega_ {p-p_ {1}-p_ {2}}+\omega_ {1+2})} , \\ (6) :\;&amp; H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} \supset - \frac{3g^{2}m^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}_ {1,2,3,-1-2},\vec{p}-\vec{p}_ {3} \right\rangle_ {0}}{\omega_ {p}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} , \\ (7) :\;&amp; H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} = -\frac{9g^{2}m^{2}}{8\omega _ {p} } \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p} \right\rangle_ {0}}{\omega_ {1}\omega_ {p+p_ {1}}(-\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})}, \\ (8) :\;&amp; H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} \supset - \frac{9m^{2}g^{2}}{4\omega _ {p} } \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}-\vec{p}_ {1}-\vec{p}_ {2},\vec{p}_ {1,2} \right\rangle_ {0}}{\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ (9) :\;&amp; H_ {3}^{(-3)}\left\lvert p \right\rangle_ {1}^{(4)} \supset - \frac{3}{8}g^{2}m^{2}\left\lvert \vec{p} \right\rangle_ {0}\int d^{3}x \, \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{1}{\omega_ {1}\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ (10) :\;&amp; - H_ {3}^{(-3)}\left\lvert p \right\rangle_ {1}^{(4)} \supset \frac{9g^{2}m^{2}\left\lvert \vec{p} \right\rangle_ {0}}{8\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{1}{\omega_ {1}\omega_ {p+p_ {1}}(\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})} \\ (11) :\;&amp; H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} \supset - \frac{9m^{2}g^{2}}{4} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p},\vec{p}_ {1,-1} \right\rangle_ {0}}{\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ (12) :\;&amp; H_ {4}^{(0)}\left\lvert p \right\rangle_ {0}^{(1)} \supset \int d^{3}x \, A_ {4}' \end{align*}\] <p>But in order to turn them into diagrammatic rules, we need to inverse $(\omega _ {p}-H_ {2})$ to get components of $\left\lvert \vec{p} \right\rangle_ {2}$, eliminate the integral measures and deal with the creation operators. Hence, <strong>as diagrammatic rules we get</strong>:</p> \[\begin{align*} (1) :\;&amp; H_ {4}^{(4)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} : -\frac{g^{2}}{4(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3})} , \\ (2) :\;&amp; H_ {3}^{(3)} \left\lvert \vec{p} \right\rangle_ {1}^{(2)} :\frac{3g^{2}m^{2}}{4\omega_ {p}} \frac{1}{(-\omega _ {p}+\omega_ {3}+\omega_ {p-p_ {3}})(-\omega _ {p} +\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2}+\omega_ {p-p_ {3}})} , \\ (3) :\;&amp; H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)}:\frac{m^{2}g^{2}}{2(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {4}+\omega_ {1+2}+\omega_ {3+4})}, \\ (4) :\;&amp; H_ {3}^{(1)} \left\lvert \vec{p} \right\rangle_ {1}^{(4)} : \frac{9g^{2}m^{2}}{4\omega_ {2+3}(\omega_ {1}+\omega_ {2+3}+\omega_ {1+2+3})(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3})} , \\ (5) : \;&amp; H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} : \frac{9g^{2}m^{2}}{4\omega_ {p}}\frac{1}{\omega_ {1+2}(-\omega _ {p} +\omega_ {p-p_ {1}-p_ {2}}+\omega_ {1+2})(-\omega _ {p} +\omega_ {1}+\omega_ {2}+\omega_ {p-p_ {1}-p_ {2}})} , \\ (6) :\;&amp; H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} : \frac{3g^{2}m^{2}}{4\omega_ {p}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(-\omega _ {p} +\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2}+\omega_ {p-p_ {3}})} , \\ (7) :\;&amp; H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} = -\frac{9g^{2}m^{2}}{8\omega _ {p} } \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p} \right\rangle_ {0}}{\omega_ {1}\omega_ {p+p_ {1}}(-\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})}, \\ (8) :\;&amp; H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} \supset - \frac{9m^{2}g^{2}}{4\omega _ {p} } \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}-\vec{p}_ {1}-\vec{p}_ {2},\vec{p}_ {1,2} \right\rangle_ {0}}{\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ (9) :\;&amp; H_ {3}^{(-3)}\left\lvert p \right\rangle_ {1}^{(4)} \supset - \frac{3}{8}g^{2}m^{2}\left\lvert \vec{p} \right\rangle_ {0}\int d^{3}x \, \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{1}{\omega_ {1}\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ (10) :\;&amp; - H_ {3}^{(-3)}\left\lvert p \right\rangle_ {1}^{(4)} \supset \frac{9g^{2}m^{2}\left\lvert \vec{p} \right\rangle_ {0}}{8\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{1}{\omega_ {1}\omega_ {p+p_ {1}}(\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})} \\ (11) :\;&amp; H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} \supset - \frac{9m^{2}g^{2}}{4} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p},\vec{p}_ {1,-1} \right\rangle_ {0}}{\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ (12) :\;&amp; H_ {4}^{(0)}\left\lvert p \right\rangle_ {0}^{(1)} \supset \int d^{3}x \, A_ {4}' \end{align*}\] <h2 id="3rd-order-states">3rd Order States</h2> <p>Let’s start with momentum states.</p> <h3 id="leftlvert-vecp-rightrangle_-32">$\left\lvert \vec{p} \right\rangle_ {3}^{(2)}$</h3> <p>$H_ {3}^{(-3)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)}$:</p> <p>It include two contributions: $H_ {3}^{(-3)}$ acting on panel (4) and panel (6) from figure (5). Let’s denote them by $H_ {3}^{(-3)}\cdot(4)$ and $H_ {3}^{(-3)}\cdot(6)$ respectively. Regarding the former we have</p> \[\begin{align*} (a) =&amp; - \frac{81m^{3}g^{3}}{8\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \left\lvert \vec{p}_ {1},\vec{p}-\vec{p}_ {1} \right\rangle \int \frac{d^{3} p_ {2}}{(2\pi)^{3}} \, \frac{1}{\omega_ {1}\omega_ {2}\omega^{2}_ {1+2}} \\ &amp;\times \frac{1}{(\omega_ {1}+\omega_ {1+2}+\omega_ {2p_ {1}+2})(\omega_ {1}+\omega_ {1+2}+\omega_ {3}+\omega_ {2p_ {1}+2})},\\ (b) =&amp; - \frac{81m^{3} g^{3}}{16\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \left\lvert \vec{p},\vec{p}-\vec{p}_ {1} \right\rangle \int \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{1}{\omega_ {2}\omega _ {p} \omega^{2}_ {p-2}} \\ &amp;\times \frac{1}{(\omega_ {1}+\omega_ {2-p}+\omega_ {1+2-p})(\omega_ {1}+\omega_ {2}+\omega _ {p} +\omega_ {1+2-p})}, \\ (c) &amp;= - \frac{27m^{3}g^{3}}{16\sqrt{2}} \int d^{3}x \, \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \left\lvert \vec{p},\vec{p}-\vec{p}_ {1} \right\rangle \int \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{1}{\omega_ {2}\omega_ {3}\omega_ {2+3}} \\ &amp;\times \frac{1}{\omega_ {1+2}(\omega_ {3}+\omega_ {1+2}+\omega_ {1+2+3})(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3})}. \end{align*}\] <p>Regarding the latter we have</p> <p>\(\begin{align*} (d) =&amp; - \frac{3m^{3}g^{3}\left\lvert \vec{p},0 \right\rangle}{4\sqrt{2}} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{1}{\omega_ {1}\omega_ {2}\omega_ {1+2}\omega_ {p}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ &amp;\times \frac{1}{(-\omega _ {p} +\omega_ {1}+\omega_ {2}+2\omega_ {1+2}+\omega_ {p-p_ {1}-p_ {2}})},\\ (e) =&amp; - \frac{9m^{3}g^{3}}{4\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \left\lvert \vec{p},\vec{p}-\vec{p}_ {1} \right\rangle \int \frac{d^{3}p_ {2,3}}{(2\pi)^{6}} \, \frac{1}{\omega_ {2}\omega_ {3}\omega^{2} _ {p} } \\ &amp;\times \frac{1}{ (\omega_ {2}+\omega_ {3}+\omega_ {2+3})(-\omega _ {p} +\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {2+3}+\omega_ {p-p_ {1}})} ,\\ (f) =&amp; - \frac{9m^{3}g^{3}}{4\sqrt{2}} \int \frac{d ^{3}p_ {1}}{(2\pi)^{3}} \, \left\lvert \vec{p},\vec{p}-\vec{p}_ {1} \right\rangle \int \frac{d^{3}p_ {2,3}}{(2\pi)^{6}} \, \frac{1}{\omega_ {2}\omega_ {3}\omega _ {p} ^{2}} \\ &amp; \times \frac{1}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(-\omega _ {p} +\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2}+\omega _ {p-p_ {3}} )} .\\ \end{align*}\)\</p> <p>The diagrams are shown below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/H3Minus3OnP25-480.webp 480w,/img/kink/H3Minus3OnP25-800.webp 800w,/img/kink/H3Minus3OnP25-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/H3Minus3OnP25.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig. 6. The diagrams of $H_3^{(-3)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)}$. </div> <hr/> <h3 id="reducible-diagrams">Reducible Diagrams</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/3rdOrderReducible-480.webp 480w,/img/kink/3rdOrderReducible-800.webp 800w,/img/kink/3rdOrderReducible-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/3rdOrderReducible.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The blob stands for all divergent diagrams. These three are the divergent contributions to $\left\lvert \vec{p} \right\rangle_ {3}^{(2)}$, in the sense that they can be amputated by cutting an external leg. </div> <p>Now we can sum up the previous results and organize diagrams according to their topology.</p> <p>For the reducible diagrams we have</p> \[\begin{align*} H_ {4}^{(0)} \left\lvert \vec{p} \right\rangle_ {1}^{(2)} =&amp; - \frac{3m\delta m^{2}g}{2\sqrt{2}\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}_ {1}, \vec{p}-\vec{p}_ {1} \right\rangle_ {0}}{\omega_ {1}(-\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})},\\ H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(3)} =&amp; - \frac{27m^{3}g^{3}}{8\sqrt{2}\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi^{3})} \, \frac{\left\lvert \vec{p}_ {1},\vec{p}-\vec{p}_ {1} \right\rangle_ {0}}{\omega_ {1}(-\omega _ {p} +\omega_ {1}+\omega_ { p-p_ {1}})} \\ &amp;\times \int \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{1}{\omega_ {1+2}\omega_ {2}(-\omega _ {p} +\omega_ {1+2}+\omega_ {2}+\omega_ {p-p_ {1}})}, \\ H_ {3}^{(-3)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)} &amp;= - \frac{27m^{3}g^{3}}{8\sqrt{2}\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \frac{\left\lvert \vec{p}_ {1}, \vec{p}-\vec{p}_ {1} \right\rangle}{\omega_ {1}(-\omega _ {p} +\omega_ {1}+\omega_ {p-p_ {1}})} \\ &amp;\times \int \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{1}{\omega_ {2}\omega_ {1+2}(-\omega _ {p} +2\omega_ {1}+\omega_ {2}+\omega_ {1+2}+\omega_ {p-p_ {1}})} \end{align*}\]]]></content><author><name>Baiyang Zhang</name></author><category term="kink"/><summary type="html"><![CDATA[Rules for Hamiltonians Rules for $H_ {3}^{(-)}$]]></summary></entry><entry><title type="html">Asymptotic Methods Applied on Anharmonic Oscillator</title><link href="https://baiyangzhang.github.io/blog/2024/Asymptotic-Methods-Applied-on-Anharmonic-Oscillator/" rel="alternate" type="text/html" title="Asymptotic Methods Applied on Anharmonic Oscillator"/><published>2024-10-11T00:00:00+00:00</published><updated>2024-10-11T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Asymptotic-Methods-Applied-on-Anharmonic-Oscillator</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Asymptotic-Methods-Applied-on-Anharmonic-Oscillator/"><![CDATA[<h1 id="chapter-1">Chapter 1</h1>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[Chapter 1]]></summary></entry><entry><title type="html">Diagrammatic Rules for Jarah Diagrams</title><link href="https://baiyangzhang.github.io/blog/2024/Rules-for-Jarah-Diagrams/" rel="alternate" type="text/html" title="Diagrammatic Rules for Jarah Diagrams"/><published>2024-09-18T00:00:00+00:00</published><updated>2024-09-18T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Rules-for-Jarah-Diagrams</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Rules-for-Jarah-Diagrams/"><![CDATA[<p>These rules are currently being used by myself and no one else, it is by no means standard or widely accepted. I find it extremely fun to play with those rules and diagrams.</p> <p>The rules are shown in the figures below. The numbers label the momentum, for example $1$ stands for $\vec{p}_ {1}$. We only need to label the independent momenta for two reasons: 1) each vertex conserves the momenta hence we can fix the not-labeled momentum without problem and 2) it is important to balance the momenta and delta functions, as we will explain later. One of the various kinds of divergences, namely a factor of $(2\pi)^{3}\delta^{3}(0)$ or equivalently (not mathematically rigorously though) $\int d^3x$ comes from the fact that the Dirac delta functions over-determine the momenta, it is also included in the diagrammatic method.</p> <p>In the following rules, some factors (such as a factor of 3) is perhaps better treated as symmetry factors, but for practical purpose I treat them as part of the definition of the the vertices.</p> <p>I note that the diagrams I have are used to calculate quantities such as $H_ {3}\left\lvert \vec{p} \right\rangle_ {1},H_ {4}\left\lvert \Omega \right\rangle_ {2}$ only, in order to obtain the final <strong>state</strong> we need to further invert some operators. The inversion is quite straightforward though.</p> <h1 id="rules-for-hamiltonians">Rules for Hamiltonians</h1> <h2 id="rules-for-h_-3-">Rules for $H_ {3}^{(-)}$</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/H3Rules-480.webp 480w,/img/kink/H3Rules-800.webp 800w,/img/kink/H3Rules-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/H3Rules.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.1. Rules for various components of $H_3$. I regard them as vertices. The meaning of graphical elements are explain later. </div> <h2 id="rules-for-h_-4-">Rules for $H_ {4}^{(-)}$</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/H4Rules-480.webp 480w,/img/kink/H4Rules-800.webp 800w,/img/kink/H4Rules-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/H4Rules.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Fig.2. Rules for various components of $H_4$. </div> <h1 id="feynman-like-rules">Feynman-like Rules</h1> <p>With above ingredients we may introduce the rules to connect them now.</p> <p>Roughly speaking we find all the possible way to concatenate a Hamiltonian to a state. Each red circle indicates that it must be concatenated to some other line to form a propagator, if not the diagram vanishes. After the concatenation we still need to <em>balance the momenta against the delta functions</em> (I am not sure if balance is the right verb here), as we will explain shortly.</p> <p>For example, say we want to calculate $H_ {4}^{(2)}\left\lvert \Omega\right\rangle_ {0}$, we need to do the following:</p> <ol> <li>Find the diagrams corresponding to $H_ {4}^{(2)}$, there are two of them. Find the diagram corresponding to $\left\lvert \Omega \right\rangle_ {0}$, there is only one.</li> <li>Put the diagrams from $H_ {4}^{(2)}$ on the left and that from $\left\lvert \Omega \right\rangle_ {0}$ on the right, with all the independent momenta labeled in the fashion that is given in the figures below. Find all the possible ways to concatenate them.</li> <li>For each concatenation, write down the symmetry factor first. There is usually more than one way to connect a circle to a leg (in the diagram of $\left\lvert \Omega \right\rangle_ {0}$), the number of doing that is the symmetry factor.</li> <li>If a circle is connected to two independent labeled momenta, we’ll call it “fully labeled.” If it’s connected to only one labeled momentum, we’ll call it “half-labeled.” Arrange the labels so that <strong>as many circles as possible are fully labeled</strong>. Each circle will cancel out a connected momentum, and you can cross them off simultaneously. If a circle isn’t connected to any labeled momentum, chance is they will survive the balancing process and give us a divergent factor. It’s easier than it sounds. Once you’ve crossed them off, replace the circle with an arrow pointing in the direction of increasing coupling. A line with an arrow represents a regular propagator.</li> <li>If there is a circle that no matter how to label and re-label the independent momenta still can’t be eliminated, keep it, a circle connected with two legs is an irregular propagator, it will contribute a factor of $\int d^{3}x$, or $(2\pi)^{3}\delta^{3}(0)$.</li> <li>Use the momentum conservation at each vertex to write down the momentum for each leg, external and internal. They should all be expressed in terms of independent momenta.</li> <li>Read from left to right, don’t forget to write down the symmetry factor. The left-most external legs give us the final state, each of them gives us an momentum eigenstate. <strong>If there is not a single leg then the state is $\left\lvert \Omega \right\rangle_ {0}$</strong>. Whenever you see an independent momentum, write the integral measure $\int d^3p / (2\pi)^{3}$. Whenever you see a propagator, write down the corresponding factor, which is listed in the figure below. Write down the expression for the vertex and the state.</li> <li>Simplify and check.</li> </ol> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/jarahRules-480.webp 480w,/img/kink/jarahRules-800.webp 800w,/img/kink/jarahRules-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/jarahRules.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Rules for two kinds of propagators, regular and circled ones. Each regular propagator contributes a factor of $\frac{1}{2\omega}$, in the mean while a circled propagator contributes an extra divergent factor of $\int d^3 x$, or $(2\pi)^3\delta^3(0)$ as I sometimes like to write. </div> <h1 id="some-examples">Some examples</h1> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/example-480.webp 480w,/img/kink/example-800.webp 800w,/img/kink/example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Here is an example of how to calculate $H_ 3^{(-3)}\lvert\Omega\rangle_ 1^{(3)}$. Here the first factor $6$ comes from the 6 different ways to connect the circles. The top two circles are fully labeled, the buttom one has no label at all, thus there is no independent momentum to ballance against the circle. It contributes the spatial integral in the final expression. Since all the vertices preserve the momenta, and the top to propogators are labeled with $p_ 1$ and $p_ 2$, the last line is fixed to be $-p_ 1-p_ 2$. It is not common to encounter an irregular propagator. There is no external leg on the left-most of the diagram, hence we assign $\left\lvert \Omega \right\rangle_ {0}$ to it. </div>]]></content><author><name>Baiyang Zhang</name></author><category term="kink"/><summary type="html"><![CDATA[These rules are currently being used by myself and no one else, it is by no means standard or widely accepted. I find it extremely fun to play with those rules and diagrams.]]></summary></entry><entry><title type="html">Quantum Domain Wall in 4D Part II</title><link href="https://baiyangzhang.github.io/blog/2024/Constructing-a-Finite-Tension-Domain-Wall-in-4D-Part-II/" rel="alternate" type="text/html" title="Quantum Domain Wall in 4D Part II"/><published>2024-08-25T00:00:00+00:00</published><updated>2024-08-25T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Constructing-a-Finite-Tension-Domain-Wall-in-4D-Part-II</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Constructing-a-Finite-Tension-Domain-Wall-in-4D-Part-II/"><![CDATA[<h1 id="spontaneous-symmetry-breaking">Spontaneous Symmetry Breaking</h1> <p>Recall that the original, un-shifted Hamiltonian in terms of bare parameter, without normal ordering reads</p> \[\hat{\mathcal{H}}^{0}(\vec{x}) = \frac{1}{2}\pi^{2}(\vec{x})+\frac{1}{2} (\partial_ {i}\phi)^{2} - \frac{m_ {0}^{2}}{4} \phi^{2}(\vec{x}) + \frac{\lambda_ {0}}{4} \phi^{4}(\vec{x}) + A,\] <p>It has two classical minima are obtained at $\pm \frac{m_ {0}}{\sqrt{ 2\lambda_ {0} }}$. As a result we have two degenerate vacua states $\left\lvert{0^{\pm}}\right\rangle$ satisfying</p> \[\left\langle{0^{-}}\right\rvert \phi \left\lvert{0^{-}}\right\rangle =- \frac{m_ {0}}{\sqrt{ 2\lambda_ {0} }},\quad \left\langle{0^{+}}\right\rvert \phi \left\lvert{0^{+}}\right\rangle =+ \frac{m_ {0}}{\sqrt{ 2\lambda_ {0} }}\] <p>Now we want to study the quantum physics around one of the vacua, say $\left\langle \phi \right\rangle = \frac{m_ {0}}{\sqrt{ 2\lambda_ {0} }}$, and we want to apply perturbation methods, since it is usually the only way we know how to proceed. The question is how to do perturbation theory with Hamiltonian formalism? For the validation of perturbation method, the field fluctuation should be small, meaning $\left\langle \phi \right\rangle$ should be small, but it is clearly not the case here, since $m_ {0} / \sqrt{ 2 } g_ {0}$ is not small by any sense.</p> <hr/> <p>Another thing we need to keep in mind is the difference between bare and renormalized parameters, eventually we need to write down the observables in terms of not bare, but renormalized parameters. Following the philosophy of <em>renormalized perturbative method</em>, we should 1) separate the Hamiltonian into renormalized terms and counter terms, then 2) use the counter terms to cancel the divergence from loops, which are now written in terms of renormalized parameters. We wrote the vev of $\phi$ in terms of bare parameters, but that is only for pedagogical reasons, what we should really do it first write the Hamiltonian into the renormalized perturbation theory form,</p> \[\hat{\mathcal{H}} = \frac{1}{2}\pi^{2}(\vec{x})+\frac{1}{2} (\partial_ {i}\phi)^{2} - \frac{m^{2}}{4} \phi^{2}(\vec{x}) + \frac{\lambda}{4} \phi^{4}(\vec{x}) + A + \text{counter terms,}\] <p>then look for the minimum of the double-well potential, now $\left\langle \phi \right\rangle = m / \sqrt{ 2 }g$, with out naught subscript.</p> <hr/> <p>The last but not the least thing we need to worry about is the normal ordering. So far my assumption is that, the Hamiltonian is defined at some intrinsic parameter $m_ {0}$, so the normal ordering should also be defined at $m_ {0}$; however, to make the calculation easier, we shift the normal ordering to another scale: $m$. We have already talked in length about how to perform this shift. The final result should not depend on the shift though.</p> <hr/> <p>In the context of Lagrangian formalism and path integral, the perturbation method is quite straightforward, we can redefine the field operator according to $\phi\to \frac{m }{\sqrt{ 2\lambda }}+\phi’$, so that the classical vacuum is obtained at $\phi’$ equals zero. The small fluctuation about $\frac{m }{\sqrt{ 2\lambda }}$ gives us the quantum effects, we will essentially calculate</p> \[Z[J] = \int D\phi' \, \exp \left\lbrace iS[\phi']+i \int \phi' J \right\rbrace ,\] <p>but only include $\phi’\sim 0$.</p> <p>How can we do the same thing but with Hamiltonian formalism? Anything that can be done with one formalism can equally be done in the other, it is just a matter of convenience.</p> <p>The problem is, in Hamiltonian formalism and working with $\hat{\mathcal{H}}$, perturbation methods are just not applicable, because the expectation value $\left\langle \phi \right\rangle := \left\langle{0^{+}}\right\rvert \phi \left\lvert{0^{+}}\right\rangle$ is by no means a small quantity, in fact $\left\langle \phi \right\rangle$ scales as $1 / \sqrt{ \lambda }$, it actually blows up as $\lambda \to 0$. Then, similar to the Lagrangian case, we need to find some new field operator $\phi’$ such that $\left\langle \phi’ \right\rangle=0$, then we can study the effects of fluctuation of $\left\langle \phi’ \right\rangle$ perturbative in $\left\lvert{0^{+}}\right\rangle$ state. Turns out, $\phi’$ is connected to $\phi$ by a unitary transformation, and in the case at hand the unitary operator turns out to be the displacement operator $\mathcal{D}_ {v }$, where $v $ is some parameter to be determined. Note that we have replaced the arbitrary function $f(\vec{x})$ with a constant function $v $. We will explain it in the following.</p> <p>Recall the defining property of displacement operator, $\mathcal{D}_ {f}^{\dagger}\phi \mathcal{D}_ {f}=\phi+f$. Thus if we let</p> \[\boxed{ v = -\frac{m }{\sqrt{ 2\lambda }} }\] <p>then (at least at leading order)</p> \[\left\langle{0^{+}}\right\rvert \mathcal{D}_ {v }^{\dagger} \phi \mathcal{D}_ {v }\left\lvert{0^{+}}\right\rangle = \left\langle{0^{+}}\right\rvert \phi+v \left\lvert{0^{+}}\right\rangle = \frac{m }{\sqrt{ 2\lambda }}-\frac{m }{\sqrt{ 2\lambda }}=0,\] <p>hence</p> \[\boxed{ 0=\left\langle{0^{+}}\right\rvert \phi'\left\lvert{0^{+}}\right\rangle, \quad \phi':= \mathcal{D}_ {v }^{\dagger}\phi \mathcal{D}_ {v }. }\] <p>It inspires us to define a new Hamiltonian exactly in the same fashion,</p> \[\boxed{ \mathcal{H} := \mathcal{D}_ {v }^{\dagger} \hat{\mathcal{H}} \mathcal{D}_ {v }. }\] <p>We are interested in the spectrum of the Hamiltonian. The good news is that, a unitary transformation preserves the spectrum! Now, in order to study the quantum correction, instead of working with $\hat{H}$, $\phi$ and $\left\lvert{0^{+}}\right\rangle$ where perturbative methods fail, we can work with $H, \phi’$ and $\left\lvert{0^{+}}\right\rangle$ where $\phi’$ can be dealt with perturbatively.</p> <p><strong>Remarks.</strong> Generally speaking, let $\mathcal{O}$ be any operator and $\left\lvert{\psi}\right\rangle$ its eigenstate. If $\mathcal{O}’=\mathcal{D}^{\dagger}\mathcal{O} \mathcal{D}$ is the unitary transformation of $\mathcal{O}$, then its eigenstate is $\mathcal{D}^{\dagger}\left\lvert{\psi}\right\rangle$, not $\left\lvert{\psi}\right\rangle$. It may seem weird to some people to team up $\mathcal{O}’$ and $\left\lvert{\psi}\right\rangle$, not $\mathcal{O}’$ and $\mathcal{D}^{\dagger}\left\lvert{\psi}\right\rangle$. In fact, it is exactly the point of our method! If we pair $\mathcal{O}’$ with $\mathcal{D}^{\dagger}\left\lvert{\psi}\right\rangle$ it would be a trivial transform compare to working with $\mathcal{O}$ and $\left\lvert{\psi}\right\rangle$, we will not get anything new! Paring up $\mathcal{O}’$ and $\left\lvert{\psi}\right\rangle$ makes it possible for perturbation methods. However, since $\left\lvert{\psi}\right\rangle$ is not the eigen state of $\mathcal{O}’$, it indeed raise some problems, the first and foremost is that now $\mathcal{O}’$ is probably not diagonalized in $\left\lvert{\psi}\right\rangle$, we need to find a way to diagonalized it. In our current case, since the displacement operator only shifts the operators by a constant, it actually preserves the diagonalization, meaning if $\hat{\mathcal{H}}$ is diagonalized in $\left\lvert{\psi}\right\rangle$’s then $\mathcal{D}^{\dagger} \hat{\mathcal{H}}\mathcal{D}$ is also diagonalized in $\left\lvert{\psi}\right\rangle$’s. But for a generic $\mathcal{D}_ {f}$ with non-trivial $f$, this will no longer be true. That would be the topic for the other half the the note, after we introduce the kink solution.</p> <p>A comparison between displacement operator method to the case of regular functions might be helpful.</p> <table> <thead> <tr> <th style="text-align: center">Functions</th> <th style="text-align: center">QFT</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">A functions $f(x)$, a neighborhood about a special locus $x_ 0$ where the interesting things happen.</td> <td style="text-align: center">A Hilbert space, a quantum state $\left\lvert{\Psi}\right\rangle$ of interest represented by a functional $\left\langle \Psi(x),- \right\rangle$, and some operator $\mathcal{O}(\phi)$.</td> </tr> <tr> <td style="text-align: center">We want to study the function $f(x )$ about $x_ 0$ perturbatively,</td> <td style="text-align: center">We want to study the $\left\langle{\Psi}\right\rvert\mathcal{O}\left\lvert{\Psi}\right\rangle$ perturbatively,</td> </tr> <tr> <td style="text-align: center">but $x_ 0$ is not a small quantity so Maclaurin expansion (Taylor expansion at the origin) fails.</td> <td style="text-align: center">but $\left\langle{\Psi}\right\rvert\phi \left\lvert{\Psi}\right\rangle=:f(x)$ is too large for $\phi$ to be treated perturbatively.</td> </tr> <tr> <td style="text-align: center"><strong>In a passive perspective, we shift the origin</strong> to $x_ 0$, then small deviation from $x_ 0$ can now be studied using Maclaurin expansion perturbatively.</td> <td style="text-align: center">In a passive perspective, we shift the operators, especially the field operator $\phi$ since it is usually the building block of other operators. The expectation value of the new, shifted operator $\phi’$ should be zero, $\left\langle{\Psi}\right\rvert \phi’\left\lvert{\Psi}\right\rangle =0$. Now we can treat $\phi$ perturbatively.</td> </tr> <tr> <td style="text-align: center">We are using a new, shifted coordinate system $\left\lbrace \overline{x} \right\rbrace$ to study the same old functions $f(x)$.</td> <td style="text-align: center">We are using shifted operators $\mathcal{D}^{\dagger}\mathcal{O}\mathcal{D}$ to study the same old states $\left\lvert{\Psi}\right\rangle$.</td> </tr> </tbody> </table> <p>In summary, now $\mathcal{H}=\mathcal{D}^{\dagger}_ {v}\hat{\mathcal{H}}\mathcal{D}_ {v}$ is a operator-valued function of $\phi’ = \mathcal{D}_ {v}^{\dagger} \phi \mathcal{D}_ {v}$, and $\phi’$ can be dealt with perturbatively. For the value of $v$, we could choose it to be the bare parameter or renormalized parameter, the final result should not depend on the convention we choose, in our note, in the spirit of renormalized perturbation theory, we choose $v$ to be renormalized, the associated displacement operator is $\mathcal{D}_ {v}$. Still, $v$ receives quantum corrections order by order, the full expression for $v$ would be an expansion in $g$:</p> \[v = -\frac{m}{\sqrt{ 2 }g} +\delta v, \quad \delta v = \delta v_ {1}+\delta v_ {2}+\cdots, \quad \delta v_ {i} \sim \mathcal{O}(g^{i}).\] <hr/> <p>In renormalized parameters the Hamiltonian reads (up to $\mathcal{O}(g^{3})$)</p> \[\begin{align*} \hat{H}(\vec{x}) &amp;\supset \int d^{3}x \, : \frac{1}{2}\pi^{2}+\frac{1}{2}(\partial_ {i}\phi)^{2} - \frac{m^{2}}{4}\phi^{2}+\frac{g^{2}}{4}\phi^{4}:_ {m} \\ &amp;\;\;\;\; + \int d^{3}x \, : \frac{\delta m^{2}}{4}\phi^{2}-\frac{1}{2}g \delta g\phi^{4} + \frac{(\delta g)^{2}}{4}\phi^{4} + \frac{3}{2}(g-\delta g)^{2}I\phi^{2}-\frac{3}{4}m^{2}I +A :_ {m}. \end{align*}\] <p>Recall that $I$ is some integral of higher order of the coupling, we defined it in part I of the note. We need to sandwich the Hamiltonian by $\mathcal{D}_ {v}$ to get the shifted Hamiltonian density $\mathcal{H}$. We will expand $\mathcal{H}$ in power of $g=\sqrt{ \lambda }$. With some help from Mathematica, we find the following results.</p> \[\begin{align*} \mathcal{H}_ {0} &amp;= A_ 0-\frac{m^4}{16 g^2}, \\ \mathcal{H}_ {1} &amp;= A_ {1} \equiv 0, \\ \mathcal{H}_ {2} &amp;= \frac{\pi^{2}}{2} + \frac{(\partial \phi)^{2}}{2} + \frac{m^{2}\phi^{2}}{2} + \frac{m^{4}}{8g^{2}}\left( -\frac{\delta g}{g} + \frac{\delta m^{2}_ {1}}{m^{2}} + \frac{\delta m^{4}_ {1}}{8g^{2}} \right) + A_ {2}, \\ \mathcal{H}_ {3} &amp;= - \frac{mg}{\sqrt{ 2 }} \phi^{3} + \phi\left( m^{2}\delta v_ {1}+\frac{m^{3}}{\sqrt{ 2 }g} \left( \frac{\delta g}{g} - \frac{\delta m^{2}_ {1}}{2m^{2}} - \frac{\delta m^{4}_ {1}}{2g^{2}} \right) \right) + A_ {3}, \\ \mathcal{H}_ {4} &amp;= \frac{g^{2}}{4}\phi^{4} + \phi^{2}\left( - \frac{3gm\delta v_ {1}}{\sqrt{ 2 }} - \frac{3m^{2}\delta g}{2g} + \frac{\delta m^{2}_ {1}}{4} + \frac{3m^{2}\delta m_ {1}^{4}}{4g^{2}} \right)+ \phi(m^{2}\delta v_ {2}) \\ &amp;\;\;\;\; + \frac{m^{4}(\delta g)^{2}}{16g^{4}} + \frac{m^{3}\delta v_ {1}}{\sqrt{ 2 }g}\left( \frac{g}{\sqrt{ 2 }m} \delta v_ {1} + \frac{\delta g_ {1}}{g} - \frac{\delta m_ {1}^{2}}{2m^{2}} - \frac{\delta m_ {1}^{4}}{2g^{2}} \right) + A_ 4, \\ \mathcal{H}_ {5} &amp;= \phi^{3}\left( g^{2}\delta v_ {1}+\sqrt{2}m\delta g_ {1}- \frac{m\delta m_ {1}^{4}}{\sqrt{2}g} \right) - \phi^{2}\left( \frac{3mg \delta v_ {2}}{\sqrt{2}} \right) \\ &amp;\;\;\;\; + \phi\left( m^{2}\delta v_ {3} - \frac{3gm\delta v_ {1}^{2}}{\sqrt{2}} - \frac{3m^{2}\delta g_ {1}\delta v_ {1}}{g} - \frac{m^{3}(\delta g)^{2}}{2\sqrt{2}g^{3}} + \frac{1}{2}\delta m_ {1}^{2}\delta v_ {1} - \frac{3mg I_ {1}}{\sqrt{2}} + \frac{3m^{2}\delta m_ {1}^{4}\delta v_ {1}}{2g^{2}} \right) \\ &amp;\;\;\;\; + \frac{m^{3}\delta v_ {2}}{\sqrt{2}g}\left( \frac{\delta g}{g} - \frac{\delta m_ {1}^{2}}{2m^{2}} - \frac{\delta m_ {1}^{4}}{2g^{2}} + \frac{\sqrt{2}g\delta v_ {1}}{m} \right) + A_ {5}. \end{align*}\] <h1 id="hamiltonian-renormalization">Hamiltonian Renormalization</h1> <p>The wavefunctions are expanded as</p> \[\begin{align*} \left\lvert{\Psi}\right\rangle &amp;= \left\lvert{\Psi_ {0}}\right\rangle + \left\lvert{\Psi_ {1}}\right\rangle + \cdots = \sum_ {i=0}^{\infty} \left\lvert{\Psi_ {i}}\right\rangle , \\ \left\lvert{\Psi _ {i} }\right\rangle &amp;\sim g^{i}. \end{align*}\] <p>The Hamiltonian renormalization conditions (HRC) are as follows.</p> <ol> <li>Vacuum condition: $H\left\lvert{\Psi}\right\rangle=0$ at all orders.</li> <li>Theory is defined at mass $m$: $H\left\lvert{\vec{p}}\right\rangle = \omega_ {p,m}\left\lvert{\vec{p}}\right\rangle$. We will just neglect $m$.</li> <li>$_ {0}\left\langle \vec{p}_ {1}\vec{p}_ {2} \middle\vert \vec{p}\right\rangle_ {i\geq2}=0$,</li> <li>No tadpole, $\left\langle{\Omega}\right\rvert\phi \left\lvert{\Omega}\right\rangle=0$.</li> </ol> <p>These are non-perturbative conditions, meaning they apply to all the orders, and the states involved are in general non-perturbative states, they can be expanded order by order. $\left\lvert{\Omega}\right\rangle$ is the full vacuum state with interaction, sometimes called physical vacuum. $\left\lvert{\vec{p}_ {1}\cdots\vec{p}_ {n}}\right\rangle$ is an $n$-meson momenta eigenstate. We define the leading order of the vacuum to be:</p> \[A_ {p} \left\lvert{\Omega_ {0}}\right\rangle =0.\] <p>Similarly $\left\lvert{\vec{p}}\right\rangle$ is the full momentum eigenstate, $\left\lvert{\vec{p}}\right\rangle=\left\lvert{\vec{p}_ {0}}\right\rangle + \left\lvert{\vec{p}_ {1}}\right\rangle+\cdots$. Recall that <strong>in the interaction picture</strong> we have $\left\lvert{\vec{p}}\right\rangle=\frac{a^{\dagger}}{\sqrt{2\omega_ {p,m}}}\left\lvert{0}\right\rangle$, it is because in the interaction picture the operator $\phi$ is exactly solvable, the solution is by construction the same as if interaction does not exist. However we are working in Schrodinger picture, so this simple relation only holds at leading order,</p> \[\left\lvert{\vec{p}}\right\rangle_ {0} = A^{\ddagger}_ {p}\left\lvert{\Omega_ {0}}\right\rangle .\] <p>The non-perturbative definition, $H\left\lvert{\vec{p}}\right\rangle=\vec{p}\left\lvert{\vec{p}}\right\rangle$, holds at each and every order.</p> <p>The orthonormal conditions are:</p> \[\begin{align*} \left\langle \Omega_ {0} \middle\vert \Omega_ {0} \right\rangle &amp;= 1,\\ \left\lvert{\vec{p}_ {1}\cdots \vec{p}_ {n} }\right\rangle_ {0} &amp;= A^{\ddagger}_ {p_ {1}}\cdots A^{\ddagger}_ {p_ {n} }\left\lvert{\Omega_ {0}}\right\rangle . \end{align*}\] <p>In this note I will use $\left\lvert{\Omega_ {i}}\right\rangle$ and $\left\lvert{\Omega}\right\rangle_ {i}$ interchangeably.</p> <p>The first Hamiltonian renormalization condition (HRC) is expanded to</p> \[\boxed{ H\left\lvert{\Omega}\right\rangle = \sum_ {i}^{\infty}H_ {i=0} \sum_ {j=0}^{\infty} \left\lvert{\Omega _ {j} }\right\rangle = \sum_ {i,j=0}^{\infty} H_ {i} \left\lvert{\Omega _ {j} }\right\rangle\sim g^{i+j-2}. }\] <p>The non-perturbed Fock states consists a full basis of Hilbert space, the $n$-meson states is defined to be</p> \[\left\lvert{\vec{p}_ {1}\cdots\vec{p}_ {n}}\right\rangle_ 0 := A_ {p_ {1}}^{\ddagger}\cdots A_ {p_ {n} }^{\ddagger} \left\lvert{\Omega_ {0}}\right\rangle .\] <p>We will use them to expand states of higher order in $g$, for example $\left\lvert{\Omega_ {n}}\right\rangle$ is the $g^{n}$-order vacuum correction, we will expand it as</p> \[\left\lvert{\Omega_ {n}}\right\rangle = \sum_ {i=0}^{\infty} \left\lvert{\Omega_ {n}}\right\rangle^{(i)} , \quad \left\lvert{\Omega}\right\rangle^{(i)} \in i\text{-meson Fock space.}\] <p>We have two things to match: 1)different orders of the coupling and 2)different Fock space.</p> <h2 id="order-g-2-and-g-1">Order $g^{-2}$ and $g^{-1}$</h2> <p>At the lowest order, the Hamiltonian density is just a constant without ladder operators, so $H_ {0}\left\lvert{\Omega_ {0}}\right\rangle=0$ gives as $\mathcal{H}_ {0}=0$, which implies $A_ {0} = m^{4} / 16g^{2}$.</p> <hr/> <p>By construction we have $H_ {1}=0$.</p> <p>Take away:</p> <p>\(\boxed{ H_ {0}=H_ {1}=0. }\)</p> <h2 id="order-g0">Order $g^{0}$</h2> <p>The first HRC (HRC1), namely $H\left\lvert{\Omega}\right\rangle=0$ implies that</p> \[H_ {2}\left\lvert{\Omega_ {0}}\right\rangle = 0 ,\] <p>which in turn implies</p> \[A_ {2} = - \frac{m^{4}}{8g^{2}} \left( -\frac{\delta g}{g} + \frac{\delta m_ {1}^{2}}{m^{2}}+ \frac{\delta m_ {1}^{4}}{\delta g^{2}} \right),\] <p>as a result</p> \[\begin{align*} \mathcal{H}_ {2} &amp;= \frac{\pi^{2}}{2} + \frac{(\partial \phi)^{2}}{2} + \frac{1}{2}m^{2}\phi^{2},\\ H_ {2} &amp;=\int d^{3}x \, : \mathcal{H}_ {2} :_ {m} = \int \frac{d^{3}p}{(2\pi)^{3}} \, \omega_ {p} A^{\ddagger}_ {p} A_ {p} . \end{align*}\] <hr/> <h2 id="order-g1">Order $g^{1}$</h2> <p>Similar to order $g^{0}$, HRC1 implies that</p> \[H_ {2}\left\lvert{\Omega_ {1}}\right\rangle = -H_ {3} \left\lvert{\Omega_ {0}}\right\rangle . \tag{HRC1}\] <p>Now we need to expand $\left\lvert{\Omega_ {1}}\right\rangle$ in $\left\lvert \Omega_ {0} \right\rangle$ and free field Fock states. Such state are created by free creation operators acting on free vacuum state,</p> \[\left\lvert \vec{p} \right\rangle_ {0} = A^{\ddagger}_ {p} \left\lvert \Omega_ {0} \right\rangle\] <p>and</p> \[\left\lvert \vec{p}_ {1}\cdots \vec{p}_ {n} \right\rangle_ {0} = A_ {p_ {1}}^{\ddagger}\cdots A^{\ddagger}_ {p_ {n} }\left\lvert \Omega_ {0} \right\rangle .\] <p>What is the norm of $\left\lvert \vec{p} \right\rangle_ {0}$? We have $_ {0}\left\langle \vec{p} \right\rvert=\left\langle \Omega_ {0} \right\rvert (A_ {p}^{\ddagger})^{\dagger}=\left\langle \Omega_ {0} \right\rvert(A_ {p})/2\omega_ {p}$ and $[A_ {p},A^{\ddagger}q]=(2\pi)^{3} \delta^{3}(\vec{p}-\vec{q})$, thus</p> \[\boxed{ _ {0}\left\langle \vec{p} \middle\vert \vec{q} \right\rangle_ {0} = \frac{(2\pi)^{3}}{2\omega _ {p} } \delta^{(3)}(\vec{p}-\vec{q}). }\] <p>The free Fock states consist a full basis of Hilbert space. We can expand the first order correction to the vacuum states in these basis,</p> \[\left\lvert{\Omega_ {1}}\right\rangle = \left\lvert{\Omega_ {1}^{(0)}}\right\rangle + \left\lvert{\Omega_ {1}^{(1)}}\right\rangle + \cdots\] <p>where $\left\lvert{\Omega_ {1}^{(0)}}\right\rangle$ isthe same as $\left\lvert{\Omega_ {1}}\right\rangle^{(0)}$, the superscript indicates the number of mesons, $\left\lvert \Omega_ {1}^{(n)} \right\rangle$ means the $n$-meson Fock space component of $\left\lvert \Omega_ {1} \right\rangle$ state. Explicitly we have</p> \[\left\lvert{\Omega^{(0)}_ {1}}\right\rangle = c_ {1,0} \left\lvert \Omega_ {0} \right\rangle , \quad c_ {1,0}\in \mathbb{C}.\] <p>I will assume that $c_ {1,0}=0$, which is quite reasonable since the correction should be something new. And</p> \[\left\lvert \Omega_ {1}^{(1)} \right\rangle = \sum c_ {1,i} \left\lvert p_ {i} \right\rangle_ 0 , \quad c_ {1,i}\in \mathbb{C}.\] <p>Generalizing it to multi-meson Fock space, we have</p> \[\left\lvert \Omega_ {1}^{(n)} \right\rangle =\sum_ {I} c_ {1,I} \left\lvert p_ {I} \right\rangle , \quad I = i_ {1}\cdots i_ {n},\; n&gt;1,\] <p>where $I$ is the general index, $\left\lvert p_ {I} \right\rangle=\left\lvert p_ {i_ {1}}p_ {i_ {2}}\cdots p_ {i_ {n}} \right\rangle$.</p> <p>Are states from different Fock spaces orthogonal to each other? It will look something like</p> \[_ {0}\left\langle \vec{p}_ {I} \middle\vert \vec{p}_ {J} \right\rangle_ {0} \propto \left\langle \Omega_ {0} \right\rvert A\cdots A A^{\ddagger}\cdots A^{\ddagger}\left\lvert \Omega \right\rangle .\] <p>According to the equal-time Wick theorem, a string of ladder operators is equal to the normal ordering of all its contraction, which, when sandwiched between vacuum state, can only be non-zero if it is a full contraction, where there are equal number of creation and annihilation operators. It means that these two states must</p> <p>have same number of particles in it, hence belong to the same order of Fock subspace. Thus</p> \[\left\langle \Psi^{(m)} \middle\vert \Psi^{(n)} \right\rangle =0 \text{ if } m \neq n.\] <p>Coming back to $\left\lvert \Omega_ {1} \right\rangle$. Focusing on the $0$-meson sub Fock space, we have</p> \[H_ {2}\left\lvert{\Omega_ {1}}\right\rangle \supset H_ {2}(\cdots)\left\lvert{\Omega_ {0}}\right\rangle =0,\] <p>since $H_ {2}$ is normal ordered. On the right hand side, the zero-meson part of $-H_ {3}\left\lvert \Omega_ {0} \right\rangle$ is what? $H_ {3}$ can be written as</p> \[H_ {3} = \int d^{3}x \, :- \frac{mg}{\sqrt{2}} \phi^{3}+\phi m^{2} \delta v_ {1}' + A_ {3} :_ {m},\] <p>where $\delta v_ {1}’$ is some function of counter terms. Thanks to the normal ordering, in $0$-Fock subspace we have</p> \[0\text{-meson:}\quad H_ {3}\left\lvert \Omega_ {0} \right\rangle =A_ {3}\left\lvert \Omega_ {0}\right\rangle=0 \implies A_ {3}=0 .\] <p>To study what is going on with multi-mesons states, we need to expand the Hamiltonians $H_ {2}$ and $H_ {3}$ in ladder operators. According to the convention we introduced in the first part of the note, we have</p> \[H_ {2} = \int \frac{d^{3}p}{(2\pi)^{3}} \, \omega_ {p} A^{\ddagger}_ {p} A_ {p} .\] <p>Let $(123)$ be the permutation action that maps 1st element to 2nd, 2nd to 3rd, and 3rd to 1st, we have</p> \[\begin{align*} H_ {3} = &amp;-\frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \frac{d^{3}p_ {2}}{(2\pi)^{3}}\, \bigg\{ A_ {p_ {1}}^{\ddagger}A_ {p_ {1}}^{\ddagger}A_ {p_ {3}}^{\ddagger} \\ &amp;+ \frac{1}{2\omega_ {p_ {3}}}A_ {p_ {1}}^{\ddagger}A_ {p_ {2}}^{\ddagger}A_ {-p_ {3}} + (123)+(123)^{2} \\ &amp;+\frac{1}{2\omega_ {p_ {2}}} \frac{1}{2\omega_ {p_ {3}}} A_ {p_ {1}}^{\ddagger}A_ {-p_ {2}} A_ {-p_ {3}} + (123)+(123)^{2} \\ &amp; + \left.\frac{1}{2\omega_ {p_ {1}}2\omega_ {p_ {2}}2\omega_ {p_ {3}}} A_ {-p_ {1}}A_ {-p_ {2}}A_ {-p_ {3}} \right\rbrace \\ &amp;+ m^{2}\delta v_ {1}'\left( A^{\ddagger}_ {p=0}+\frac{A_ {p=0}}{2m} \right), \\ p_ {3} =&amp; -p_ {1}-p_ {2},\\ \delta v_ {1}' =&amp; \delta v_ {1}+\frac{m}{\sqrt{2}g} \left( \frac{\delta g}{g} - \frac{\delta m^{2}_ {1}}{2m^{2}} - \frac{\delta m^{4}_ {1}}{2g^{2}}\right). \end{align*}\] <p>In order to solve the order $g$ HRC1 equation</p> \[H_ {2}\left\lvert{\Omega_ {1}}\right\rangle = -H_ {3} \left\lvert{\Omega_ {0}}\right\rangle\] <p>for $\left\lvert \Omega_ {1} \right\rangle$, we would like to find the inverse of $H_ {2}$. The kernel of $H_ {2}$ is $\left\lvert \Omega_ {0} \right\rangle$, of course inverse of $H_ {2}$ does not exist on $\left\lvert \Omega_ {0} \right\rangle$. But we can always define the inverse on other Fock states. For example, consider a 3-meson state $\left\lvert \vec{p}_ {1}\vec{p}_ {2}\vec{p}_ {3} \right\rangle_ {0}$, since $H_ {2}$ is diagonalized in these basis, the inverse can be trivially written as $\frac{1}{H_ {2}}$ where $H_ {2}$ is to be understood as its eigenvalues,</p> \[\frac{1}{ H_ {2}} \left\lvert \vec{p}_ {1}\vec{p}_ {2}\vec{p}_ {3} \right\rangle_ {0} = \frac{1}{\omega_ {p_ {1}}\omega_ {p_ {2}}\omega_ {p_ {3}}} \left\lvert \vec{p}_ {1}\vec{p}_ {2}\vec{p}_ {3} \right\rangle_ {0}.\] <p>Since we have established that $\left\lvert \Omega_ {1} \right\rangle$ does not contain $\Omega_ {0}$ component, that is $\Omega_ {1}$ does not contain the kernel of $H_ {2}$, we can write formally</p> \[\left\lvert \Omega_ {1} \right\rangle = - \frac{1}{H_ {2}} H_ {3} \left\lvert \Omega_ {0} \right\rangle\] <p>Substitute the expression for $H_ {3}$, we have (after some trivial rearrangement)</p> \[\begin{align*} \left\lvert \Omega_ {1} \right\rangle =&amp; \frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}_ {1}\vec{p}_ {2}\vec{p}_ {3} \right\rangle_ {0} }{(\omega_ {p_ {1}}+\omega_ {p_ {2}}+\omega_ {p_ {3}})} \\ &amp;- m\delta v_ {1}' \left\lvert \vec{p}=0 \right\rangle_ {0} ,\\ \vec{p}_ {3} =&amp; -\vec{p}_ {1}-\vec{p}_ {2}. \end{align*}\] <p>The no-tadpole rule demands that $\left\langle \Omega \right\rvert\phi \left\lvert \Omega \right\rangle=0$, expand $\left\lvert \Omega \right\rangle$ up to $\left\lvert \Omega_ {1} \right\rangle$ we get</p> \[\begin{align*} \left\langle \Omega \right\rvert \phi \left\lvert \Omega \right\rangle &amp;= (\left\langle \Omega_ {0} \right\rvert +\left\langle \Omega_ {1} \right\rvert ) \phi (\left\lvert \Omega_ {0} \right\rangle +\left\lvert \Omega_ {1} \right\rangle ) \\ &amp;= 2 \left\langle \Omega_ {0} \right\rvert \int \frac{d^{3}k}{(2\pi)^{3}} \, e^{ -i\vec{k}\cdot \vec{x} } \frac{A_ {-k}}{2\omega_ {k}} (-m\delta v_ {1}')A^{\ddagger}_ {p=0} \left\lvert \Omega_ {0} \right\rangle \\ &amp;= -\delta v_ {1}'\\ &amp;=0. \end{align*}\] <p>The long-ass expression for $\delta v_ {1}’$ turns out to be zero. This can be translated into a relation for $\delta v_ {1}$, which will help us to simplify the higher order Hamiltonians:</p> \[\boxed{ \delta v_ {1}=- \frac{m}{\sqrt{2}g} \left( \frac{\delta g}{g}- \frac{\delta m_ {1}^{2}}{2m^{2}}- \frac{\delta m_ {1}^{4}}{2g^{2}} \right). }\] <p>Putting everything together, we find</p> \[\boxed{ \mathcal{H}_ {3}(\vec{x}) = -\frac{mg}{\sqrt{2}} \phi^{3}(\vec{x}), }\] <p>everything else has disappeared. The first order correction to vacuum state is</p> \[\boxed{ \left\lvert \Omega_ {1} \right\rangle = \frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}_ {1}\vec{p}_ {2}\vec{p}_ {3} \right\rangle_ {0} }{(\omega_ {p_ {1}}+\omega_ {p_ {2}}+\omega_ {p_ {3}})}, \quad \vec{p}_ {1}+\vec{p}_ {2}+\vec{p}_ {3}=0 }\] <p>We are not quite done yet, we need to find the interaction correction to the momentum eigenstates. At lowest order we have $H_ {0}\left\lvert \vec{p} \right\rangle_ {0}=\omega_ {p}\left\lvert \vec{p} \right\rangle_ {0}$, and after we include all orders we require that $H\left\lvert \vec{p} \right\rangle=\omega_ {p}\left\lvert p \right\rangle$. Our task is to find the difference between $\left\lvert - \right\rangle_ {0}$ and $\left\lvert - \right\rangle$ order by order.</p> <p>In order to make it easier to keep tracks of the number of mesons, let’s introduce the following notation.</p> <ul> <li>For a state, we use a superscript in parenthesis to denote how many meson it contains, $\left\lvert \psi \right\rangle^{(m)}$ indicates $\left\lvert \psi \right\rangle$ contains $m$ mesons, hence belongs to the $m$-meson Fock (sub)space. The superscript is sometimes inside the ket notation, sometimes out (as in here), I will in general not pay too much attention to it as long as it is clear what is meant;</li> <li>For an operator, we use the same notation to denote <strong>how many mesons it creates</strong> when acting on a state, for example $\mathcal{O}^{(m)}$ means that $\mathcal{O}^{(m)}\left\lvert \psi(n) \right\rangle$ as a whole has $m+n$ states.</li> </ul> <p>There is also a nice diagrammatic symbol that Jarah created (Jarah diagram) to indicate different contributions. An explanation of how such diagrams work is given in the figure below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/jarahDiagram-480.webp 480w,/img/kink/jarahDiagram-800.webp 800w,/img/kink/jarahDiagram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/jarahDiagram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The diagram is separated into two parts, the vertex lies in the middle. First, look at the equation at the bottum, where the left hand side is the higher order correction that we want to calculate, the right hand side is how we calculate it, by acting on a lower-order state by some operator. The operator is represented by the bullet in the middle, that's why $\mathcal{O}$ is placed right under the bullet. The diagram can be separated into two parts, the left panel corresponds to the left hand side of the equation, the right panel shows on what states the operator acts. The arrow-lines are not fermions but mesons, the arrow shows the direction in which the coupling-order increases. The coupling order always increases from right to the left. Note that in vacuum sector, momenta are conserved at each vertex. We will omit the vertical dashed lines that intersect meson lines. </div> <p>In the case of vacuum correction, I copy Jarah’s explanation here shamelessly.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/3_0_Vacuum-480.webp 480w,/img/kink/3_0_Vacuum-800.webp 800w,/img/kink/3_0_Vacuum-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/3_0_Vacuum.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> This graph represents the calculation of $\left\lvert \Omega_ {1} \right\rangle ^{3}$, which is $-H_ {2}^{-1} H_ {3}\left\lvert \Omega_ {0} \right\rangle ^{(0)}$. The vertex represents the operator $-H_ {2}^{-1} H_ {3}$. The order $i$ of $\left\lvert \Omega_ {i} \right\rangle$ increases as one moves to the left. Consider a vertical slice. It intersects some number of lines $n$. This represents the $n$-meson Fock space. To the right of the vertex there are no lines, reflecting the fact that $\left\lvert \Omega_ {0} \right\rangle=\left\lvert \Omega_ {0} \right\rangle^{(0)}$ lives in the zero-meson Fock space. To the left, there are three lines, as we are calculating a contribution $\left\lvert \Omega_ {1} \right\rangle^{(3)}$ to $\left\lvert \Omega_ {1} \right\rangle$ in the three-meson Fock space. </div> <p>As an application of the notation we talked about, consider $H_ {3}$. It has different parts creating different numbers of operators, we write them as</p> \[H_ {3}= H_ {3}^{(-3)} + H_ {3}^{(-1)}+H_ {3}^{(1)}+H_ {3}^{(3)},\] <p>where $H^{(-3)}$ is the part with three annihilation operators hence decrease the number of mesons by 3, etc. All these are summarized in the last chapter.</p> <hr/> <p>Now we can make use of the second HRC that defines the momenta eigenstates. It says</p> \[H _ {\text{full}} \left\lvert \vec{p} \right\rangle = \omega_ {p} \left\lvert \vec{p} \right\rangle ,\] <p>we do the following expansion:</p> \[H_ {\text{full}} = \sum_ {i\geq 2} H_ {i} , \quad \left\lvert \vec{p} \right\rangle = \left\lvert \vec{p} \right\rangle_ {0}+\sum_ {j\geq 1} \left\lvert \vec{p} \right\rangle_ {1}^{(j)}\] <p>since $H_ {2}\left\lvert \vec{p} \right\rangle_ {0}=\omega_ {0}\left\lvert \vec{p} \right\rangle_ {0}$, after some rearrangement we have the master formula</p> \[\boxed{ \sum_ {i\geq 3} H_ {i} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} = \left( \omega_ {p}-\sum_ {i\geq 2}H_ {i} \right)\sum_ {j\geq 1} \left\lvert \vec{p} \right\rangle_ {1}^{(j)}. }\] <p>Now, both parts will have contribution from different Fock space, for example $H_ {4}$ acting on $\left\lvert \vec{p} \right\rangle_ {0}^{(1)}$ may yield something with $2,3,\cdots$ free mesons. Now, besides matching the orders in coupling, we will also match the number of mesons.</p> <p>Let’s see what happens at leading order $\sim g$ of the coupling. At this order, with regards to the Hamiltonian, we only need up to $H_ {3}$, thus the master formula reads</p> \[H_ {3}\left\lvert \vec{p} \right\rangle_ {0}^{(1)} = (\omega _ {p} -H_ {2}) \left\lvert \vec{p} \right\rangle_ {1}.\] <p>There is not $H_ {3}\left\lvert \vec{p} \right\rangle_ {1}$ since $\left\lvert \vec{p} \right\rangle_ {1}\sim g$. Out goal is to express $\left\lvert \vec{p} \right\rangle_ {1}$ in terms of $\left\lvert \vec{p} \right\rangle_ {0}$.</p> <p>The RHS adopts an expansion in Fock space:</p> \[(\omega_ {p}-H_ {2})\sum_ {n\geq 1}\left\lvert \vec{p} \right\rangle_ {1}^{(n)},\quad \text{with n mesons.}\] <p>The same expansion on the left hand side reads</p> \[H_ {3} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} = H_ {3}^{(-3)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} + H_ {3}^{(-1)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} + H_ {3}^{(1)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} + H_ {3}^{(3)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} ,\] <p>Again, there is nothing else since $H_ {4}$ is of order $g^{2}$ already. To see how many particles (we will use particle and meson interchangeably in this note) are there, we just add all the upstairs number together, for example $H^{(3)}\left\lvert \vec{p} \right\rangle^{(1)}$ has $3+1=4$ particles in it.</p> <p>Putting The LHS and RHS together we have</p> \[\sum_ {i}H_ {3}^{(i)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} = (\omega_ {p}-H_ {2})\sum_ {n\geq 1}\left\lvert \vec{p} \right\rangle_ {1}^{(n)}, \quad i\in \left\lbrace -3,-1,1,3 \,\middle\vert\, \right\rbrace .\] <p>Balancing the superscripts, namely require $i+1=n$, we get</p> \[\begin{align*} H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {0}^{(1)} =&amp; (\omega _ {p} -H_ {2}) \left\lvert \vec{p} \right\rangle_ {1}^{(2)}, \\ H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {0}^{(1)} =&amp; (\omega _ {p} -H_ {2}) \left\lvert \vec{p} \right\rangle_ {1}^{(4)}. \end{align*}\] <p>Next we need to substitute the expression for $H_ {3}$ in terms of ladder operator and contract, which can be found in the last section of the note. By the end of the day we get two components of $\left\lvert \vec{p} \right\rangle_ {1}$, namely the 2-free-meson and 4-free-meson components, as shown below:</p> \[\begin{align*} \left\lvert \vec{p} \right\rangle_ {1}^{(2)} &amp;= (\omega _ {p} -H_ {2})^{-1}H_ {3}^{(1)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)}， \\ \left\lvert \vec{p} \right\rangle_ {1}^{(4)} &amp;= (\omega _ {p} -H_ {2})^{-1} H_ {3}^{(3)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)}. \end{align*}\] <p>Substitute the expression for $H_ {3}$ in terms of ladder operators, after some simplification we get</p> \[\left\lvert \vec{p} \right\rangle_ {1}^{(2)} = \frac{3mg}{2\sqrt{2}\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}}\, \frac{\left\lvert \vec{p}_ {1},\vec{p}- \vec{p}_ {1} \right\rangle^{(2)}_ {0}}{\omega_ {p_ {1}}+\omega_ {p-p_ {1}}-\omega_ {p}} .\] <p>Let’s take a closer look at $\left\lvert \vec{p} \right\rangle_ {1}^{(2)}$. Since $\omega(p)$ is not a linear function in $p$, considering $\vec{p}_ {1}+\vec{p}_ {2}=\vec{p}$, we have $\omega(\vec{p}_ {1})+\omega (\vec{p_ {2}}) \neq \omega(\vec{p})$, thus the integrand does not go to zero, hence is free of singularities.</p> <p>Another component is</p> \[\left\lvert \vec{p} \right\rangle_ {1}^{(4)} = \frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p},\vec{p}_ {1,2,-1-2} \right\rangle_ {0}^{(4)}}{\omega_ {p_ {1}}+\omega_ {p_ {2}}+\omega_ {p_ {1}+p_ {2}}}.\] <hr/> <h2 id="order-g2">Order $g^{2}$</h2> <p>The Hamiltonian is</p> \[H_ {4}=\int d^{3}x : \mathcal{H}_ {4}:\] <p>where the Hamiltonian density reads (<strong>we have used the relation for $\delta v_ {1}$</strong>)</p> \[\mathcal{H}_ {4} = \frac{g^{2}}{4}\phi^{4} + \phi^{2}\left( - \frac{\delta m_ {1}^{2}}{2} \right) + \phi(m^{2}\delta v_ {2})+ \frac{m^{4}(\delta g)^{2}}{16g^{4}} - \frac{m^{2}\delta v_ {1}^{2}}{2} + A_ 4,\] <p>Let’s rewrite it as</p> \[\mathcal{H}_ {4} = \frac{g^{2}}{4} \phi^{4} + C_ {2} \phi^{2} + C_ {1} \phi + C_ {0}.\] <p>The vacuum renormalization condition at order $g^{2}$ reads</p> \[H_ {4}\left\lvert \Omega_ {0} \right\rangle+H_ {3}\left\lvert \Omega_ {1} \right\rangle+H_ {2}\left\lvert \Omega_ {2} \right\rangle=0.\] <p>We need to decompose $H_ {4}$ into Fock subspace. We already know how to do that for $\phi^{3}$, we just need to workout $\phi^{4}$. The same calculation we did for $H_ {3}$ gets us</p> \[\begin{align*} :\phi^{4}: =&amp; :\phi^{4}:^{(4)}+:\phi^{4}:^{(2)}+:\phi^{4}:^{(0)}+:\phi^{4}:^{(-2)}+:\phi^{4}:^{(-4)},\\ :\phi^{4}:^{(4)} =&amp; \int \prod_ {i=1}^{4} \frac{d^{3}p_ {i}}{(2\pi)^{3}} \, e^{ -i\vec{x}\cdot \sum_ {i=1}^{4}\vec{p}_ {i} } A^{\ddagger}_ {p_ {1}}A^{\ddagger}_ {p_ {2}}A^{\ddagger}_ {p_ {3}}A^{\ddagger}_ {p_ {4}} ,\\ :\phi^{4}:^{(2)} =&amp; 4\int \prod_ {i=1}^{4} \frac{d^{3}p_ {i}}{(2\pi)^{3}} \, e^{ -i\vec{x}\cdot \sum_ {i=1}^{4}\vec{p}_ {i} } A^{\ddagger}_ {p_ {1}}A^{\ddagger}_ {p_ {2}}A^{\ddagger}_ {p_ {3}} \frac{A_ {-p_ {4}}}{2\omega_ {p_ {4}}} ,\\ :\phi^{4}:^{(0)} =&amp; 6\int \prod_ {i=1}^{4} \frac{d^{3}p_ {i}}{(2\pi)^{3}} \, e^{ -i\vec{x}\cdot \sum_ {i=1}^{4}\vec{p}_ {i} } A^{\ddagger}_ {p_ {1}} A^{\ddagger}_ {p_ {2}} \frac{A_ {-p_ {3}}}{2\omega_ {p_ {3}}}\frac{A_ {-p_ {4}}}{2\omega_ {p_ {4}}} ,\\ :\phi^{4}:^{(-2)} =&amp; 4\int \prod_ {i=1}^{4} \frac{d^{3}p_ {i}}{(2\pi)^{3}} \, e^{ -i\vec{x}\cdot \sum_ {i=1}^{4}\vec{p}_ {i} } A^{\ddagger}_ {p_ {1}} \frac{A_ {-p_ {2}}}{2\omega_ {p_ {2}}}\frac{A_ {-p_ {3}}}{2\omega_ {p_ {3}}}\frac{A_ {-p_ {4}}}{2\omega_ {p_ {4}}} ,\\ :\phi^{4}:^{(-4)} =&amp; \int \prod_ {i=1}^{4} \frac{d^{3}p_ {i}}{(2\pi)^{3}} \, e^{ -i\vec{x}\cdot \sum_ {i=1}^{4}\vec{p}_ {i} } \frac{A_ {-p_ {1}}}{2\omega_ {p_ {1}}}\frac{A_ {-p_ {2}}}{2\omega_ {p_ {2}}}\frac{A_ {-p_ {3}}}{2\omega_ {p_ {3}}}\frac{A_ {-p_ {4}}}{2\omega_ {p_ {4}}} . \end{align*}\] <h3 id="vacuum-states-correction">Vacuum states correction</h3> <p>Let’s look at the 1-meson subspace first. There is no such contribution from $H_ {3}$. What about from $H_ {4}$? For $H_ {4}\left\lvert \Omega_ {0} \right\rangle^{(0)}$ to have one meson, we need $H_ {4}^{(1)}$ to act on $\left\lvert \Omega_ {0} \right\rangle$. We have</p> <p>\(\begin{align*} \left\lvert \Omega_ {2} \right\rangle^{(1)} &amp;= - H_ {2}^{-1} H_ {4}^{(1)} \left\lvert \Omega_ {0} \right\rangle, \\ &amp;= - C_ {1} H_ {2}^{-1} :\phi:\left\lvert \Omega_ {0} \right\rangle \\ &amp;= - \frac{C_ {1}}{m} \left\lvert \vec{p} \right\rangle_ {0}, \quad \vec{p}=0. \end{align*}\) The last condition, $p=0$, is required by momentum conservation.</p> <p>The no-tadpole rule at order $g^{2}$ gives as that</p> \[\text{no-tadpole at }g^{2}: - \frac{C_ {1}}{m^{2}}+ \left\langle \Omega_ {1} \right\rvert\phi \left\lvert \Omega_ {1} \right\rangle=0,\] <p>however $\left\lvert \Omega_ {1} \right\rangle$ has only 3-meson component, thus the second term in the above equation is zero, we have $C_ {1}=0$. This fixes another counter term:</p> \[\boxed{ \delta v_ {2}=0. }\] <p>It simplifies the Hamiltonian to</p> \[\mathcal{H}_ {4}=\frac{g^{2}}{4} \phi^{4} - \frac{\delta m_ {1}^{2}}{2} \phi^{2} + C_ {0}.\] <p>In general the no-tadpole rule require the linear term in $\phi$ to vanish, and the true-vacuum condition require the constant term to vanish, which we will check later.</p> <hr/> <p><strong>Introduce the shorthand notation $\left\lvert \vec{p}_ {-1-2} \right\rangle:=\left\lvert -\vec{p}_ {1}-\vec{p}_ {2} \right\rangle$, $\left\lvert \vec{p}_ {-1’-2’} \right\rangle:=\left\lvert -\vec{p}’_ {1}-\vec{p}’_ {2} \right\rangle$ and $\left\lvert \vec{p}_ {1,2} \right\rangle:=\left\lvert \vec{p}_ {1}\vec{p}_ {2} \right\rangle$. Also let’s write $\omega_ {1}=\omega_ {p_ {1}},\, \omega_ {1’}=\omega_ {\vec{p}_ {1}’},\,\omega_ {1+2}=\omega_ {p_ {1}+p_ {2}}$ and</strong></p> \[\frac{d^{3}p_ {1,2,1',2'}}{(2\pi)^{12}} := \frac{d^{3}p_ {1}}{(2\pi)^{3}}\frac{d^{3}p_ {2}}{(2\pi)^{3}}\frac{d^{3}p'_ {1}}{(2\pi)^{3}}\frac{d^{3}p'_ {2}}{(2\pi)^{3}}.\] <p>The decomposition of $H_ {4}$ by meson numbers reads</p> \[\begin{align*} H_ {4} =&amp; \sum_ {n=0}^{4} H_ {4}(4-2n), \\ H_ {4}^{(4)} =&amp; \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, A^{\ddagger}_ {1}A^{\ddagger}_ {2}A^{\ddagger}_ {3}A^{\ddagger}_ {-1-2-3} ,\\ H_ {4}^{(2)} =&amp; g^{2} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, A^{\ddagger}_ {1}A^{\ddagger}_ {2}A^{\ddagger}_ {3} \frac{A_ {1+2+3}}{2\omega_ {1+2+3}} \\ &amp;- \frac{\delta m_ {1}^{2}}{2} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, A_ {1}^{\ddagger}A_ {-1}^{\ddagger},\\ H_ {4}^{(0)} =&amp; \frac{3g^{2}}{2} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}}\, A^{\ddagger}_ {1} A^{\ddagger}_ {2} \frac{A_ {-3}}{2\omega_ {3}}\frac{A_ {1+2+3}}{2\omega_ {1+2+3}} \\ &amp;- \delta m_ {1}^{2} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{A_ {1}^{\ddagger}A_ {1}}{2\omega_ {1}}+\int d^{3}x \, C_ {0} ,\\ H_ {4}^{(-2)} =&amp; g^{2}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}}\, A^{\ddagger}_ {1} \frac{A_ {-2}}{2\omega_ {2}}\frac{A_ {-3}}{2\omega_ {3}}\frac{A_ {1+2+3}}{2\omega_ {1+2+3}} \\ &amp; -\frac{\delta m_ {1}^{2}}{2}\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{A_ {1}A_ {-1}}{(2\omega_ {1})^{2}} , \\ H_ {4}^{(-4)} =&amp; \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}}\, \frac{A_ {-1}}{2\omega_ {1}}\frac{A_ {-2}}{2\omega_ {2}}\frac{A_ {-3}}{2\omega_ {3}}\frac{A_ {1+2+3}}{2\omega_ {1+2+3}} , \end{align*}\] <p>where we have used the condition that $\vec{p}_ {1}+\vec{p}_ {2}+\vec{p}_ {3}+\vec{p}_ {4}=0$.</p> <p>We have now all the ingredients needed to solve</p> \[\boxed{ \left\lvert \Omega_ {2} \right\rangle=-H_ {2}^{-1} H_ {4}\left\lvert \Omega_ {0} \right\rangle - H_ {2}^{-1} H_ {3}\left\lvert \Omega_ {1} \right\rangle, }\] <p>one meson number at a time. We will go from $6$ mesons and down to $0$ mesons.</p> <p>In $6$-meson Fock space we have</p> \[\begin{align*} \left\lvert \Omega_ {2} \right\rangle^{(6)} =&amp; -H_ {2}^{-1} H_ {3}^{(3)}\left\lvert \Omega_ {1} \right\rangle^{(3)} \\ =&amp;\frac{m^{2}g^{2}}{2} \int \frac{d^{3}p_ {1,2,1',2'}}{(2\pi)^{12}} \, \\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2,-1-2}\;\vec{p}'_ {1,2,-1-2} \right\rangle_ {0}}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {1}+\omega_ {2}+\omega_ {1+2}+\omega_ {1}'+\omega_ {2}'+\omega_ {1'+2'})} \end{align*}\] <p>where</p> \[\left\lvert \vec{p}'_ {1,2,-1-2} \right\rangle_ {0} := \left\lvert \vec{p}'_ {1},\vec{p}'_ {2},\vec{p}'_ {-1-2} \right\rangle_ {0} := \left\lvert \vec{p}'_ {1},\vec{p}'_ {2},-\vec{p}'_ {1}-\vec{p}'_ {2} \right\rangle_ {0}.\] <p>This is represented by the figure below. Note the manifestation of momentum conservation.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/kink/p63-480.webp 480w,/img/kink/p63-800.webp 800w,/img/kink/p63-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/kink/p63.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Here we have some operator (vertex) acting on a state with three mesons, namele $\left\lvert \Omega_ {1} \right\rangle^{(3)}$. The three momenta $\vec{p}_ {1}, \vec{p}_ {2}$ and $\vec{p}_ {3}=-\vec{p}_ {1}-\vec{p}_ {2}$ in the "initial" states are passed on to the "final" state, that's why we have the three long arrows arossing the left and right panel. Momentum conservation demands $\vec{p}_ {1} + \vec{p}_ {2} +\vec{p}_ {3}=0$. The so-called vertex creats another three mesons, that's why we have three meson lines starting in the middle of the plot. Momentum conservation also applies to primed momenta. </div> <p>In the case of 4-mesons, both $H_ {3}$ and $H_ {4}$ contribute. The contribution from $H_ {4}$ is simpler:</p> \[- H_ {2}^{-1} H_ {4}\left\lvert \Omega_ {0} \right\rangle= - \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3}} ,\] <p>while the contribution from $H_ {3}\left\lvert \Omega_ {1} \right\rangle$ is more complicated due to the expansion of $\left\lvert \Omega_ {1} \right\rangle$, we have</p> \[\begin{align*} H_ {3}^{(1)}\left\lvert \Omega_ {1} \right\rangle^{(3)} =&amp; -\frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{3}{2\omega_ {1+2}}A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {1+2} \times \frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1',2'}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}_ {1',2',-1'-2'}\right\rangle_ {0} }{(\omega_ {1'}+\omega_ {2'}+\omega_ {3'})}\\ =&amp; - \frac{m^{2}g^{2}}{2}\int \frac{d^{3}p_ {1,2,1',2'}}{(2\pi)^{12}} \, \frac{3A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {1+2}A_ {1'}^{\ddagger}A^{\ddagger}_ {2'}A^{\ddagger}_ {-1'-2'}\left\lvert \Omega_ {0} \right\rangle}{2\omega_ {1+2}(\omega_ {1'}+\omega_ {2'}+\omega_ {3'})}\\ =&amp; - \frac{9m^{2}g^{2}}{4}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{\omega_ {1+2}(\omega_ {1+2}+\omega_ {3}+\omega_ {1+2+3})} \end{align*}\] <p>where all the contractions offer a factor of 3 and $\left\lvert \vec{p}_ {1,2,3,-1-2-3} \right\rangle$ is a short-handed notation for $\left\lvert \vec{p}_ {1} \vec{p}_ {2} \vec{p}_ {3},-\vec{p}_ {1} -\vec{p}_ {2} -\vec{p}_ {3}\right\rangle$.</p> <p>Thus</p> \[\begin{align*} -H_ {2}^{-1} H_ {3}\left\lvert \Omega_ {1} \right\rangle =&amp; \left( \frac{3mg}{2} \right)^{2} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{1}{\omega_ {1+2}(\omega_ {1+2}+\omega_ {3}+\omega_ {1+2+3})} \\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3})}. \end{align*}\] <p>Putting them together we have</p> \[\boxed{ \begin{align*} \left\lvert \Omega_ {2} \right\rangle^{(4)} = &amp; \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \left( \frac{9m^{2}}{\omega_ {1+2}(\omega_ {1+2}+\omega_ {3}+\omega_ {1+2+3})} -1\right) \\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3}} \end{align*} }\] <hr/> <p>We move on to calculate $\left\lvert \Omega_ {2} \right\rangle^{(2)}=-H_ {2}^{-1} H_ {4}^{(2)}\left\lvert \Omega_ {0} \right\rangle - H_ {2}^{-1} H_ {3}^{(-1)}\left\lvert \Omega_ {1}\right\rangle^{(3)}$. We get</p> \[\begin{align*} - \frac{1}{H_ {2}}H_ {4}^{(2)}\left\lvert \Omega_ {0} \right\rangle =&amp; \frac{1}{2}\delta m^{2} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}_ {1,-1} \right\rangle_ {0}}{2\omega_ {1}} \\ - \frac{1}{H_ {2}}H_ {3}^{(-1)}\left\lvert \Omega_ {1}\right\rangle^{(3)} =&amp; \frac{9m^{2}g^{2}}{4} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}_ {1,-1} \right\rangle_ {0}}{\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})2\omega_ {1}}. \end{align*}\] <p>Putting them together we get</p> \[\left\lvert \Omega \right\rangle^{(2)}_ {2}=\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \left\lbrace \delta m^{2}+\frac{9 m^{2}g^{2}}{2} \int \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{1}{\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \right\rbrace \frac{\left\lvert \vec{p}_ {1,-1} \right\rangle_ {0}}{4\omega_ {1}} .\] <p>The integral over $p_ {2}$ has superfacial degree of divergent $3-3=0$, thus adopts logarithmic divergence. <strong>This divergence ought to be canceled by $\delta m^{2}$</strong>, as we will check later. If that’s true then $\left\lvert \Omega \right\rangle^{(2)}_ {2}=0.$</p> <hr/> <p>The HRC1 equation reads</p> \[H_ {4}^{0}\left\lvert \Omega_ {0} \right\rangle+H_ {3}^{(-3)}\left\lvert \Omega_ {1}^{(3)} \right\rangle+H_ {2}\left\lvert \Omega_ {2} \right\rangle^{(0)}=0,\] <p>but $\left\lvert \Omega_ {2} \right\rangle^{(0)}$ does not exist by construction, if $\left\lvert \Omega_ {2} \right\rangle$ has any $\left\lvert \Omega_ {0} \right\rangle$ component we can absorbe it into the $\left\lvert \Omega_ {0} \right\rangle$ itself. So we are left with</p> \[H_ {4}^{(0)}\left\lvert \Omega_ {0} \right\rangle+H_ {3}^{(-3)}\left\lvert \Omega_ {1}^{(3)} \right\rangle=0,\] <p>This fixes the counter terms. The contribution from $H_ {4}^{(0)}$ is a divergent constant:</p> \[H_ {4}^{(0)}\left\lvert \Omega_ {0} \right\rangle = \int d^{3}x \, C_ {0} \left\lvert \Omega_ {0} \right\rangle.\] <p>So the contribution from $H_ {3}$ must cancel it. In order to compare the above result, we need to keep the $\int d^{3}x$ integral, writing $H_ {3}^{(-3)}$ as</p> \[H_ {3}^{(-3)} = -\frac{mg}{\sqrt{2}} \int d^{3}x \, e^{ -i\vec{x}\cdot(\vec{p}_ {1}+\vec{p}_ {2}+\vec{p}_ {3}) } \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}}\, \frac{1}{2\omega_ {1}2\omega_ {2}2\omega_ {3}} A_ {-1}A_ {-2}A_ {-3} .\] <p>Similar to the calculation before, we have</p> \[\begin{align*} H_ {3}^{(-3)} \left\lvert \Omega_ {1} \right\rangle^{3} =&amp; -\frac{mg}{\sqrt{2}} \int d^{3}x \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}}\, \frac{1}{2\omega_ {1}2\omega_ {2}2\omega_ {3}} A_ {-1}A_ {-2}A_ {-3}\\ &amp;\times \frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1}'}{(2\pi)^{3}} \frac{d^{3}p_ {2}'}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}_ {1}'\vec{p}_ {2}',-\vec{p}_ {1}'-p_ {2}' \right\rangle_ {0} }{(\omega_ {p_ {1}'}+\omega_ {p_ {2}'}+\omega_ {p_ {1}'+p_ {2}'})}\\ =&amp; -\frac{3g^{2}m^{2}}{8} \int d^{3}x \int \frac{d^{3}p_ {1}d^{3}p_ {2}}{(2\pi)^{6}} \, \frac{\left\lvert \Omega \right\rangle_ {0}}{\omega_ {p_ {1}}\omega_ {p_ {2}}\omega_ {p_ {1}+p_ {2}}(\omega_ {p_ {1}}+\omega_ {p_ {2}}+\omega_ {p_ {1}+p_ {2}})} . \end{align*}\] <p>To cancel the divergence, we obviously need</p> \[C_ {0} = A_ {4}' \equiv \frac{3g^{2}m^{2}}{8} \int \frac{d^{3}p_ {1}d^{3}p_ {2}}{(2\pi)^{6}} \, \frac{1}{\omega_ {p_ {1}}\omega_ {p_ {2}}\omega_ {p_ {1}+p_ {2}}(\omega_ {p_ {1}}+\omega_ {p_ {2}}+\omega_ {p_ {1}+p_ {2}})} .\] <hr/> <h3 id="momentum-states-corrections">Momentum states corrections</h3> <p>Next we turn to the renormalization condition for the momentum eigenstates. At order $g^{2}$ this conditions reads</p> \[(\omega_ {p}-H_ {2})\left\lvert p \right\rangle_ {2} = H_ {4} \left\lvert \vec{p} \right\rangle_ {0} +H_ {3}\left\lvert p \right\rangle_ {1} .\] <p>Again we start from the highest meson number and go downwards. The highest possible particle number comes from $H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)}$, which is simple since there only exists creation operators. It reads:</p> \[\left\lvert \vec{p} \right\rangle_ {2}^{(7)} = \frac{m^{2}g^{2}}{2} \int \frac{d^{3}p_ {1,2,3,4}}{(2\pi)^{12}} \, \frac{\left\lvert \vec{p},\vec{p}_ {1,2,3,4,-1-2,-3-4} \right\rangle_ {0}}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {4}+\omega_ {1+2}+\omega_ {3+4})}.\] <hr/> <p><strong>Next Fock space is $5$</strong>, coming from the following contributions:</p> \[H_ {4}^{(4)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} = \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \left\lvert \vec{p},\vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0} ,\] \[H_ {3}^{(3)} \left\lvert \vec{p} \right\rangle_ {1}^{(2)} = \frac{3g^{2}m^{2}}{4\omega_ {p}}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}-\vec{p}_ {1}, \vec{p}_ {1,2,3,-2-3} \right\rangle_ {0}}{\omega _ {p}-\omega_ {1}-\omega_ {p-p_ {1}}}\] <p>and</p> \[H_ {3}^{(1)} \left\lvert \vec{p} \right\rangle_ {1}^{(4)} = - \frac{3g^{2}m^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \left( \frac{3\left\lvert \vec{p},\vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{\omega_ {2+3}(\omega_ {1}+\omega_ {2+3}+\omega_ {1+2+3})} + \frac{\left\lvert \vec{p}_ {1,2,3,-1-2},\vec{p}-\vec{p}_ {3} \right\rangle_ {0}}{\omega_ {p}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \right)\] <p>Does the first term agrees with Jarah’s result? The second term is fine as it is.</p> <p>Altogether these lead to</p> \[\begin{align*} \left\lvert \vec{p}\right\rangle_ {2}^{(5)} =&amp; \frac{g^{2}}{4}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \left( \frac{9m^{2}}{\omega_ {2+3}(\omega_ {1}+\omega_ {2+3}+\omega_ {1+2+3})}-1 \right) \frac{\left\lvert \vec{p},\vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3}} \\ &amp;+ \frac{3g^{2}m^{2}}{4\omega _ {p} }\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}_ {1,2,3,-1-2},\vec{p}-\vec{p}_ {3} \right\rangle_ {0}}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {3}+\omega_ {p+p_ {3}}-\omega_ {p})}. \end{align*}\] <hr/> <p><strong>3-Fock space comes from</strong></p> \[(\omega_ {p}-H_ {2})\left\lvert \vec{p} \right\rangle_ {2}^{(3)} = H_ {4}^{(2)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} +H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} +H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)}.\] <p>Same as before, we get:</p> \[\begin{align*} H_ {4}^{(2)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} =&amp; \frac{g^{2}}{2\omega_ {p}} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\left\lvert \vec{p}-\vec{p}_ {1}-\vec{p}_ {2},\vec{p}_ {1,2} \right\rangle_ {0} -\frac{\delta m^{2}}{2}\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \left\lvert \vec{p},\vec{p}_ {1,-1} \right\rangle_ {0}, \\ H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} =&amp; - \frac{9g^{2}m^{2}}{4\omega_ {p}} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}-\vec{p}_ {1}-\vec{p}_ {2},\vec{p}_ {1,2} \right\rangle_ {0}}{\omega_ {1+2}(-\omega _ {p} +\omega_ {p-p_ {1}-p_ {2}}+\omega_ {1+2})} ,\\ H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} =&amp; - \frac{9m^{2}g^{2}}{4} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p},\vec{p}_ {1,-1} \right\rangle_ {0}}{\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})}\\ &amp;- \frac{9m^{2}g^{2}}{4\omega _ {p} } \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}-\vec{p}_ {1}-\vec{p}_ {2},\vec{p}_ {1,2} \right\rangle_ {0}}{\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \end{align*}\] <p>Inverting $\omega _ {p}-H_ {2}$ we get</p> \[\begin{align*} \left\lvert \vec{p} \right\rangle_ {2}^{(3)} =&amp; \frac{g^{2}}{4\omega _ {p} }\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \left( -2+\frac{9m^{2}}{\omega_ {1+2}}\left( \frac{1}{-\omega _ {p} +\omega_ {p-p_ {1}-p_ {2}}+\omega_ {1+2}} + \frac{1}{\omega_ {1}+\omega_ {2}+\omega_ {1+2}} \right) \right)\\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2},\vec{p}-\vec{p}_ {1}-\vec{p}_ {2} \right\rangle_ {0}}{-\omega _ {p} +\omega_ {1}+\omega_ {2}+\omega_ {p-p_ {1}-p_ {2}}} \\ &amp;- \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \left( \delta m^{2} + \frac{9m^{2}g^{2}}{2}\int \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{1}{\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \right) \frac{\left\lvert \vec{p},\vec{p}_ {1,-1} \right\rangle_ {0}}{4\omega_ {1}}. \end{align*}\] <p>As a consistancy check, this renormalization condition for $\delta m^{2}$ is the same as that we got from $\left\lvert \Omega_ {2} \right\rangle$.</p> <hr/> <p><strong>1-Fock space comes from</strong></p> <p>We have</p> \[(\omega_ {p}-H_ {2})\left\lvert \vec{p} \right\rangle_ {2}^{(1)} = H_ {4}^{(0)} \left\lvert \vec{p} \right\rangle_ {0}^{(1)} +H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} +H_ {3}^{(-3)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)}.\] <p>During the computation sometimes we need again to keep $d^{3}x$ when dealing with conter terms.</p> <p>we have</p> \[\begin{align*} H_ {4}^{(0)}\left\lvert p \right\rangle_ {0}^{(1)} =&amp; A_ {4}'\int d^{3}x \, \left\lvert \vec{p} \right\rangle_ {0} - \frac{\delta m^{2}}{2\omega _ {p} }\left\lvert \vec{p} \right\rangle_ {0},\\ H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} =&amp; -\frac{9g^{2}m^{2}}{8\omega _ {p} } \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p} \right\rangle_ {0}}{\omega_ {1}\omega_ {p+p_ {1}}(-\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})},\\ H_ {3}^{(-3)}\left\lvert p \right\rangle_ {1}^{(4)} =&amp; - \frac{9g^{2}m^{2}\left\lvert \vec{p} \right\rangle_ {0}}{8\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{1}{\omega_ {1}\omega_ {p+p_ {1}}(\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})}\\ &amp;- \frac{3}{8}g^{2}m^{2}\delta^{3}(0) \left\lvert \vec{p} \right\rangle_ {0} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{1}{\omega_ {1}\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})}. \end{align*}\] <p>In the last term if we write $(2\pi)^{3}\delta^{3}(0)=\int d^{3}x$ then it cancels with the $A_ {4}’$ term.</p> <p>Another approach is to use</p> \[\int d^{3}x \, \left( - \frac{\delta m^{2}}{2} :\phi^{2}: \right) = - \frac{\delta m^{2}}{2}\int d^{3}x \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, e^{ -i\vec{x}\cdot(\vec{p}_ {1}+\vec{p}_ {2}) } \left( A^{\ddagger}_ {1,2}+2A^{\ddagger}_ {1} \frac{A_ {-2}}{2\omega_ {1}}+\frac{A_ {-1,-2}}{2\omega_ {1}2\omega_ {2}} \right).\] <p>Now recall that due to the conservation of momentum, $(\omega_ {p}-H_ {2})\left\lvert \vec{p} \right\rangle_ {2}^{(1)} =0$, this allows as to calculate $\delta m^{2}$,</p> \[\begin{align*} \frac{\delta m^{2}}{2\omega _ {p} } =&amp;- \frac{9m^{2}g^{2}}{8\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{1}{\omega_ {1}\omega_ {p+p_ {1}}(-\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})} \\ &amp;- \frac{9g^{2}m^{2}}{8\omega _ {p} } \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{1}{\omega_ {1}\omega_ {p+ {p_ {1}}}(\omega _ {p} +\omega_ {1}+\omega_ {p+p_ {1}})} \\ =&amp; - \frac{9m^{2}g^{2}}{8\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{1}{\omega_ {1}\omega_ {p+p_ {1}}} \left( \frac{2(\omega_ {1}+\omega_ {p+p_ {1}})}{(\omega_ {1}+\omega_ {p+p_ {1}})^{2}-\omega p^{2}} \right)\\ \approx &amp;- \frac{9g^{2}m^{2}}{16\pi^{2}\omega _ {p} }\ln\left( \frac{\Lambda}{m} \right) + \text{const},\\ \implies \delta m^{2} =&amp; - \frac{9g^{2}m^{2}}{8\pi^{2}}\ln\left( \frac{\Lambda}{m} \right) + \text{const} \end{align*}\] <p>The constant part can be fixed later.</p> <p>As for the orthogonal condition, we can check that $_ {0}\left\langle \vec{p}_ {1,2} \middle\vert \vec{p}\right\rangle_ {2}$ indeed is zero.</p> <h2 id="coupling-counter-term-at-order-g3">Coupling counter term at order $g^{3}$</h2> <p>The 3rd-order Hamiltonian density reads</p> \[\mathcal{H}_ {5} = C_ {3}\phi^{3}+ C_ {1}\phi + C_ {0}.\] <p>where</p> \[\begin{align*} C_ {3}=&amp; \frac{m\delta g}{\sqrt{2}} +\frac{g \delta m_ {1}^{2}}{2\sqrt{2}m} - \frac{m^{2}\delta m_ {1}^{4}}{2\sqrt{2}g}, \\ C_ {1}=&amp; m^{2}\delta v_ {3}-\frac{3gm\mathcal{I}_ {1}}{\sqrt{2}}+\frac{m^{3}\delta g^{2}}{\sqrt{2}g^{3}}-\frac{m \delta g\delta m_ {1}^{2}}{2\sqrt{2}g^{2}} -\frac{\delta m_ {1}^{4}}{8\sqrt{2}gm},\\ C_ {0}=&amp; A_ {5}. \end{align*}\] <p>We have the renormalization condition saying that the interaction vacuum is really a vacuum, $H\left\lvert \Omega \right\rangle=0$, the $\left\lvert \Omega_ {0} \right\rangle$ component of it then requires that $C_ {0}=A_ {5}=0$.</p> <p>Since we have</p> \[\begin{align*} \int d^{3}x : \phi^{3}:^{(3)} =&amp; \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {-1-2}^{\ddagger} \\ \int d^{3}x:\phi^{3}:^{(1)} =&amp; \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{3}{2\omega_ {1+2}}A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {1+2}\\ \int d^{3}x:\phi^{3}:^{(-1)} =&amp; \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\,\frac{3}{2\omega_ {2}} \frac{1}{2\omega_ {1+2}} A_ {1}^{\ddagger}A_ {-2} A_ {1+2} \\ \int d^{3}x:\phi^{3}:^{(-3)} =&amp; \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{1}{2\omega_ {1}2\omega_ {2}2\omega_ {1+2}} A_ {-1}A_ {-2}A_ {1+2} \end{align*}\] <p>we have</p> \[\begin{align*} H_ {5}=&amp; H_ {5}^{(3)}+H_ {5}^{(1)}+H_ {5}^{(-1)}+H_ {5}^{(-3)} ,\\ H_ {5}^{(3)}=&amp; C_ {3}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {-1-2}^{\ddagger} ,\\ H_ {5}^{(1)}=&amp; C_ {3}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{3}{2\omega_ {1+2}}A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {1+2} +C_ {1}A_ {0}^{\ddagger} ,\\ H_ {5}^{(-1)}=&amp;C_ {3} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\,\frac{3}{2\omega_ {2}} \frac{1}{2\omega_ {1+2}} A_ {1}^{\ddagger}A_ {-2} A_ {1+2} + C_ {1} \frac{A_ {0}}{2m} ,\\ H_ {5}^{(-3)}=&amp; C_ {3}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{1}{2\omega_ {1}2\omega_ {2}2\omega_ {1+2}} A_ {-1}A_ {-2}A_ {1+2} ,\\ \end{align*}\] <h3 id="the-vacuum-correction">The vacuum correction</h3> <p>where $C_ {3},C_ {1}$ are parameters to be determined. As before the equation for $\left\lvert \Omega \right\rangle_ {3}$ is :</p> \[\left\lvert \Omega \right\rangle_ {3} = -H_ {2}^{-1}(H_ {5}\left\lvert \Omega \right\rangle_ {0}+H_ {4}\left\lvert \Omega \right\rangle_ {1}+H_ {3}\left\lvert \Omega \right\rangle_ {2}),\] <p>if separate into different Fock spaces we get</p> \[\begin{align*} - H_ {2}\left\lvert \Omega \right\rangle_ {3}^{(9)} =&amp; H_ {3}^{(3)} \left\lvert \Omega \right\rangle_ {2}^{(6)},\\ - H_ {2}\left\lvert \Omega \right\rangle_ {3}^{(7)} =&amp; H_ {3}^{(3)} \left\lvert \Omega \right\rangle_ {2}^{(4)}+H_ {3}^{(1)} \left\lvert \Omega \right\rangle_ {2}^{(6)}+H_ {4}^{(4)}\left\lvert \Omega \right\rangle_ {1}^{(3)},\\ - H_ {2}\left\lvert \Omega \right\rangle_ {3}^{(5)} =&amp; H_ {3}^{(1)}\left\lvert \Omega \right\rangle_ {2}^{(4)} +H_ {3}^{(-1)}\left\lvert \Omega \right\rangle_ {2}^{(6)} +H_ {4}^{(2)}\left\lvert \Omega \right\rangle_ {1}^{(3)}, \\ - H_ {2}\left\lvert \Omega \right\rangle_ {3}^{(3)} =&amp; H_ {3}^{(-1)}\left\lvert \Omega \right\rangle_ {2}^{(4)} +H_ {3}^{(-3)}\left\lvert \Omega \right\rangle_ {2}^{(6)} +H_ {4}^{(0)} \left\lvert \Omega \right\rangle_ {1}^{(3)}, \\ - H_ {2}\left\lvert \Omega \right\rangle_ {3}^{(1)} =&amp; H_ {3}^{(-3)}\left\lvert \Omega \right\rangle_ {2}^{(4)}+H_ {4}^{(-2)}\left\lvert \Omega \right\rangle_ {1}^{(3)}+H_ {5}^{(1)}\left\lvert \Omega \right\rangle_ {0}. &amp; \end{align*}\] <p>Substitute the ingredients and simplify as before, we get the following results.</p> <h4 id="leftlvert-omega-rightrangle_-39">$\left\lvert \Omega \right\rangle_ {3}^{(9)}:$</h4> <p>\(\begin{align*} \left\lvert \Omega \right\rangle_ {3}^{(9)} =&amp; \frac{g^{3}m^{3}}{2\sqrt{2}}\int \frac{d^{3}p_ {1,2,3,4,5,6}}{(2\pi)^{18}} \, \frac{1}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {4}+\omega_ {1+2}+\omega_ {3+4})} \\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2,3,4,5,6},-\vec{p}_ {1}-\vec{p}_ {2},-\vec{p}_ {3}-\vec{p}_ {4}，-\vec{p}_ {5}-\vec{p}_ {6} \right\rangle_ {0}}{(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {4}+\omega_ {5}+\omega_ {6}+\omega_ {1+2}+\omega_ {3+4}+\omega_ {5+6})} \end{align*}\)</p> <h4 id="leftlvert-omega-rightrangle_-37">$\left\lvert \Omega \right\rangle_ {3}^{(7)}:$</h4> \[\begin{align*} H_ {3}^{(3)}\left\lvert \Omega \right\rangle_ {2}^{(4)} =&amp; -\frac{g^{3}m}{4\sqrt{2}}\int \frac{d^{3}p_ {1,2,3,4,5}}{(2\pi)^{15}} \, \frac{ \frac{9m^{2}}{\omega_ {3+4}(\omega_ {3+4}+\omega_ {5}+\omega_ {3+4+5})}-1 }{\omega_ {3}+\omega_ {4}+\omega_ {5}+\omega_ {3+4+5}} \left\lvert \vec{p}_ {1,2,3,4,5},\vec{p}_ {-1-2},\vec{p}_ {-3-4-5} \right\rangle_ {0},\\ H_ {3}^{(1)}\left\lvert \Omega \right\rangle_ {2}^{(6)} =&amp; -\frac{9 g^3 m^3}{4 \sqrt{2}} \int \frac{d^{3}p_ {1,2,3,4,5}}{(2\pi)^{15}} \, \frac{\left\lvert \vec{p}_ {1,2,3,4,5,-1-2-3,-4-5} \right\rangle_ {0}}{\omega_ {1+2}(\omega_ {1+2}+\omega_ {3}+\omega_ {1+2+3})(\omega_ {4}+\omega_ {5}+\omega_ {4+5})}, \\ H_ {4}^{(4)}\left\lvert \Omega \right\rangle_ {1}^{(3)} =&amp; \frac{g^{3}m}{4\sqrt{2}} \int \frac{d^{3}p_ {1,2,3,4,5}}{(2\pi)^{15}} \, \frac{\left\lvert \vec{p}_ {1,2,3,4,5,-1-2-3,-4-5} \right\rangle_ {0}}{\omega_ {4}+\omega_ {5}+\omega_ {4+5}}. \end{align*}\] <p>Put altogether and inverse $-H_ {2}$, we get:</p> \[\left\lvert \Omega \right\rangle_ {3}^{(7)} = \frac{g^{3}m}{4\sqrt{2}}\int \frac{d^{3}p_ {1,2,3,4,5}}{(2\pi)^{15}} \, \frac{\left( \frac{9m^{2}}{\omega_ {1+2}(\omega_ {1+2}+\omega_ {3}+\omega_ {1+2+3})}-1 \right)\left\lvert \vec{p}_ {1,2,3,4,5,-1-2-3,-4-5} \right\rangle_ {0}}{(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3})(\omega_ {4}+\omega_ {5}+\omega_ {4+5})}.\] <h4 id="leftlvert-omega-rightrangle_-35">$\left\lvert \Omega \right\rangle_ {3}^{(5)}:$</h4> <p>we have</p> \[\begin{align*} H_ {3}^{(1)}\left\lvert \Omega \right\rangle_ {2}^{(4)} =&amp; \frac{3 g^3 m}{4 \sqrt{2}} \int \frac{d^{3}p_ {1,2,3,4}}{(2\pi)^{12}} \, \frac{\left\lvert \vec{p}_ {1,2,3,4,-1-2-3-4} \right\rangle_ {0}}{\omega_ {1+2}+\omega_ {3}+\omega_ {4}+\omega_ {1+2+3+4}} \\ &amp;\times \left(2- \frac{9m^{2}}{\omega_ {3+4}(\omega_ {1+2}+\omega_ {3+4}+\omega_ {1+2+3+4})}-\frac{9m^{2}}{\omega_ {1+2+3}(\omega_ {1+2+3}+\omega_ {4}+\omega_ {1+2+3+4})}\right), \\ H_ {3}^{(-1)}\left\lvert \Omega \right\rangle_ {2}^{(6)}=&amp; -\frac{9g^{3}m^{3}}{4\sqrt{2}}\int \frac{d^{3}p_ {1,2,3,4}}{(2\pi)^{12}} \, \left( \frac{\left\lvert \vec{p}_ {1,2,3,-1,-2-3} \right\rangle_ {0}}{\omega_ {4}\omega_ {1+4}(\omega_ {2}+\omega_ {3}+\omega_ {2+3})(\omega_ {1}+\omega_ {4}+\omega_ {1+4})} \right. \\ &amp;\left. + \frac{3\left\lvert \vec{p}_ {2,4,-1-2,1+3,-3-4} \right\rangle_ {0}}{\omega_ {1}\omega_ {3}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {1}+\omega_ {2}+\omega_ {1+2}+\omega_ {3}+\omega_ {4}+\omega_ {3+4})}\right) , \\ H_ {4}^{(2)}\left\lvert \Omega \right\rangle_ {1}^{(3)} =&amp; -\delta m^{2}\frac{gm}{2\sqrt{2}} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}_ {1,2,3,-1,-2-3} \right\rangle_ {0}}{\omega_ {2}+\omega_ {3}+\omega_ {2+3}} \\ &amp;+ \frac{3g^{3}m}{2\sqrt{2}} \int \frac{d^{3}p_ {1,2,3,4}}{(2\pi)^{12}} \, \frac{\left\lvert \vec{p}_ {1,2,3,-3-4,-1-2+4} \right\rangle_ {0}}{\omega_ {4}(\omega_ {3}+\omega_ {4}+\omega_ {3+4})}. \end{align*}\] <p>Next step would be inversing the $-H_ {2}$, put everything together and simplify, but I’ll leave to later.</p> <h4 id="leftlvert-omega-rightrangle_-33">$\left\lvert \Omega \right\rangle_ {3}^{(3)}$</h4> <p>We have</p> \[\begin{align*} H_ {3}^{(-1)}\left\lvert \Omega \right\rangle_ {2}^{(4)} =&amp; \frac{8g^{2}m}{2\sqrt{2}}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \left\lvert \vec{p}_ {1,3,-1-3} \right\rangle_ {0} \left( \frac{1}{2\omega_ {2}\omega_ {1+2}(\omega_ {2}+\omega_ {1+2}+\omega_ {3}+\omega_ {1+3})} \right. \\ &amp;+ \frac{3m^{2}}{\omega_ {2}\omega_ {1+2}\omega_ {1+2+3}(\omega_ {2}+\omega_ {3}+\omega_ {1+2}+\omega_ {1+3})(\omega_ {2}+\omega_ {1+3}+\omega_ {1+2+3})} \\ &amp;\left.+\frac{3m^{2}(2\omega_ {1}+\omega_ {2}+\omega_ {1+2}+\omega_ {3}+\omega_ {1+3})}{4\omega_ {1}\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {1}+\omega_ {3}+\omega_ {1+3})(\omega_ {2}+\omega_ {3}+\omega_ {1+2}+\omega_ {1+3})} \right), \\ H_ {3}^{(-3)}\left\lvert \Omega \right\rangle_ {2}^{(6)} =&amp; \\ H_ {4}^{(0)}\left\lvert \Omega \right\rangle_ {1}^{(3)} =&amp; \frac{gm}{4\sqrt{2}}\int d^{3}x \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \left( \frac{-6\delta m^{2}}{\omega_ {1}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})}+\frac{4A_ {4}'}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \right)\left\lvert \vec{p}_ {1,2,-1-2} \right\rangle_ {0} \\ &amp;+ \frac{9mg^{3}}{4\sqrt{2}}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}_ {1,2,-1-2} \right\rangle_ {0}}{\omega_ {3}\omega_ {1+2+3}(\omega_ {1+2}+\omega_ {3}+\omega_ {1+2+3})} \end{align*}\] <h4 id="leftlvert-omega-rightrangle_-31">$\left\lvert \Omega \right\rangle_ {3}^{(1)}$</h4> <p>We have</p> \[\begin{align*} H_ {5}^{(1)} \left\lvert \Omega \right\rangle_ {0}^{(0)} =&amp; C_ {1}\left\lvert \vec{p} \right\rangle {\Large\mid}_ {\vec{p}=0} , \\ H_ {3}^{(-3)} \left\lvert \Omega \right\rangle_ {2}^{(4)} =&amp; -\frac{3gm\delta m^{2}}{4\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}=0 \right\rangle_ {0}}{\omega_ {1}^{2}(m+2\omega_ {1})}+\frac{3g^{3}}{4\sqrt{2}}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}=0 \right\rangle_ {0}}{\omega_ {1}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ H_ {4}^{(-2)} \left\lvert \Omega \right\rangle_ {1}^{(3)} =&amp; - \delta m^{2} \frac{3gm}{4\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)} \, \frac{\left\lvert \vec{p}=0 \right\rangle}{\omega_ {1}^{2}(m+2\omega_ {1})}+\frac{3g^{3}}{4\sqrt{2}}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}=0 \right\rangle}{\omega_ {1}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})}. \end{align*}\] <p>Inverse $-H_ {2}$ and put everything altogether</p> \[\left\lvert \Omega \right\rangle_ {3}^{(1)} = - \frac{C_ {1}\left\lvert \vec{p}=0 \right\rangle_ {0}}{m}-\frac{3gm\delta m^{2}}{2\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}=0 \right\rangle_ {0}}{\omega_ {1}^{2}(m+2\omega_ {1})}+\frac{3g^{3}}{2\sqrt{2}}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}=0 \right\rangle_ {0}}{\omega_ {1}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})}\] <hr/> <p><strong>Let’s apply the no-tadpole condition.</strong> Expand and match the coupling, we find the equation involving $H_ {5}$ is</p> \[_ {3}\left\langle \Omega \right\rvert \phi(\vec{x})\left\lvert \Omega \right\rangle_ {0} = - _ {2}\left\langle \Omega \right\rvert \phi(\vec{x})\left\lvert \Omega \right\rangle_ {1},\] <p>This should allow us to fix a constant parameter ($C_ {1}$ specifically) in $H_ {5}$. The right hand side reduces to</p> \[\begin{align*} \left\langle \Omega_ {2} \right\rvert\phi(\vec{x})\left\lvert \Omega_ {1} \right\rangle =&amp; \frac{e^{ -i\vec{k}\cdot \vec{x} }}{2m} C_ {1} \\ =&amp;\left\langle \Omega_ {2}^{(4)} \right\rvert\phi(\vec{x})\left\lvert \Omega_ {1}^{(3)} \right\rangle \\ =&amp; -\frac{e^{ -i\vec{k}\cdot \vec{x} }3g^{3}m\left\lvert \Omega_ {0} \right\rangle}{2\sqrt{2}}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{-9m^{2}+\omega_ {1}^{2}+\omega_ {1}(\omega_ {2}+\omega_ {1+2})}{\omega_ {1}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})^{2}(m+\omega_ {1}+\omega_ {2}+\omega_ {1+2})}\\ &amp;+ \frac{-9m^{2}+\omega_ {2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})}{\omega_ {2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})^{2}(m+\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ &amp;+ \frac{2(-9m^{2}+m\omega_ {1+2}+2\omega_ {1+2}^{2})}{\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(m+\omega_ {1}+\omega_ {2}+\omega_ {1+2})(m+2\omega_ {1+2})} \end{align*}\] <p>Looks like the integral can not be simplified any more.</p> <hr/> <h3 id="momentum-state-correction">Momentum state correction</h3> <p>From $H\left\lvert \vec{p} \right\rangle=\omega _ {p}\left\lvert \vec{p} \right\rangle$, expand it, the $g^{3}$ order part reads</p> \[(H_ {2}-\omega _ {p} )\left\lvert \vec{p} \right\rangle_ {3} = -H_ {3}\left\lvert \vec{p} \right\rangle_ {2}-H_ {4}\left\lvert \vec{p} \right\rangle_ {1} - H_ {5} \left\lvert \vec{p} \right\rangle_ {0},\] <p>separate into different Fock spaces we get:</p> \[\begin{align*} (\omega _ {p} -H_ {2})\left\lvert \vec{p} \right\rangle_ {3}^{(10)} =&amp; H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {2}^{(7)} , \\ (\omega _ {p} -H_ {2})\left\lvert \vec{p} \right\rangle_ {3}^{(8)} =&amp; H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {2}^{(7)} + H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)} + H_ {4}^{(4)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} , \\ (\omega _ {p} -H_ {2})\left\lvert \vec{p} \right\rangle_ {3}^{(6)} =&amp; H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {2}^{(7)} + H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)}+ H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {2}^{(3)} + H_ {4}^{(2)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)}+H_ {4}^{(4)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} , \\ (\omega _ {p} -H_ {2})\left\lvert \vec{p} \right\rangle_ {3}^{(4)} =&amp; H_ {3}^{(-3)}\left\lvert \vec{p} \right\rangle_ {2}^{(7)} +H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)} + H_ {3}^{(1)} \left\lvert \vec{p} \right\rangle_ {2}^{(1)} + H_ {4}^{(0)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)}+ H_ {4}^{(2)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} +H_ {5}^{(3)}\left\lvert \vec{p} \right\rangle_ {0}^{(1)}, \\ (\omega _ {p} -H_ {2})\left\lvert \vec{p} \right\rangle_ {3}^{(2)} =&amp; H_ {3}^{(-3)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)}+ H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {2}^{(3)} + H_ {4}^{(0)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} + H_ {4}^{(-2)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} +H_ {5}^{(1)}\left\lvert \vec{p} \right\rangle_ {0}^{(1)}, \\ (\omega _ {p} -H_ {2})\left\lvert \vec{p} \right\rangle_ {3}^{(0)} =&amp;H_ {3}^{(-3)} \left\lvert \vec{p} \right\rangle_ {2}^{(3)} +H_ {4}^{(-4)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)}+H_ {4}^{(-2)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)}+H_ {5}^{(-1)}\left\lvert \vec{p} \right\rangle_ {0}^{(1)}=0. \end{align*}\] <h4 id="leftlvert-vecp-rightrangle_-310">$\left\lvert \vec{p} \right\rangle_ {3}^{(10)}$</h4> <p>we have</p> \[H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {2}^{(7)} = - \frac{g^{3}m^{3}}{2\sqrt{2}} \int \frac{d^{3}p_ {1,2,3,4,5,6}}{(2\pi)^{18}} \, \frac{\left\lvert \vec{p},\vec{p}_ {1,2,3,4,5,6,-1-2,-3-4,-5-6} \right\rangle_ {0}}{\omega_ {3}+\omega_ {4}+\omega_ {5}+\omega_ {5}+\omega_ {3+4}+\omega_ {5+6}}\] <p>inverse $\omega _ {p}-H_ {2}$ we get</p> \[\begin{align*} \left\lvert \vec{p} \right\rangle_ {3}^{10} =&amp;- \frac{g^{3}m^{3}}{2\sqrt{2}} \int \frac{d^{3}p_ {1,2,3,4,5,6}}{(2\pi)^{18}} \, \frac{1}{\omega_ {3}+\omega_ {4}+\omega_ {5}+\omega_ {5}+\omega_ {3+4}+\omega_ {5+6}} \\ &amp;\times \frac{\left\lvert \vec{p},\vec{p}_ {1,2,3,4,5,6,-1-2,-3-4,-5-6} \right\rangle_ {0}}{\omega _ {p} +\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {4}+\omega_ {5}+\omega_ {6}+\omega_ {1+2}+\omega_ {3+4}+\omega_ {5+6}}. \end{align*}\] <h4 id="leftlvert-vecp-rightrangle_-38">$\left\lvert \vec{p} \right\rangle_ {3}^{(8)}$</h4> <p>we get</p> \[\begin{align*} H_ {3}^{(1)}\left\lvert \vec{p} \right\rangle_ {2}^{(7)} =&amp; \\ H_ {3}^{(3)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)} =&amp; \\ H_ {4}^{(4)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)} =&amp; \end{align*}\] <h4 id="leftlvert-vecp-rightrangle_-36">$\left\lvert \vec{p} \right\rangle_ {3}^{(6)}$</h4> <h4 id="leftlvert-vecp-rightrangle_-34">$\left\lvert \vec{p} \right\rangle_ {3}^{(4)}$</h4> <p>We have</p> \[H_ {5}\left\lvert \vec{p} \right\rangle_ {0} = C_ {5,3}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \left\lvert \vec{p},\vec{p}_ {1,2,-1-2} \right\rangle + \frac{3C_ {5,3}}{2\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \left\lvert \vec{p}-\vec{p}_ {f_ {1}},\vec{p}_ {1} \right\rangle + C_ {5,1} \left\lvert \vec{p},0 \right\rangle .\] <h4 id="leftlvert-vecp-rightrangle_-32">$\left\lvert \vec{p} \right\rangle_ {3}^{(2)}$</h4> <p>In summary, we have</p> \[\begin{align*} H_ {3}^{(-3)}\left\lvert \vec{p} \right\rangle_ {2}^{(5)} =&amp; ,\\ H_ {3}^{(-1)}\left\lvert \vec{p} \right\rangle_ {2}^{(3)} =&amp; ,\\ H_ {4}^{(0)}\left\lvert \vec{p} \right\rangle_ {1}^{(2)} =&amp; \frac{3gm A_ {4}'}{2\sqrt{2}\omega _ {p} }\int d^{3}x \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}_ {1},\vec{p}-\vec{p}_ {1} \right\rangle}{-\omega _ {p} +\omega_ {1}+\omega_ {p-p_ {1}}} \\ &amp; - \frac{3gm\delta m^{2}}{2\sqrt{2}\omega _ {p} } \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}_ {1},\vec{p}-\vec{p}_ {1} \right\rangle}{\omega_ {1}(-\omega _ {p} +\omega_ {1}+\omega_ {p-p_ {1}})} \\ &amp;+ \frac{9mg^{3}}{8\sqrt{2}\omega _ {p} } \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}_ {1},\vec{p}-\vec{p}_ {1} \right\rangle}{\omega_ {2}\omega_ {p+p_ {2}}(-\omega _ {p} +\omega_ {2}+\omega_ {p+p_ {2}})} \\ H_ {4}^{(-2)}\left\lvert \vec{p} \right\rangle_ {1}^{(4)}=&amp; ,\\ H_ {5}^{(1)}\left\lvert \vec{p} \right\rangle_ {0}^{(1)}=&amp; C_ {5,1} \left\lvert \vec{p},\vec{q}=0 \right\rangle + \frac{3C_ {5,3}}{2\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \left\lvert \vec{p}_ {1},\vec{p}-\vec{p}_ {1} \right\rangle_ {0} , \end{align*}\] <h4 id="leftlvert-vecp-rightrangle_-30">$\left\lvert \vec{p} \right\rangle_ {3}^{(0)}$</h4> <h1 id="summary-of-results">Summary of results</h1> <p>I use the shorthand notation $\left\lvert \vec{p}_ {-1-2} \right\rangle:=\left\lvert -\vec{p}_ {1}-\vec{p}_ {2} \right\rangle$, $\left\lvert \vec{p}_ {-1’-2’} \right\rangle:=\left\lvert -\vec{p}’_ {1}-\vec{p}’_ {2} \right\rangle$, $\omega_ {1}=\omega_ {p_ {1}}, \omega_ {1’}=\omega_ {\vec{p}_ {1}’},\omega_ {1+2}=\omega_ {p_ {1}+p_ {2}}$. Multiple indices usually denote tensor product, for example $\left\lvert \vec{p}_ {1,2} \right\rangle:=\left\lvert \vec{p}_ {1} \right\rangle\left\lvert \vec{p}_ {2} \right\rangle=\left\lvert \vec{p}_ {1}\vec{p}_ {2} \right\rangle$, and</p> \[\frac{d^{3}p_ {1,2,1',2'}}{(2\pi)^{12}} := \frac{d^{3}p_ {1}}{(2\pi)^{3}}\frac{d^{3}p_ {2}}{(2\pi)^{3}}\frac{d^{3}p'_ {1}}{(2\pi)^{3}}\frac{d^{3}p'_ {2}}{(2\pi)^{3}}.\] <p>We also simplify $A_ {p_ {1}}^{\ddagger}$ as $A_ {1}^{\ddagger}$ and $A_ {-p_ {1}-p_ {2}}$ as $A_ {-1-2}$.</p> <h2 id="hamiltonians">Hamiltonians:</h2> <p>In the below is the summary of Hamiltonians updated by Hamiltonian Renormalization Conditions (HRC):</p> \[\begin{align*} \mathcal{H}_ {0} =&amp; \mathcal{H}_ {1}=0, \\ \mathcal{H}_ {2} =&amp; \frac{\pi^{2}}{2} + \frac{(\partial \phi)^{2}}{2} + \frac{1}{2}m^{2}\phi^{2} \\ H_ {2} =&amp; \int \frac{d^{3}p}{(2\pi)^{3}} \, \omega_ {p} A^{\ddagger}_ {p} A_ {p} , \\ \mathcal{H}_ {3} =&amp; -\frac{mg}{\sqrt{2}} \phi^{3}, \\ H_ {3} =&amp; H_ {3}^{(3)}+H_ {3}^{(1)}+H_ {3}^{(-1)} + H_ {3}^{(-3)} \end{align*}\] <p>where</p> \[\begin{align*} H_ {3}^{(3)} =&amp; -\frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {-1-2}^{\ddagger} \\ H_ {3}^{(1)} =&amp; -\frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{3}{2\omega_ {1+2}}A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {1+2} \\ H_ {3}^{(-1)} =&amp; -\frac{mg}{\sqrt{2}}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\,\frac{3}{2\omega_ {2}} \frac{1}{2\omega_ {1+2}} A_ {1}^{\ddagger}A_ {-2} A_ {1+2} \\ H_ {3}^{(-3)} =&amp; -\frac{mg}{\sqrt{2}}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{1}{2\omega_ {1}2\omega_ {2}2\omega_ {1+2}} A_ {-1}A_ {-2}A_ {1+2} . \end{align*}\] <p>In each term the momentum conservation is suggested by the fact that, if we treat the subscript of creation operators as plus momenta, that of the annihilation operators as negative momenta, then their summation gives zero, for example in $A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {1+2}$ the total momentum would be (1+2-1-2) which is zero.</p> <p>and</p> \[\begin{align*} H_ {4} =&amp; \sum_ {n=0}^{4} H_ {4}^{(4-2n)}, \\ H_ {4}^{(4)} =&amp; \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, A^{\ddagger}_ {1}A^{\ddagger}_ {2}A^{\ddagger}_ {3}A^{\ddagger}_ {-1-2-3} ,\\ H_ {4}^{(2)} =&amp; g^{2} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, A^{\ddagger}_ {1}A^{\ddagger}_ {2}A^{\ddagger}_ {3} \frac{A_ {1+2+3}}{2\omega_ {1+2+3}} \\ &amp;- \frac{\delta m_ {1}^{2}}{2} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, A_ {1}^{\ddagger}A_ {-1}^{\ddagger},\\ H_ {4}^{(0)} =&amp; \frac{3g^{2}}{2} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}}\, A^{\ddagger}_ {1} A^{\ddagger}_ {2} \frac{A_ {-3}}{2\omega_ {3}}\frac{A_ {1+2+3}}{2\omega_ {1+2+3}} \\ &amp;- \delta m_ {1}^{2} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{A_ {1}^{\ddagger}A_ {1}}{2\omega_ {1}}+\int d^{3}x \, A_ {4}' ,\\ H_ {4}^{(-2)} =&amp; g^{2}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}}\, A^{\ddagger}_ {1} \frac{A_ {-2}}{2\omega_ {2}}\frac{A_ {-3}}{2\omega_ {3}}\frac{A_ {1+2+3}}{2\omega_ {1+2+3}} \\ &amp; -\frac{\delta m_ {1}^{2}}{2}\int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{A_ {1}A_ {-1}}{(2\omega_ {1})^{2}} , \\ H_ {4}^{(-4)} =&amp; \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}}\, \frac{A_ {-1}}{2\omega_ {1}}\frac{A_ {-2}}{2\omega_ {2}}\frac{A_ {-3}}{2\omega_ {3}}\frac{A_ {1+2+3}}{2\omega_ {1+2+3}} . \end{align*}\] <p>and</p> \[\begin{align*} H_ {5}=&amp; H_ {5}^{(3)}+H_ {5}^{(1)}+H_ {5}^{(-1)}+H_ {5}^{(-3)} ,\\ H_ {5}^{(3)}=&amp; C_ {5,3}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {-1-2}^{\ddagger} ,\\ H_ {5}^{(1)}=&amp; C_ {5,3}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{3}{2\omega_ {1+2}}A_ {1}^{\ddagger}A_ {2}^{\ddagger}A_ {1+2} +C_ {5,1}A_ {0}^{\ddagger} ,\\ H_ {5}^{(-1)}=&amp;C_ {5,3} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\,\frac{3}{2\omega_ {2}} \frac{1}{2\omega_ {1+2}} A_ {1}^{\ddagger}A_ {-2} A_ {1+2} + C_ {5,1} \frac{A_ {0}}{2m} ,\\ H_ {5}^{(-3)}=&amp; C_ {5,3}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}}\, \frac{1}{2\omega_ {1}2\omega_ {2}2\omega_ {1+2}} A_ {-1}A_ {-2}A_ {1+2} ,\\ \end{align*}\] <p>where $C_ {5,i}$ are some combinations of counter terms whose value will be fixed later.</p> <h2 id="vacuum-states-corrections">Vacuum states corrections</h2> <p>The corrections to vacuum states:</p> \[\begin{align*} \left\lvert \Omega \right\rangle_ {1}^{(3)} =&amp; \frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}_ {1,2,-1-2}\right\rangle_ {0} }{(\omega_ {1}+\omega_ {2}+\omega_ {3})}, \\ \left\lvert \Omega \right\rangle_ {2}^{(6)} =&amp;\frac{m^{2}g^{2}}{2} \int \frac{d^{3}p_ {1,2,1',2'}}{(2\pi)^{12}} \\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2,-1-2}\;\vec{p}'_ {1,2,-1-2} \right\rangle_ {0}}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {1}+\omega_ {2}+\omega_ {1+2}+\omega_ {1'}+\omega_ {2'}+\omega_ {1'+2'})} \\ \left\lvert \Omega \right\rangle_ {2}^{(4)} =&amp; \frac{g^{2}}{4} \int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \left( \frac{9m^{2}}{\omega_ {1+2}(\omega_ {1+2}+\omega_ {3}+\omega_ {1+2+3})} -1\right) \\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3}} ,\\ \left\lvert \Omega \right\rangle_ {3}^{(9)} =&amp; \frac{g^{3}m^{3}}{2\sqrt{2}}\int \frac{d^{3}p_ {1,2,3,4,5,6}}{(2\pi)^{18}} \, \frac{1}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {4}+\omega_ {1+2}+\omega_ {3+4})} \\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2,3,4,5,6},-\vec{p}_ {1}-\vec{p}_ {2},-\vec{p}_ {3}-\vec{p}_ {4}，-\vec{p}_ {5}-\vec{p}_ {6} \right\rangle}{(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {4}+\omega_ {5}+\omega_ {6}+\omega_ {1+2}+\omega_ {3+4}+\omega_ {5+6})}\\ \left\lvert \Omega \right\rangle_ {3}^{(7)} =&amp; \frac{g^{3}m}{4\sqrt{2}}\int \frac{d^{3}p_ {1,2,3,4,5}}{(2\pi)^{15}} \, \frac{\left( \frac{9m^{2}}{\omega_ {1+2}(\omega_ {1+2}+\omega_ {3}+\omega_ {1+2+3})}-1 \right)\left\lvert \vec{p}_ {1,2,3,4,5,-1-2-3,-4-5} \right\rangle}{(\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3})(\omega_ {4}+\omega_ {5}+\omega_ {4+5})},\\ \left\lvert \Omega \right\rangle_ {3}^{(5)} =&amp; \\ \left\lvert \Omega \right\rangle_ {3}^{(3)} =&amp; \\ \left\lvert \Omega \right\rangle_ {3}^{(1)} =&amp; - \frac{C_ {1}\left\lvert \vec{p}=0 \right\rangle}{m}-\frac{3gm\delta m^{2}}{2\sqrt{2}} \int \frac{d^{3}p_ {1}}{(2\pi)^{3}} \, \frac{\left\lvert \vec{p}=0 \right\rangle}{\omega_ {1}^{2}(m+2\omega_ {1})}+\frac{3g^{3}}{2\sqrt{2}}\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p}=0 \right\rangle}{\omega_ {1}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \end{align*}\] <p>The momentum eigenstates:</p> \[\begin{align*} \left\lvert \vec{p} \right\rangle_ {1}^{(2)} =&amp; \frac{3mg}{2\sqrt{2}\omega _ {p} }\int \frac{d^{3}p_ {1}}{(2\pi)^{3}}\, \frac{\left\lvert \vec{p}_ {1},\vec{p} -\vec{p}_ {1} \right\rangle^{(2)}_ {0}}{\omega_ {p_ {1}}+\omega_ {p-p_ {1}}-\omega_ {p}} , \\ \left\lvert \vec{p} \right\rangle_ {1}^{(4)} =&amp; \frac{mg}{\sqrt{2}} \int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \frac{\left\lvert \vec{p} \, \vec{p}_ {1,2,-1-2} \right\rangle_ {0}^{(4)}}{\omega_ {1}+\omega_ {2}+\omega_ {1+2}}, \\ \left\lvert \vec{p} \right\rangle_ {2}^{(7)} =&amp; \frac{m^{2}g^{2}}{2} \int \frac{d^{3}p_ {1,2,3,4}}{(2\pi)^{12}} \, \frac{\left\lvert \vec{p},\vec{p}_ {1,2,3,4,-1-2,-3-4} \right\rangle_ {0}}{\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {4}+\omega_ {1+2}+\omega_ {3+4}}, \\ \left\lvert \vec{p}\right\rangle_ {2}^{(5)} =&amp; \frac{g^{2}}{4}\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \left( \frac{9m^{2}}{\omega_ {2+3}(\omega_ {1}+\omega_ {2+3}+\omega_ {1+2+3})}-1 \right) \frac{\left\lvert \vec{p},\vec{p}_ {1,2,3,-1-2-3} \right\rangle_ {0}}{\omega_ {1}+\omega_ {2}+\omega_ {3}+\omega_ {1+2+3}} \\ &amp;+ \frac{3g^{2}m^{2}}{4\omega _ {p} }\int \frac{d^{3}p_ {1,2,3}}{(2\pi)^{9}} \, \frac{\left\lvert \vec{p}_ {1,2,3,-1-2},\vec{p}-\vec{p}_ {3} \right\rangle_ {0}}{(\omega_ {1}+\omega_ {2}+\omega_ {1+2})(\omega_ {3}+\omega_ {p+p_ {3}}-\omega_ {p})}.\\ \left\lvert \vec{p} \right\rangle_ {2}^{(3)} =&amp; \frac{g^{2}}{4\omega _ {p} }\int \frac{d^{3}p_ {1,2}}{(2\pi)^{6}} \, \left( -2+\frac{9m^{2}}{\omega_ {1+2}}\left( \frac{1}{-\omega _ {p} +\omega_ {p-p_ {1}-p_ {2}}+\omega_ {1+2}} + \frac{1}{\omega_ {1}+\omega_ {2}+\omega_ {1+2}} \right) \right)\\ &amp;\times \frac{\left\lvert \vec{p}_ {1,2},\vec{p}-\vec{p}_ {1}-\vec{p}_ {2} \right\rangle_ {0}}{-\omega _ {p} +\omega_ {1}+\omega_ {2}+\omega_ {p-p_ {1}-p_ {2}}} \end{align*}\] <p>The counter terms:</p> \[\begin{align*} \delta v_ {1}= &amp;- \frac{m}{\sqrt{2}g} \left( \frac{\delta g}{g}- \frac{\delta m_ {1}^{2}}{2m^{2}}- \frac{\delta m_ {1}^{4}}{2g^{2}} \right) \\ \delta v_ {2} =&amp; 0, \\ A_ {4}' \equiv&amp; \frac{3g^{2}m^{2}}{8} \int d^{3}x\,\frac{d^{3}p_ {1}d^{3}p_ {2}}{(2\pi)^{6}} \, \frac{1}{\omega_ {p_ {1}}\omega_ {p_ {2}}\omega_ {p_ {1}+p_ {2}}(\omega_ {p_ {1}}+\omega_ {p_ {2}}+\omega_ {p_ {1}+p_ {2}})} ,\\ \delta m^{2} =&amp; - \frac{9m^{2}g^{2}}{2}\int \frac{d^{3}p_ {2}}{(2\pi)^{3}} \, \frac{1}{\omega_ {2}\omega_ {1+2}(\omega_ {1}+\omega_ {2}+\omega_ {1+2})} \\ =&amp; - \frac{9g^{2}m^{2}}{8\pi^{2}}\ln\left( \frac{\Lambda}{m} \right) + \text{const} \end{align*}\] <p>where $A_ {4}’$ is the constant part of $H_ {4}$.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="#domainWall"/><category term="kink"/><summary type="html"><![CDATA[Spontaneous Symmetry Breaking]]></summary></entry><entry><title type="html">Example of Mathematica Package Quantum</title><link href="https://baiyangzhang.github.io/blog/2024/Example-of-Mathematica-Package-Quantum/" rel="alternate" type="text/html" title="Example of Mathematica Package Quantum"/><published>2024-08-04T00:00:00+00:00</published><updated>2024-08-04T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Example-of-Mathematica-Package-Quantum</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Example-of-Mathematica-Package-Quantum/"><![CDATA[<p>I have put together a short example of using Mathematica’s Quantum package to solve the harmonic oscillator problem <a href="https://github.com/BaiyangZhang/BaiyangZhang.github.io/blob/master/assets/Mathematica/ExampleHarmonicOscillator.nb">here</a>, hopefully I can apply this package to my current project on the quantum corrections of kink mass.</p>]]></content><author><name>Baiyang Zhang</name></author><summary type="html"><![CDATA[I have put together a short example of using Mathematica’s Quantum package to solve the harmonic oscillator problem here, hopefully I can apply this package to my current project on the quantum corrections of kink mass.]]></summary></entry><entry><title type="html">Note on The Moral Foundations of Politics</title><link href="https://baiyangzhang.github.io/blog/2024/Note-on-The-Moral-Foundations-of-Politics/" rel="alternate" type="text/html" title="Note on The Moral Foundations of Politics"/><published>2024-07-30T00:00:00+00:00</published><updated>2024-07-30T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Note-on-The-Moral-Foundations-of-Politics</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Note-on-The-Moral-Foundations-of-Politics/"><![CDATA[<h1 id="enlightenment-politics">Enlightenment Politics</h1> <blockquote> <p>f there is a single overarching idea shared in common by adherents to different strands of Enlightenment thinking, it is faith in the power of human reason to understand the true nature of our circumstances and ourselves. Human improvement is measured by the yardstick of <strong>individual rights</strong> that embody, and protect, <strong>human freedom</strong>.</p> </blockquote> <blockquote> <p>Descartes announced that he was in search of propositions that are impossible to doubt. His famous example, known as the <code class="language-plaintext highlighter-rouge">cogito</code>, was ‘‘I think, therefore I am.’’</p> </blockquote> <blockquote> <p>Immanuel Kant defined in <code class="language-plaintext highlighter-rouge">The Critique of Pure Reason</code> (1781), of placing knowledge ‘‘on the secure path of a science.’’</p> </blockquote> <blockquote> <p>These developments in philosophy reflected and reinforced the emergence of modern scientific consciousness.</p> </blockquote> <p>Such ideas, as necessary conditions for the development of natural science (not merely technology), seems to never had appeared in China. Year 1781 is the year 乾隆四十六年 in China, one of the most closed, ignorant, and autocratic era in history.</p> <blockquote> <p>During the seventeenth and eighteenth centuries, when the hallmark of scientific knowledge was indubitable certainty, ethics, political philosophy, and the human sciences were regarded as superior to the natural sciences. This view seems strange from the vantage point of the twenty-first century, when fields like physics, chemistry, astronomy, geology, and biology have all advanced with astonishing speed to discoveries that would have been unimaginable in the eighteenth century.</p> </blockquote> <h2 id="the-workmanship-ideal-of-knowledge">The Workmanship Ideal of Knowledge</h2> <blockquote> <p>The first distinctive feature of the early Enlightenment concerns the range of <code class="language-plaintext highlighter-rouge">a priori knowledge</code>, the kind of knowledge that either follows from definitions or is otherwise deduced from covering principals. This is the kind of knowledge Descartes had in mind when he formulated his cogito and that Kant located in the realm of ‘‘analytic judgments.’</p> </blockquote> <p><strong>Epistemology</strong> is a branch of philosophy that studies the nature, origin, and limits of human knowledge. The term comes from the Greek words “episteme,” meaning knowledge or understanding, and “logos,” meaning study or discourse. Epistemology addresses questions such as:</p> <ul> <li>What is knowledge?</li> <li>How is knowledge acquired?</li> <li>What do people know?</li> <li>How do we know what we know?</li> <li>What are the limits of human knowledge?</li> <li>What makes beliefs justified or rational?</li> </ul> <p>In exploring these questions, epistemology deals with the definition of knowledge and its scope and limits. It often involves debating between different theories of knowledge, such as empiricism (the idea that knowledge comes primarily from sensory experience), rationalism (the idea that reason is the main source of knowledge), and constructivism (the idea that knowledge is constructed by individuals through their interactions with the world).</p> <p>Immanuel Kant distinguished between two types of judgments: <code class="language-plaintext highlighter-rouge">analytic</code> and <code class="language-plaintext highlighter-rouge">synthetic</code>. These distinctions are central to his philosophy, especially in his work “Critique of Pure Reason.”</p> <ol> <li> <p><strong>Analytic Judgments</strong>: An analytic judgment is one where the predicate (the part of the sentence that says something about the subject) is contained within the subject itself. The truth of an analytic judgment is derived from the meanings of the words involved and logical reasoning. They are tautological in nature and do not add any new information about the world. For example, the statement “All bachelors are unmarried” is analytic because the predicate “unmarried” is part of the definition of the subject “bachelor.”</p> </li> <li> <p><strong>Synthetic Judgments</strong>: A synthetic judgment, on the other hand, is one where the predicate adds something to the subject that is not contained within it. The truth of a synthetic judgment is determined through how our concepts relate to the world and cannot be known just by understanding the meanings of the words. They require empirical investigation or intuition. For instance, “The cat is on the mat” is a synthetic judgment because the concept of “the cat” does not inherently include the concept of “being on the mat.”</p> </li> </ol> <p>Kant’s distinction between analytic and synthetic judgments is fundamental to his epistemology, particularly in addressing the question of how human beings can have knowledge about the world. He further introduced the concept of “synthetic a priori” judgments, which are synthetic judgments that are known independently of experience (a priori), like mathematical truths.</p> <hr/> <p>The <code class="language-plaintext highlighter-rouge">creationist</code> or <code class="language-plaintext highlighter-rouge">workmanship</code> theory in political science, often associated with the work of John Locke, is a theory of political obligation. It suggests that political authority and legitimacy derive from the consent of the governed, likening the role of the government or ruler to that of a craftsman or creator who constructs a system with the consent and for the benefit of the people.</p> <p>This theory is rooted in the idea that political and social structures are artificial constructs, made by human beings, unlike natural phenomena. The “creationist” aspect implies that political structures are deliberately created or constructed, rather than organically evolved. The “workmanship” aspect emphasizes the idea that the creators or rulers of these structures have a responsibility to the people they govern, similar to how a craftsman is responsible for the quality and function of their creation.</p> <p>Locke’s theory was revolutionary at its time because it challenged the prevailing notion of the divine right of kings, suggesting instead that political authority is justified only when it serves the interests of the governed and respects their rights. This theory laid the groundwork for modern concepts of democracy, individual rights, and the social contract.</p> <hr/> <p>Thomas Hobbes and John Locke, two prominent philosophers, had distinct views on natural law, reflecting their differing perspectives on human nature and the ideal structure of society.</p> <p>Hobbes, in his work “Leviathan,” presented a rather pessimistic view of human nature. He believed that in the state of nature (a hypothetical condition without government or laws), humans are driven by self-interest and a desire for self-preservation, leading to a “war of all against all” (bellum omnium contra omnes). In this state, life would be “solitary, poor, nasty, brutish, and short.”</p> <p>For Hobbes, natural law is a set of precepts or general rules, <em>discovered by reason</em>, which prohibit anything destructive to one’s own life. <em>It’s based on the right of every individual to preserve their own life</em>, leading to the conclusion that humans should seek peace. This is where his famous concept of the social contract comes into play: individuals surrender some of their freedoms and submit to the authority of a ruler (or a ruling assembly) to ensure their own safety and peace. Thus, Hobbes’s natural law is fundamentally about self-preservation and the avoidance of harm to others as a means of securing one’s own safety.</p> <p>Locke’s view, as articulated in “Two Treatises of Government,” is more optimistic about human nature. He believed that in the state of nature, humans live in a state of equality and freedom, not inherently prone to violence or war. For Locke, the <em>law of nature is a moral guide based on the belief that God has given the world to all people in common</em>. It teaches that, since all are equal and independent, no one ought to harm another in their life, health, liberty, or possessions.</p> <p>Locke’s natural law is grounded in the rights to life, liberty, and property. It includes the idea that people have the obligation to respect the rights of others. His social contract theory suggests that people form governments to protect these natural rights. If a government fails to do so, citizens have the right to overthrow it. This view laid the groundwork for modern democracy and significantly influenced the development of political philosophy in the Western world.</p> <p>So, Hobbes saw natural law as a means of avoiding the brutal state of nature through self-preservation and peace, whereas Locke viewed natural law as a moral guide ensuring equality and the inherent rights of life, liberty, and property.</p> <hr/> <blockquote> <p>A basic issue for Locke and many of his contemporaries was the ontological status of natural law and in particular its relation to God’s will.</p> </blockquote> <p>In this sentence, “ontological status” refers to the fundamental nature or essence of natural law, especially in relation to its existence and its relationship to God’s will. Ontology, in philosophy, is the study of being or existence, and it deals with questions concerning what entities exist or can be said to exist, and how such entities can be grouped, related within a hierarchy, and subdivided according to similarities and differences.</p> <p>So, when discussing the “ontological status of natural law” in the context of John Locke and his contemporaries, the focus is on understanding the very essence of natural law: whether it exists as an objective reality independent of human beings, how it relates to or derives from God’s will, and what its fundamental characteristics are. This was a central topic in the philosophical and theological debates of that era, particularly in the context of determining the basis and legitimacy of moral and legal principles. Locke and many others were engaged in trying to understand whether natural laws were inherent aspects of the universe, ordained by God, or whether they were constructs of human reason and society.</p> <p>“Will-centered” refers to the philosophical position known as voluntarism. This is a theory that emphasizes the role of the will, either divine or human, in various philosophical contexts. In the context of Locke’s moral and political writings, being “will-centered” or a voluntarist means that Locke ultimately leaned towards the view that natural law and moral principles are determined by the will, particularly the will of God, rather than being inherent or objective truths that exist independently of any will.</p> <p>In Locke’s time, the debate about the nature of natural law often centered around whether natural laws were intrinsic to the universe (a position known as intellectualism or rationalism) or whether they were decrees of God’s will (voluntarism). A will-centered or voluntarist approach suggests that moral and legal norms derive their authority from an act of will, particularly the divine will, rather than from reason alone or from the inherent nature of reality. In this view, what is right or wrong, just or unjust, is so because God wills it to be that way, and human beings understand and follow these laws through revelation, religious teachings, or other means of discerning God’s will.</p> <blockquote> <p>Locke distinguished “ectype”’ from “archetype” ideas: ectypes are general ideas of substances, and archetypes are ideas constructed by man.</p> </blockquote> <p>John Locke’s distinction between “ectype” and “archetype” ideas is a crucial aspect of his epistemological theory, which he discusses in his work “An Essay Concerning Human Understanding.” This distinction is part of his broader inquiry into the nature of human knowledge and understanding.</p> <p>In Locke’s philosophy, archetypes are the original models or patterns from which copies are made. They are the fundamental, primary ideas that exist in the mind of God or, in a more secular interpretation, the perfect, abstract forms of things. When Locke refers to archetypes as ideas constructed by man, he means that these are the ideal standards or criteria we hold in our minds for categorizing and understanding the world. They represent our understanding of what the essential characteristics of a particular thing are.</p> <p>For instance, the archetype of a tree would be the idealized concept or mental representation of what a tree is supposed to be. This archetype is not derived from any particular tree but is a kind of composite or abstracted idea of “treeness” that we use to recognize and categorize individual trees.</p> <p>Ectypes, on the other hand, are derivative or secondary ideas. They are the imperfect copies or generalizations that we derive from our experience with individual instances in the world. Ectype ideas are more about the general ideas of substances we form based on our sensory experiences and observations. When we see many individual trees, for example, we form a general idea of what a tree is - this is an ectype. It’s a more practical, experiential idea based on the aggregation of real-world instances.</p> <p>In summary, Locke’s distinction between archetype and ectype ideas can be understood as a differentiation between the idealized, abstract concepts we hold in our minds as standards (archetypes) and the more practical, general ideas we form based on our sensory experience of the world (ectypes). Archetypes are about the essence or ideal form of things, while ectypes are about the general, often imperfect, concepts we derive from actual experiences.</p> <h2 id="the-preoccupation-with-certainty">The Preoccupation with Certainty</h2> <blockquote> <p>The post-Humean Enlightenment tradition has been marked by a fallibilist view of knowledge. All knowledge claims are fallible on this account, and science advances not by making knowledge more certain but by producing more knowledge. Recognizing the corrigibility of all knowledge claims and the possibility that one might always be wrong exemplifies the modern scientific attitude. As Karl Popper (1902-1994) noted, the most that we can say, when hypotheses survive empirical tests, is that they have not been falsified so that we can accept them provisionally.</p> </blockquote> <p><code class="language-plaintext highlighter-rouge">Value judgments</code> are statements or opinions that express an evaluation, typically of something’s worth, beauty, goodness, or morality. Examples include statements like “Lying is wrong,” or “This painting is beautiful.” A.J. Ayer was a key figure in the logical positivist movement, which held that for a statement to be meaningful, it must be either empirically verifiable (i.e., testable by observation or experiment) or analytically true (true by definition, like mathematical or logical statements). In logical positivism, a <code class="language-plaintext highlighter-rouge">proposition</code> is a statement that can be either true or false. It’s a claim about the world that can, <em>at least in principle</em>, be tested and verified or falsified.</p> <p>The Logical Positivist movement, also known as Logical Empiricism, was a philosophical movement that emerged in the early 20th century. It primarily revolved around a group of philosophers associated with the Vienna Circle (<code class="language-plaintext highlighter-rouge">Moritz Schlick</code>, <code class="language-plaintext highlighter-rouge">Hans Hahn</code>, ), along with others like A.J. Ayer in Britain. This movement sought to apply the rigor of scientific methodology to philosophy, with a significant focus on the analysis of language and the verification of statements.</p> <p>Key Features of Logical Positivism include</p> <ol> <li> <p><strong>Verification Principle</strong>: The central tenet of Logical Positivism is the verification principle. This principle asserts that a statement is only meaningful if it can be empirically verified or is analytically true (true by virtue of its meaning, like “All bachelors are unmarried”). The idea was to eliminate metaphysical and abstract discussions that couldn’t be supported by empirical evidence or logical reasoning.</p> </li> <li> <p><strong>Empiricism and Science</strong>: Logical Positivists emphasized the importance of empirical evidence and scientific methods in acquiring knowledge. They viewed science as the model for all true knowledge.</p> </li> <li> <p><strong>Rejection of Metaphysics</strong>: They were critical of metaphysics and other traditional philosophical endeavors, which they saw as meaningless since such statements couldn’t be empirically verified. They believed that many philosophical problems arose from misunderstandings of language and could be resolved by clarifying the language used.</p> </li> <li> <p><strong>Language and Meaning</strong>: A significant focus was placed on the analysis of language, particularly the language of science. They aimed to clarify how language is used in scientific theories and to distinguish between meaningful and meaningless statements.</p> </li> <li> <p><strong>Influence of Wittgenstein</strong>: Although not officially part of the Vienna Circle, Ludwig Wittgenstein’s early work, especially his “Tractatus Logico-Philosophicus,” significantly influenced Logical Positivism. Wittgenstein argued that <em>much of philosophy consists of nonsensical propositions and that the role of philosophy should be to clarify thought and language</em>.</p> </li> <li> <p><strong>Ethical and Aesthetic Statements</strong>: Logical Positivists generally considered ethical and aesthetic statements to be expressions of emotions or subjective preferences, rather than statements that could be true or false.</p> </li> </ol> <p>The “positivism” component is linked to the movement’s commitment to a scientific and empirical approach to knowledge. Positivism, as a philosophical stance, argues that knowledge should be based on positive, observable facts and their logical and mathematical treatment. It rejects introspection and intuition as sources of knowledge and instead emphasizes empirical evidence obtained through observation and experimentation. Logical Positivists extended this approach by asserting that statements must be empirically verifiable (or analytically true) to be meaningful.</p> <hr/> <p>Somewhat to my surprise, Karl Popper is not a member of the Vienna circle even though they shared many intellectual engagements. Furthermore, Karl Popper is even critically oppositional. The Vienna Circle advocated for the verification principle, which held that a statement is meaningful only if it can be empirically <em>verified</em>. Popper challenged this view, proposing <em>falsificationism</em> instead. According to Popper, scientific theories cannot be conclusively verified but can be falsified. He argued that a theory is scientific if it is testable and can potentially be refuted by evidence. This approach places a greater emphasis on the role of empirical refutation rather than verification.</p> <p>Also, Popper was critical of what he called <code class="language-plaintext highlighter-rouge">historicism</code> – the belief that <em>history unfolds according to deterministic laws or principles</em>. He argued that such theories, which <em>were often used to justify authoritarian regimes</em>, are fundamentally flawed. He believed that historicism led to totalitarianism because it promoted the idea that certain individuals or groups had access to inevitable truths about societal development, thus justifying their absolute rule. Popper advocated for what he termed an <code class="language-plaintext highlighter-rouge">open society</code>. An open society, in his view, is characterized by a democratic government, individual freedoms, and a critical attitude towards tradition and authority. It allows for change and improvement through rational and critical discourse, as opposed to the unquestioning acceptance of dogmatic principles.</p> <p>Just as Popper applied the <em>principle of falsifiability</em> to scientific theories, he suggested that political policies should also be subjected to critical scrutiny and should be alterable in the face of new evidence or arguments. He was wary of any political theory or system that claimed to have absolute or final answers.</p> <hr/> <p>According to Ayer, the expression of a value judgment is not a proposition since it can not be judged by right and wrong, the question of truth or falsehood does not here arise.</p> <p>Regarding ethics, Ayer points out that many theorists in ethics tend to treat statements about the causes and characteristics of our ethical feelings as if these statements were definitions of ethical concepts. For example, a theory might claim that an action is good if it promotes happiness. Here, the cause of the ethical feeling (happiness) is used to define the ethical concept (good). Ayer argues that ethical concepts are <em>pseudo-concepts</em>, since ethical concepts, in his view, is neither empirically verifiable or analytically correct.</p> <p>Ayer’s stance is closely associated with <code class="language-plaintext highlighter-rouge">emotivism</code>, a meta-ethical view that suggests <em>ethical statements do not assert propositions but express emotional attitudes</em>. According to emotivism, saying “Stealing is wrong” is akin to expressing one’s disapproval of stealing, rather than making an objective claim about the nature of stealing.</p> <h2 id="the-centrality-of-individual-rights">The Centrality of Individual Rights</h2> <blockquote> <p>In addition to faith in science, the Enlightenment’s central focus on individual rights differentiates its political philosophy from the ancient and medieval commitments to order and hierarchy. This focus brings the freedom of the individual to the center of arguments about politics. This move was signaled in the natural law tradition by a shift in emphasis from the logic of law to the idea of natural right.</p> </blockquote> <p>Hobbes contended that it was customary to conflate “Jus and Lex, law and right”. Yet he made the distinction that right, consisted in liberty to do, or to forbeare, whereas law, determines and binds to one of them. Similarly by Locke.</p> <p>John Locke’s oppinion on natural law is as the following. In his work <em>Essays on the Law of Nature</em>, Locke argues a moral law inherent in the world and discoverable through reason.</p> <p>Key points of Locke’s argument include:</p> <ol> <li> <p><strong>Natural Law and Reason:</strong> Locke posits that natural law is an aspect of the natural world, similar to physical laws. According to him, this <em>moral law can be discovered through the use of reason, without the need for divine revelation</em>.</p> </li> <li> <p><strong>Moral Obligations:</strong> He argues that <em>natural law imposes moral obligations on individuals</em>. These moral principles are universal and apply to all people, regardless of their culture or society.</p> </li> <li> <p><strong>Rights and Duties:</strong> Locke’s view of natural law is closely tied to his ideas about individual rights and duties. He believes that natural law forms the basis for understanding human rights, especially the right to life, liberty, and property.</p> </li> <li> <p><strong>Foundation for Political Theory:</strong> These essays lay the groundwork for Locke’s later political theories, particularly those presented in his famous works, “Two Treatises of Government.” He uses the concept of natural law to argue for the rights of individuals and the limitations of governmental power.</p> </li> <li> <p><strong>Human Equality:</strong> Locke emphasizes the inherent equality of all human beings, derived from their natural state. This idea is a critical aspect of his argument against absolute monarchy and for the formation of governments based on the consent of the governed.</p> </li> <li> <p><strong>Religious Tolerance:</strong> Although not as explicitly developed in these essays as in his later works, Locke’s concept of natural law also leads to his advocacy for religious tolerance, seeing religious belief as a matter of individual conscience.</p> </li> </ol> <p>In summary, Locke’s “Essays on the Law of Nature” propose that there is a moral law inherent in the natural world, understandable through human reason, and that this law underpins human rights and forms the basis for just and ethical governance.</p> <hr/> <p>John Locke’s <code class="language-plaintext highlighter-rouge">voluntarist theology</code> reflects his views on the nature of God and the relationship between divine will and moral law. The emphasis is on <em>the will will (voluntas in Latin, hence the name) of God of God as the primary or sole source of moral law</em>. Locke’s voluntarism posits that <em>moral laws are decrees of God’s will</em>. In this view, what is morally right or wrong is so because God wills it, and not necessarily because it aligns with any intrinsic moral truths or rational principles independent of God’s will. Locke emphasizes the <em>absolute freedom</em> and <em>omnipotence</em> of God. He argues that God’s will is not bound by any external standards or principles. Therefore, moral laws are a product of God’s free choice.</p> <p>While Locke is a proponent of reason and believes that human beings can discover moral truths through rational inquiry, he also upholds the importance of divine revelation. In his voluntarist theology, revelation plays a crucial role in imparting knowledge of God’s will, which might not be entirely accessible through reason alone. Locke’s voluntarism is tied to his rejection of innate ideas, a concept he famously critiques in his “Essay Concerning Human Understanding.” He argues against the notion that <em>moral principles are innately known</em>, instead positing that our understanding of moral laws comes from experience, reason, and revelation. Locke’s voluntarist approach suggests that moral obligations are ultimately grounded in obedience to God’s will. This perspective can lead to a form of ethical subjectivism, where moral truths depend on the decrees of a divine authority.</p> <hr/> <blockquote> <p>In Locke’s formulation, natural law dictates that man is subject to divine imperatives to live in certain ways, but, within the limits set by the law of nature, men can act in a godlike fashion. Man as maker has a maker’s knowledge of his intentional actions, and a natural right to dominion over man’s products. … Provided we do not violate natural law, we stand in the same relation to the objects we create as God stands to us; we own them just as he owns us.</p> </blockquote> <h2 id="tensions-between-science-and-individual-rights">Tensions Between Science and Individual Rights</h2> <p>The two enlightenment values, the preoccupation of science and the commitment to individual rights, seem to be in contradiction with each other. Science is deterministic, concerned with discovering the laws that govern the universe, with human being included. This has potential for conflict with an ethic that emphasizes individual freedom, for now the freedom has to be subjugated to the laws (of nature, of God).</p> <p>In Locke’s theory, the freedom to comprehend natural law by one’s own lights supplied the basis of Locke’s right to resist, which could be invoked against the sovereign. No one is in a higher position to monopolize the right to interpret the scripture.</p> <blockquote> <p>We will see this tension surface repeatedly in the utilitarian, Marxist, and social contract traditions, without ever being fully resolved.</p> </blockquote> <h1 id="classical-utilitarianism">Classical Utilitarianism</h1> <p>Jeremy Bentham famously wrote that</p> <blockquote> <p>Nature has placed mankind under the governance of two sovereign masters, <em>pain</em> and <em>pleasure</em>. It is for them alone to point out what we ought to do, as well as to determine what we shall do. On the one hand the standard of right and wrong, on the other the chain of causes and effects, are fastened to their throne. They govern us in all we do, in all we say, in all we think: every effort we can make to throw off our subjection, will serve but to demonstrate and confirm it. In words a man may pretend to abjure their empire: but in reality he will remain subject to it all the while. The principle of utility recognizes this subjection, and assumes it for the foundation of that system, the object of which is to rear the fabric of felicity by the hands of reason and law. Systems which attempt to question it, deal in sounds instead of senses, in caprice instead of reason, in darkness instead of light.</p> </blockquote> <p>Some regimes indeed deals “in sounds instead of senses, in caprice instead of reason,” yet as long as they get only one thing right, as long as they supress the alternative, their reign will continue.</p> <p>The <code class="language-plaintext highlighter-rouge">principle of utility</code>, as Bentham explains, “approves or disapproves of every action whatsoever, according to the tendency which it appears to have to augment or diminish the happiness of the party whose interest is in question: or, what is the same thing in other words, to promote or to oppose that happiness.”</p> <blockquote> <blockquote> <p>A century later Marx and Engels would write of a uto pian order in which politics could be replaced by administration.≥ Bentham believed that it could be done in eighteenth-century England.</p> </blockquote> </blockquote> <p>Funny enoguh, Marx thought very little of Jeremy Benthem.Marx wrote, in <em>Das Capita</em>, that Bentham was a “panegyrist of bourgeois society,” and “With the driest naiveté he (Bentham) takes the modern shopkeeper, especially the English shopkeeper, as the normal man. Whatever is useful to this queer normal man, and to his world, is absolutely useful. This yard-measure, then, he applies to past, present, and future. The Christian religion, for example, is ‘useful,’ ‘because it forbids in the name of religion the same faults which the penal code condemns in the name of the law.’ Artistic criticism is ‘harmful,’ because it disturbs worthy people in their enjoyment of Martin Tupper, etc.”</p> <p>Bentham’s happiness principal, when applied to governments, requires us to maximize the greatest happiness of the greatest number in the community.</p> <p>Bentham defended an extensive system of political rights, but he saw rights as human artifacts, created by the legal system and enforced by the sovereign. He insisted that there are no rights without enforcement and no enforcement without government, a blunt statement of the view that would subsequently become known as legal positivism.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="politics"/><summary type="html"><![CDATA[Enlightenment Politics]]></summary></entry><entry><title type="html">Hausdorff Measure of Fractals</title><link href="https://baiyangzhang.github.io/blog/2024/Hausdorff-Dimension-of-Fractals/" rel="alternate" type="text/html" title="Hausdorff Measure of Fractals"/><published>2024-07-24T00:00:00+00:00</published><updated>2024-07-24T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Hausdorff-Dimension-of-Fractals</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Hausdorff-Dimension-of-Fractals/"><![CDATA[<h1 id="background">Background</h1> <p>I am writing a paper with Zhi-Peng on the <a href="## [Diophantine](https://en.wikipedia.org/wiki/Diophantine_approximation)">Diophatine approximation</a>,here is a short introduction on fractal as prerequisites.</p> <p>A fractal, such as the <a href="https://brilliant.org/wiki/cantor-set/">middle third Cantor set</a>, usually have the following properties:</p> <ol> <li>Self-similarity; sometimes the self similarity is not strict, it is quasi-self-similar in that arbitrarily small portions of the set can be magnified and then distorted smoothly to coincide with a large part of the set, take the <a href="https://en.wikipedia.org/wiki/Julia_set">Julia set</a> for example. Or it could be ever weaker, as the statistical self-similarity for random von Koch curve.</li> <li>Has a “fine structure”. It contains details at arbitrarily small scales.</li> <li>Its fractal dimension being different from its <code class="language-plaintext highlighter-rouge">topological dimension</code> (The topological dimension of a set is always an integer and is 0 if it is totally disconnected, 1 if each point has arbitrarily small neighborhoods with boundary of dimension 0, and so on).</li> <li>The geometry of the fractal can not be described simply by the zero locus of some defining condition.</li> <li>The size of a fractal is usually not quantified by the usual measure, such as length, area.</li> </ol> <p>In the theory of phase transition we have two notions quite similar to it:</p> <ol> <li>the system is scale-invariant at the critical point;</li> <li>there exists non-integer critical exponents at the critical point.</li> </ol> <p>It seems fractal does not have a mathematically rigor definition. Kenneth Falconer mentioned in his textbook that,</p> <blockquote> <p>My personal feeling is that the definition of a ‘fractal’ should be regarded in the same way as a biologist regards the definition of ‘life’. There is no hard and fast definition, but just a list of properties characteristic of a living thing, such as the ability to reproduce or to move or to exist to some extent independently of the environment. Most living things have most of the characteristics on the list, though there are living objects that are exceptions to each of them.</p> </blockquote> <p>So it’s best to learn fractal by studying some examples. Two examples of fractals are:</p> <p><code class="language-plaintext highlighter-rouge">Koch's curve</code>, obtained from a segment of a straight line, by repeating a pattern that gives the line an angle, see the figure below. It is self-similar by construction, the length goes to infinity by a power law as $n\to \infty$.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/KochCcurve-480.webp 480w,/img/KochCcurve-800.webp 800w,/img/KochCcurve-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/KochCcurve.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The von Koch curve. </div> <p>Another example is the coastal line of England, whose length $L(\epsilon)$ depends on the length $\epsilon$ of the yardstick. The coastal length is assumed to have the power law form,</p> \[L(\epsilon)\sim ~L_ {0}\epsilon^{-\alpha}.\] <p>The power-law behavior reminds us with the critical exponents near the critical point in statistical field theory, for example the magnetization of a ferromagnet near the critical temperature.</p> <p>We will talk more about dimension of a fractal, how to define and calculate it, in the future of the note. Now I only mention that the fractal dimension $d_ {\text{frac}}$ of the coastal line is defined to be</p> \[\alpha=d_ {\text{frac}}-d_ {\text{top}}\] <p>where $d_ {\text{top}}$ is the topological dimension of the coastal line which is $1$. If the measured length does not dependent on the length of the yardstick $\epsilon$, then $\alpha=0$ and $d_ {\text{frac}}=d_ {\text{top}}$. In our case we have roughly (by actual measurement)</p> \[d_ {\text{frac}}\sim 1.25.\] <hr/> <p>How should we think of the dimension of a fractal? Consider some regular geometric object, such as a familiar two dimensional square $\square$. If we double the side length of it, its area is multiplied by $2^{d}$ where $d$ is the dimension. In general, if the size of an object is multiplied by a factor $\lambda$, its area, or length, or whatever quantity that measures the “content” of the object, should be multiplied by a factor $\lambda^{d}$, where $d$ can be regarded as (one of the many) definitions of dimension. The number obtained in this way is usually referred to as the <code class="language-plaintext highlighter-rouge">similarity dimension</code> of the set.</p> <p>Let’s try to apply this definition to Koch’s curve. It is self-similar, if we shrink it by a factor of $3$, then it reduces to one of its four “components”. This component should have length that is one quarter of the original one. In other words, if we multiply Koch’s curve by factor $\lambda=\frac{1}{3}$, then the length should be multiplied by $\frac{1}{4}$, the before-mentioned definition of dimension should give</p> \[\text{new length}=\text{new size}^{d}\implies \frac{1}{4}=\left( \frac{1}{3} \right)^{d}\implies d\sim 1.26.\] <p>However, similarity dimension can not be applied to fractals which lack strict self similarity. There are other definitions of dimension that are much more widely applicable, such the famous Hausdorff dimension (which will be the central idea of the note), or box-counting dimension. Very roughly, a dimension provides a description of how much space a set fills. It is a measure of the prominence of the irregularities of a set when viewed at very small scales.</p> <hr/> <p>There exists various different definitions of dimension of a fractal, and applied on the same set they give different results. However, when applied on a perfectly self-similar fractal, such as the Koch’s curve, they should all give the same result.</p> <p>The fractal dimension is used to quantify this roughness and complexity. The higher the dimension, the higher the roughness, the higher the complexity. The fractional dimension <em>not only suggests that the fractal is curved</em>, it tells something drastically different, take the coastal line for example, it tells us the behavior of the total coastal length as the yardstick we use to measure it goes to zero.</p> <p>The earliest known measure of roughness of an object is the Hausdorff dimension (also known as Hausdorff-Besicovitch dimension) introduced by Felix Hausdorff in 1918, even before fractal geometry was a thing.</p> <h2 id="case-study-brownian-motion">Case study: Brownian motion</h2> <p>It seems that, in Brownian motion, the momentum change of a molecule at a collision depends only upon the last collision. It is a Gaussian stochastic process.</p> <p>Consider a lattice in $D$ dimension, with space and time discretization $\Delta x$ and $\Delta t$. Supposed the molecule of study can only hop from one site to the neighbor site, with direction chosen at random. One can then ask for the probability</p> \[P(x_ {1},t_ {1};x_ {0},t_ {0}) = \text{molecure move from }(x_ {0},t_ {0}) \text{ to } (x_ {1},t_ {1}).\] <p>The probability should satisfy three conditions,</p> <ol> <li>If $t_ {0}=t_ {1}$ then the particle does not move, $P=\delta(x_ {0},x_ {1})$.</li> <li>The total probability is normalized to one.</li> <li>At successive times, it can arrive only from neighbor sites.</li> </ol> <p>The last conditions gives us the dynamics of the particle, it tells how the particle must move. Using the discretized Laplace operator, we can turn the last condition into an equation. Then we can go to the continuum limit by setting $\Delta t\to 0$ and $\Delta x\to 0$. This limit is well defined under the condition that $\Delta t \propto (\Delta x)^{2}$.</p> <p>It shouldn’t surprise us that at the continuum limit, the probability distribution adopt a Gaussian form.</p> <p>The probability satisfies the so-called <code class="language-plaintext highlighter-rouge">Kolmogorov equation</code>,</p> \[\int d^{d}x_ {1} \, P(x_ {2},t_ {2};x_ {1},t_ {1})P(x_ {1},t_ {1};x_ {0},t_ {0})=P(x_ {2},t_ {2};x_ {0},t_ {0}).\] <p><strong>This will give us a path-integral interpretation of the probability.</strong></p> <h1 id="hausdorff-measure">Hausdorff Measure</h1> <p>For a more detailed introduction on measure theory please refer to my two previous notes, <a href="https://www.mathlimbo.net/blog/2022/Basic-Measure-Theory-Part-I/">Basic Measure Theory Part I</a> and <a href="https://www.mathlimbo.net/blog/2022/Basic-Measure-Theory-Part-II/">Part II</a>. Here we assume the basic knowledge of measure theory.</p> <p>To build up some intuition, let’s return to the example of Cantor sets. If we measure it using dimension one, then it has total length zero. The set is too “small” to be measured with dimension one. However, if we measure it using dimension zero, that is just count how many points it contains, then the dimension becomes infinity. The set is too “large” to be measured with dimension zero. The question is, is there a dimension between zero and one, that we can somehow “use” to measure the size of Cantor set, which gives us neither zero nor infinity? Or, if this requirement is too strong, we can weaken it by asking if there is a number, below which the measurement gives infinity, above which the measurement gives zero, this critical point perhaps can be regarded as the dimension? Turns out, we can find such a number! That is what Hausdorff measure gives us, as we will dive into details.</p> <p>The idea behind the Hausdorff dimension is to measure how a set scales as you cover it with balls of decreasing radius. In more technical terms, it quantifies how the number of these small balls (or other shapes) needed to cover the set scales as the size of the balls decreases. So first, we need to define how to <strong>cover a set</strong> in rigorous mathematical language.</p> <p>Recall that if $U$ is a subset of $\mathbb{R}^{n}$ (or any other metric space), then the <code class="language-plaintext highlighter-rouge">diameter</code> of $U$, denoted $\left\lvert U \right\rvert$, is defined to be the greatest distance between any two points in it, that is</p> \[\left\lvert U \right\rvert := \text{sup }\left\lbrace \left\lvert x-y \right\rvert : x,y\in U \right\rbrace .\] <p>If $\left\lbrace U_ {i} \right\rbrace$ is a countable (or finite) collection of sets of diameter at most $\delta$, that is $\left\lvert U_ {i} \right\rvert\leq \delta$. If $\left\lbrace U_ {i} \right\rbrace$ covers $F$, i.e.</p> \[F \subset \bigcup_ {i} U_ {i} ,\] <p>Then $\left\lbrace U_ {i} \right\rbrace$ is said to be a $\delta$-cover of $F$.</p> <p>Let $F$ be the subset of $\mathbb{R}^{n}$, we introduce a non-negative number $s$ which will play the role of dimension in the future. For any diameter $\delta&gt;0$ we define</p> \[\mathcal{H}^{s}_ {\delta}(F) := \text{inf } \left\lbrace \sum\left\lvert U_ {i} \right\rvert ^{s} \,\middle\vert\, \left\lbrace U_ {i} \right\rbrace \text{ is a } \delta \text{-cover of } F \right\rbrace .\] <p>Thus we look at all the $\delta$-cover of $F$ and seek to minimize the sum of the $s$th powers of the diameters. This sum goes to a limit as $\delta$ goes to zero, we define</p> \[\mathcal{H}^{s}(F) := \lim_ { \delta \to 0 } \mathcal{H}_ {\delta}^{s}(F).\] <p>The limit always exists for any set $F$, but it need not be any finite number, it can (and usually is) $0$ or $\infty$. We call $\mathcal{H}^{s}(F)$ the $s$<code class="language-plaintext highlighter-rouge">-dimensional Hausdorff measure of</code> $F$</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/fractal/deltaCover-480.webp 480w,/img/fractal/deltaCover-800.webp 800w,/img/fractal/deltaCover-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/fractal/deltaCover.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The plot is copied from Falconer's textbook. It shows two different $\delta$-cover of $F$. </div> <p>To show that $\mathcal{H}^{s}$ is indeed a measure, we must show that it satisfies all the properties a measure must have, for example $\mathcal{H}^{s}(\emptyset)$ is zero, the measure of a subset is always no larger than the original set, etc. We will not provide a proof here.</p> <hr/> <p>Hausdorff measure is a generalization of more familiar measures, such as length, area and volume. Specifically, it can be shown that for a Borel subset $F$ of $\mathbb{R}^{n}$, $\mathcal{H}^{s}(F)$ is equal to its Lebesgue measure, namely $n$-volume up to a multiplicative constant,</p> \[\mathcal{H}^{n}(F) = c_ {n}^{-1} \text{vol}^{n(F)},\] <p>where $c_ {n}$ is the volume of an $n$-dimensional ball if diameter $1$.</p> <p>Similarly, for a nice lower dimensional subset of $\mathbb{R}^{n}$, we have that $\mathcal{H}^{0}$ is the number of points in $F$, $\mathcal{H}^{1}$ is the length of a smooth curve $F$, $\mathcal{H}^{2}$ is $\frac{1}{\pi}$ times the area of $F$, etc.</p> <hr/> <p>We know that one of the defining concept of dimension is revealed under scaling of a subset. On magnification by a scale $\lambda$, the length of a curve is multiplied by $\lambda$, the area of a surface is multiplied by $\lambda^{2}$, the volume of an object is multiplied by $\lambda^{3}$. If Hausdorff measure is truly a generalization of length, area and volume, then $s$-Hausdorff measure should be multiplied by $\lambda^{s}$. It turns out to be true.</p> <p><strong>Scaling Property.</strong> Let $S$ be a similarity transformation of scale factor $\lambda&gt;0$. If $F\subset \mathbb{R}^{n}$, then</p> \[\boxed{ \mathcal{H}^{s}(S(F)) = \lambda^{s}\mathcal{H}^{s}(F). }\] <p>Proof. The similarity transformation $S$ also transfers a $\delta$-cover of $F$ to a $\lambda \delta$-cover of $S(F)$, for everything is scaled by a factor of $\lambda$. By definition of Hausdorff measure we have, after the scaling,</p> \[\mathcal{H}^{s}_ {\lambda \cdot\delta}(SF) = \text{inf}\left\lbrace \sum \left\lvert A_ {i} \right\rvert^{s} \mid A_ {i} \text{ is a }\lambda \delta \text{ cover of }SF \right\rbrace\] <p>and I claim that each element $A_ {i}$ of $\lambda \delta$-covers of $SF$ is obtained by $\lambda U_ {i}$ for a unique $U_ {i}$ which is a $\delta$-cover of $F$. Roughly speaking, it is because 1) each $\delta$-cover of $F$ gives a $\lambda\delta$-cover of $SF$, it means that $S$ is an injection; 2) since $\lambda \neq 0$, there always exists an inverse scaling map $S^{-1}$ which scales $SF$ back to $F$, i.e. scaling by $\lambda ^{-1}$, $S^{-1}$ is also an injection just like $S$, since they are essentially the same kind of operation; 3) since $S$ and $S^{-1}$ are both injections, <strong>$S$ is a bijection</strong>. And their measures, $\mathcal{H}^{s}_ {\lambda \delta}(A_ {i})$ and $\mathcal{H}^{s}_ {\delta}(U_ {i})$ where $A_ {i}=SU_ {i}$ differs only by a multiplicative constant, which turns out to be $\lambda^{s}$, as we will see later. It means that $S$ preserves the order, if $U\leq U’$ then $\sum\left\lvert SU \right\rvert^{s}\leq \sum\left\lvert SU’ \right\rvert^{s}$. Thus all the $A_ {i}$s and all the $U_ {i}$s (and their Hausdorff measures) are 1-2-1 correspondent, with the ordering preserved. Then we have</p> \[\begin{align*} \mathcal{H}^{s}_ {\lambda \cdot\delta}(SF) &amp;= \text{inf }\left\lbrace \sum \left\lvert A_ {i} \right\rvert^{s} \right\rbrace = \text{inf }\left\lbrace \sum \left\lvert SU_ {i} \right\rvert^{s} \right\rbrace \\ &amp;= \text{inf }\left\lbrace \lambda^{s} \sum \left\lvert U_ {i} \right\rvert^{s} \right\rbrace = \lambda^{s}\mathcal{H}^{s}_ {\delta}(F), \end{align*}\] <p>where $\left\lbrace U_ {i} \right\rbrace$ is a $\delta$-cover of $F$ thus $\left\lbrace SU_ {i} \right\rbrace$ is a $\lambda\delta$-cover of $S(F)$. On taking the limit $\delta\to 0$ we have</p> \[\mathcal{H}^{s}(SF) = \lambda^{s}\mathcal{H}^{s}(F).\] <p>Q.E.D.</p> <p>Note that the proof here is slightly different than what Falconer gave in his textbook. There to prove $\text{inf}\left\lbrace A \right\rbrace=\text{inf}\left\lbrace B \right\rbrace$ he essentially proves that 1) $\text{inf}\left\lbrace A \right\rbrace\leq \text{inf}\left\lbrace B \right\rbrace$ and 2) $\text{inf}\left\lbrace A \right\rbrace\geq \text{inf}\left\lbrace B \right\rbrace$, then it follows $\text{inf}\left\lbrace A \right\rbrace=\text{inf}\left\lbrace B \right\rbrace$. Our proof is a little big different, it says that 1) $S:A\to B$ is a injection and 2) $S^{-1} B\to A$ is also an injection, so $S$ is a bijection. Furthermore, $S$ preserves the ordering, so $\text{inf}\left\lbrace A \right\rbrace=\text{inf}\left\lbrace B \right\rbrace$.</p> <hr/> <p>A similar argument gives the following result. Let $F\subset\mathbb{R}^{n}$ and $f: F\to \mathbb{R}^{m}$ be a map such that</p> \[\left\lvert f(x)-f(y) \right\rvert \leq c\left\lvert x-y \right\rvert ^{\alpha}, \quad c,\alpha&gt;0.\] <p>Which is called the <code class="language-plaintext highlighter-rouge">Holder condition of exponent</code> $\alpha$. Then for each $s$</p> \[\mathcal{H}^{s/\alpha} (f(F)) \leq c^{s/\alpha} \mathcal{H}^{s}(F).\] <p>Particularly important is the case $\alpha=1$, when the map is called <code class="language-plaintext highlighter-rouge">Lipschitz</code>. This case can be used to prove that $\mathcal{H}^{s}$ is translational and rotational invariant, we will not go to the details though.</p> <h1 id="hausdorff-dimension">Hausdorff Dimension</h1> <p>The notion of dimension is central to fractal geometry. Roughly speaking, dimension indicates how much space a set occupies <strong>near to each of its points</strong>. The keyword here is <em>near</em>, dimension, when interpreted in this way, is a local notion, not global. The global size a set occupies might has nothing to do with dimension, for example, given two different line segments, one is longer than the other hence occupies more space, but they are both dimension one, and length is the global size. On the other hand, if you pick a point and look at what happens in its small neighbor, then these two lines appears the same. That is to say, the local size of these to lines are the same, reflecting the fact that they are of the same dimension.</p> <p>Of the wide variety of “fractal dimensions” in use, the Hausdorff dimension is the oldest and probably the most important. It has the advantage of being defined for any set, not just strictly self-similar ones. It is also mathematically convenient, as it is based on measures, which are relatively easy to manipulate. However, a major disadvantage is that it can be sometimes hard to calculate <strong>by numerical methods</strong>.</p> <p>The graph of Hausdorff measure $\mathcal{H}^{s}$ vs $s$ is shown below. Below the critical value it is infinity, above the critical value it is zero, at the critical point it jumps from $\infty$ to $0$. We define this critical value as the <code class="language-plaintext highlighter-rouge">Hausdorff dimension</code>, denoted $\text{dim}_ {H}$. It is also called Hausdorff-Besicovitch dimension. The Hausdorff dimension of a set $F$ is denoted $\text{dim}_ {H}F$. We state without proof that, Hausdorff dimension exists for any subset of $\mathbb{R}^{n}$.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/fractal/Hs-480.webp 480w,/img/fractal/Hs-800.webp 800w,/img/fractal/Hs-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/fractal/Hs.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The graph of $\mathcal{H}^{s}(F)$ vs $s$. Below the critical value it is infinity, above the critical value it is zero, at the critical point it jumps from $\infty$ to $0$. This critical value is defined to be the Hausdorff dimension of $F$. </div> <p>Formally,</p> \[\mathcal{H}^{s}F = \begin{cases} \infty &amp; 0\leq s &lt; \text{dim}_ {H}F, \\ 0 &amp; s &gt; \text{dim}_ {H}F. \end{cases}\] <p>If $s=\text{dim}_ {H}F$, then $\mathcal{H}^{s}F$ may be zero, $\infty$ or some finite number in between. In the last case, a Borel set satisfying this condition is called an $s$-set. Mathematically they are convenient to study and occurs surprisingly often.</p> <p>Hausdorff dimension satisfies the following (rather well expected) properties.</p> <ul> <li>Monotonicity. If $E\subset F$ then $\text{dim}_ {H}E\leq \text{dim}_ {H}F$.</li> <li>Countable stability. If $F_ {1},F_ {2},\cdots$ is a sequence of countable sets, then the Hausdorff dimension of $\cup_ {i}F_ {i}$ is the supremum of $\left\lbrace \text{dim}_ {H}F_ {i} \right\rbrace$.</li> </ul> <p>If follows from countable stability that if $F$ is a countable set then it has Hausdorff dimension zero.</p> <p>If $F\subset\mathbb{R}^{n}$ is an open set, then $\text{dim}_ {H}F=n$, since $F$ can be covered by countable open balls, each has dimension $n$.</p> <p>The Hausdorff dimension is preserved by bi-Lipschitz maps $f$, which are maps satisfy</p> \[c_ {1}\left\lvert x-y \right\rvert \leq \left\lvert f(x)-f(y) \right\rvert \leq c_ {2}\left\lvert x-y \right\rvert ,\] <p>where</p> \[0 &lt; c_ {1} \leq c_ {2} &lt; \infty.\] <p>As for the importance of bi-Lipschitz maps, I quote Falconer here:</p> <blockquote> <p>In topology two sets are regarded as ‘the same’ if there is a homeomorphism between them. One approach to fractal geometry is to regard two sets as ‘the same’ if there is a bi-Lipschitz mapping between them. Just as topological invariants are used to distinguish between non-homeomorphic sets, we may seek parameters, including dimension, to distinguish between sets that are not bi-Lipschitz equivalent. Since bi-Lipschitz transformations are necessarily homeomorphisms, topological parameters provide a start in this direction, and Hausdorff dimension (and other definitions of dimension) provide further distinguishing characteristics between fractals.</p> </blockquote> <hr/> <p>Next let’s used the famous mid-third Cantor set as an examples to illustrate how to calculate the Hausdorff dimension.</p> <p>Recall that the mid-third Cantor set $F$ (Cantor set for short) is divided into the left part and right part, each similar to the whole. Denote them as $F_ {L}$ and $F_ {R}$ respectively. It is shown in the figure below.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&lt;</span><span class="n">div</span> <span class="n">class</span><span class="o">=</span><span class="sh">"</span><span class="s">row mt-3</span><span class="sh">"</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="n">div</span> <span class="n">class</span><span class="o">=</span><span class="sh">"</span><span class="s">col-sm mt-3 mt-md-0</span><span class="sh">"</span><span class="o">&gt;</span>
        

<span class="o">&lt;</span><span class="n">figure</span>
  
<span class="o">&gt;</span>
  <span class="o">&lt;</span><span class="n">picture</span><span class="o">&gt;</span>
    <span class="o">&lt;</span><span class="err">!</span><span class="o">--</span> <span class="n">Auto</span> <span class="n">scaling</span> <span class="k">with</span> <span class="n">imagemagick</span> <span class="o">--&gt;</span>
    <span class="o">&lt;</span><span class="err">!</span><span class="o">--</span>
      <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="p">.</span><span class="n">debugbear</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">blog</span><span class="o">/</span><span class="n">responsive</span><span class="o">-</span><span class="n">images</span><span class="c1">#w-descriptors-and-the-sizes-attribute and
</span>      <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">developer</span><span class="p">.</span><span class="n">mozilla</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">en</span><span class="o">-</span><span class="n">US</span><span class="o">/</span><span class="n">docs</span><span class="o">/</span><span class="n">Learn</span><span class="o">/</span><span class="n">HTML</span><span class="o">/</span><span class="n">Multimedia_and_embedding</span><span class="o">/</span><span class="n">Responsive_images</span> <span class="k">for</span> <span class="n">info</span> <span class="n">on</span> <span class="n">defining</span> <span class="sh">'</span><span class="s">sizes</span><span class="sh">'</span> <span class="k">for</span> <span class="n">responsive</span> <span class="n">images</span>
    <span class="o">--&gt;</span>
    
      <span class="o">&lt;</span><span class="n">source</span>
        <span class="n">class</span><span class="o">=</span><span class="sh">"</span><span class="s">responsive-img-srcset</span><span class="sh">"</span>
        <span class="n">srcset</span><span class="o">=</span><span class="sh">"</span><span class="s">/img/fractal/CantorSet-480.webp 480w,/img/fractal/CantorSet-800.webp 800w,/img/fractal/CantorSet-1400.webp 1400w,</span><span class="sh">"</span>
        
          <span class="n">sizes</span><span class="o">=</span><span class="sh">"</span><span class="s">95vw</span><span class="sh">"</span>
        
        <span class="nb">type</span><span class="o">=</span><span class="sh">"</span><span class="s">image/webp</span><span class="sh">"</span>
      <span class="o">&gt;</span>
    
    <span class="o">&lt;</span><span class="n">img</span>
      <span class="n">src</span><span class="o">=</span><span class="sh">"</span><span class="s">/img/fractal/CantorSet.png</span><span class="sh">"</span>
      
        <span class="n">class</span><span class="o">=</span><span class="sh">"</span><span class="s">img-fluid rounded z-depth-1</span><span class="sh">"</span>
      
      
        <span class="n">width</span><span class="o">=</span><span class="sh">"</span><span class="s">100%</span><span class="sh">"</span>
      
      
        <span class="n">height</span><span class="o">=</span><span class="sh">"</span><span class="s">auto</span><span class="sh">"</span>
      
      
      
      
      
      
      <span class="n">onerror</span><span class="o">=</span><span class="sh">"</span><span class="s">this.onerror=null; $(</span><span class="sh">'</span><span class="s">.responsive-img-srcset</span><span class="sh">'</span><span class="s">).remove();</span><span class="sh">"</span>
    <span class="o">&gt;</span>
  <span class="o">&lt;/</span><span class="n">picture</span><span class="o">&gt;</span>

  
<span class="o">&lt;/</span><span class="n">figure</span><span class="o">&gt;</span>

    <span class="o">&lt;/</span><span class="n">div</span><span class="o">&gt;</span>
<span class="o">&lt;/</span><span class="n">div</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">div</span> <span class="n">class</span><span class="o">=</span><span class="sh">"</span><span class="s">caption</span><span class="sh">"</span><span class="o">&gt;</span>
    <span class="n">Construction</span> <span class="n">of</span> <span class="n">the</span> <span class="n">middle</span><span class="o">-</span><span class="n">third</span> <span class="n">Cantor</span> <span class="nb">set</span> <span class="err">$</span><span class="n">F</span><span class="err">$</span><span class="p">,</span> <span class="n">by</span> <span class="n">repeated</span> <span class="n">removal</span> <span class="n">of</span> <span class="n">the</span> <span class="n">middle</span> <span class="n">third</span> <span class="n">of</span> <span class="n">intervals</span><span class="p">.</span> <span class="err">$</span><span class="n">E_k</span><span class="err">$</span> <span class="ow">is</span> <span class="n">what</span> <span class="n">we</span> <span class="n">got</span> <span class="n">after</span> <span class="err">$</span><span class="n">k</span><span class="err">$</span><span class="n">th</span> <span class="n">removal</span><span class="p">.</span>
<span class="o">&lt;/</span><span class="n">div</span><span class="o">&gt;</span>

</code></pre></div></div> <p>Apparently we have $\mathcal{H}^{s}(F_ {L}) = \mathcal{H}^{s}(F_ {R})$. We can find the relation between $\mathcal{H}^{s}(F)$ (the whole) and $\mathcal{H}^{s}(F_ {R})$ (the part) by noticing that, if $\left\lbrace U_ {i} \right\rbrace$ is a $\delta$-cover of $F$, then $\frac{1}{3}\left\lbrace U_ {i} \right\rbrace$ is a $\delta/3$-cover of $F_ {L}$, this gives us</p> \[\mathcal{H}^{s}_ {\delta/3}(F_ {L}) = \text{inf }\left\lbrace \sum_ {i}\left\lvert \frac{U_ {i}}{3} \right\rvert^{s} \right\rbrace = \frac{1}{3^{s}}\text{inf }\left\lbrace \sum_ {i}\left\lvert U_ {i} \right\rvert^{s} \right\rbrace = \frac{1}{3^{s}}\mathcal{H}^{s}_ {\delta}(F).\] <p>Taking the limit $\delta\to0$ we have</p> \[\mathcal{H}^{s}(F_ {L}) = \frac{1}{3^{s}}\mathcal{H}^{s}(F).\] <p>Also we have $F = F_ {L} \cup F_ {R}$, thus</p> \[\mathcal{H}^{s} (F) = \mathcal{H}^{s}(F_ {L}) + \mathcal{H}^{s}(F_ {R}) = \frac{2}{3^{s}} \mathcal{H}^{s}(F).\] <p>The equation $\mathcal{H}^{s} (F) = \frac{2}{3^{s}} \mathcal{H}^{s}(F)$ has three solutions,</p> <ul> <li>$\mathcal{H}^{s}(F)=0$,</li> <li>$\mathcal{H}^{s}(F)=\infty$</li> <li>$0&lt;\mathcal{H}^{s}(F)&lt;\infty$ and $s=\log_ {3}2$.</li> </ul> <p>This agrees with the picture given before, suggesting that the Hausdorff measure is infinity when the dimension is below $\log_ {3}2$, and zero above, so $\log_ {3}2$ is a critical point, hence the Hausdorff dimension of the Cantor set. However, the story is not over yet, in the last case we have assumed that $\mathcal{H}^{s}(F)$ at $s=\log_ {3}2$ is a finite quantity, which needs justification.</p> <p>Recall from Fig. that $E_ {k}$ is what we got after cutting it for $k$-times. $E_ {k}$ consists of $2^{k}$ intervals each of length $3^{-k}$, thus we can regard it as the $3^{-k}$-cover of $F$. It gives as</p> \[\mathcal{H}^{s}_ {3^{-k}}(F) \leq \sum_ {i=1}^{2^{k}}\left\lvert 3^{-k} \right\rvert ^{s} = 2^{k} 3^{-ks}.\] <p>At $s=\log_ {3}2$, in the $k\to \infty$ limit we have</p> \[\mathcal{H}^{s}(F) \leq 1.\] <p>It is slighter harder to find an infimum of $\mathcal{H}^{s}$, so we will neglect it here. With even more effort one can show that $\mathcal{H}^{s}F=1$.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="fractal"/><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">Quantum Domain Wall in 4D Part I</title><link href="https://baiyangzhang.github.io/blog/2024/Constructing-a-Finite-Tension-Domain-Wall-in-4D-Part-I/" rel="alternate" type="text/html" title="Quantum Domain Wall in 4D Part I"/><published>2024-07-15T00:00:00+00:00</published><updated>2024-07-15T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Constructing-a-Finite-Tension-Domain-Wall-in-4D-Part-I</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Constructing-a-Finite-Tension-Domain-Wall-in-4D-Part-I/"><![CDATA[<h1 id="table-of-contents">Table of Contents</h1> <ul> <li><a href="#1-coherent-state-and-solitonic-state">1. Coherent state and solitonic state</a></li> <li><a href="#2-conventions">2. Conventions</a></li> <li><a href="#3-normal-ordering-with-mass-m">3. Normal ordering with mass m</a></li> <li><a href="#4-triviality-of-phi-fourth-theory">4. Triviality of phi-fourth theory</a></li> <li><a href="#5-perturbative-expansion-of-the-hamiltonian">5. Perturbative Expansion of the Hamiltonian</a></li> <li><a href="#6-passive-transformation-by-d_-f">6. Passive Transformation by $D_ {f}$</a></li> </ul> <h1 id="1-coherent-state-and-solitonic-state">1. Coherent state and solitonic state</h1> <p>In quantum field theory (QFT), a <strong>coherent state</strong> is a specific type of quantum state that exhibits classical-like behavior. These states are widely used to describe states that most closely resemble classical waves. To understand it, it’s best to start with quantum mechanics.</p> <p>In quantum mechanics, coherent states are eigenstates of the annihilation operator $\hat{a}$. For a harmonic oscillator, a coherent state $\left\lvert{\alpha}\right\rangle$ satisfies: \(\hat{a} \left\lvert{\alpha}\right\rangle = \alpha \left\lvert{\alpha}\right\rangle\)</p> <p>where $\alpha$ is a complex number. Coherent states minimize the Heisenberg uncertainty principle, making them the quantum states most similar to classical oscillations. They exhibit minimal quantum fluctuations, contrary to pathologically defined states such as the eigen state of $\hat{x}$, which maximizes the fluctuation in the momentum space. Also, coherent states form an over-complete basis for the Hilbert space.</p> <p>In quantum field theory (QFT), coherent states are often defined with respect to <code class="language-plaintext highlighter-rouge">smeared annihilation operators</code>. This approach takes into account the fact that field operators are distributions that need to be smeared with test functions to make physical sense. To be specific, the field operators $\hat{\phi}(x)$ and their conjugate momenta $\hat{\pi}(x)$ are functions of spacetime coordinates and are typically distributions. To handle these distributions properly, one introduces smeared field operators:</p> \[\hat{\phi}(f) = \int d^dx \, f(x) \hat{\phi}(x)\] <p>where $f(x)$ is a smooth test function that <strong>smears</strong> the field operator over spacetime. Similarly, the annihilation operator can be smeared with a test function $g(x)$:</p> \[\hat{a}(g) = \int d^dx \, g(x) \hat{a}(x) := \int \frac{d^{d}p}{(2\pi)^{d}} \, \tilde{g}(p) a_ {p},\] <p>where $\widetilde{g}(p)$ is the Fourier transform of $g(x)$, and $\hat{a}(x)$ defined by the last integral in momentum space. The eigen equation reads</p> \[\hat{a}(g) \left\lvert{\alpha}\right\rangle = \alpha(g) \left\lvert{\alpha}\right\rangle\] <p>where $\alpha(g)=(\alpha(\vec{x}),g(\vec{x}))$ is the inner product of these two functions.</p> <p>Consider a free scalar field $\hat{\phi}(x)$ in 4D. The field can be expanded in terms of creation and annihilation operators:</p> \[\hat{\phi}(x) = \int \frac{d^3k}{(2\pi)^{3/2}} \frac{1}{\sqrt{2\omega_ k}} \left( \hat{a}_ k e^{-ik \cdot x} + \hat{a}_ k^\dagger e^{ik \cdot x} \right)\] <p>where $\hat{a}_ k$ and $\hat{a}_ k^\dagger$ are the annihilation and creation operators for mode $k$.</p> <p>A coherent state $\left\lvert{\alpha}\right\rangle$ for this field is an eigenstate of the smeared annihilation operator:</p> \[\hat{a}(g) \left\lvert{\alpha}\right\rangle = \alpha(g) \left\lvert{\alpha}\right\rangle\] <p>where the smeared annihilation operator is given by:</p> \[\hat{a}(g) = \int \frac{d^3k}{(2\pi)^{3/2}} \frac{1}{\sqrt{2\omega_ k}} \tilde{g}(k) \hat{a}_ k\] <p>and $\tilde{g}(k)$ is the Fourier transform of the test function $g(x)$.</p> <p>In some theories, especially those involving non-linear sigma models and certain gauge theories, solitons can be seen as coherent states of the underlying field theory. This correspondence helps in understanding the non-perturbative aspects of the field theory.</p> <hr/> <p>At the end of section 4.3 in Coleman’s note on classical and quantum lumps, he said and I quote</p> <blockquote> <p>I do not believe there are any plausible variational computations using coherent states or simple generalizations of them in more than one spatial dimension. It would be nice to have reasonable variational states in this case. A good place to begin exploring would be a super-renormalizable theory in two spatial dimensions. Here, although all divergences are not removed by normal ordering, it is still possible to sum them up in closed form. Thus we have at least a minimal criterion for a reasonable trial state: the expectation value of the Hamiltonian density should not be infinite. Coherent states do not meet this test.</p> </blockquote> <p>We will see if this is correct in 3+1 dimension.</p> <h1 id="2-conventions">2. Conventions</h1> <p>we are not interested in the interaction picture but in the Schrodinger picture. It is for a bunch of reasons, one of them is that it is easy to see what the normal-ordering prescription corresponds to in this picture. Schrodinger-picture operators are given as functions of the field $\phi(\vec{x})$ and the canonical momentum density $\pi(\vec{x})$, where $\vec{x}$ is the spatial coordinate, not the Lorentzian spacetime coordinate $x^{\mu}$. We begin with a phi-fourth theory in Schrodinger picture, normal ordered at mass scale $m_ {0}$:</p> \[\begin{align*} \hat{H}(\vec{x}) &amp;= \int d^{3}x: \hat{\mathcal{H}}^{0}(\vec{x}) :_ {m_ {0}} \\ \hat{\mathcal{H}}^{0}(\vec{x}) &amp;= \frac{1}{2}(\pi(\vec{x})^{2}+(\partial_ {i}\phi(\vec{x})^{2}) + \frac{1}{4}(\lambda_ {0}\phi^{4}(\vec{x})-m_ {0}^{2}\phi^{2}(\vec{x}))+A. \end{align*}\] <p>The hat denotes that the vacuum of the Hamiltonian is not obtained at $\phi=0$ yet. To be more specific, the Hamiltonian undergoes spontaneous symmetry breaking, as a result the minimum of the Hamiltonian is obtained at $\phi=v_ {0}$ for some $v_ {0}$. Later we will shift the field operator from $\phi$ to $\phi’$, such that the vacuum is indeed obtained at $\phi’=0$, the Hamiltonian in terms of $\phi’$ will be denoted without the hat. Note the factor $-m_ {0}^{2} /4$ in the mass term, and the last $A$ is a c-number to cancel the zero point energy in the vacuum sector. We also define coupling $g_ {0}$ as</p> \[g_ {0}^{2} := \lambda_ {0}.\] <p>In the Schrodinger picture, the field operator and canonical momentum operator can be decomposed as</p> \[\begin{align*} \phi(\vec{x})&amp;= \int \frac{d^{3}p}{(2\pi)^{3}} \, e^{ -i\vec{p}\cdot \vec{x} } \left( A_ {p}^{\ddagger}+\frac{A_ {-p}}{2\omega_ {p}} \right), \\ \pi(\vec{x})&amp;= i \int \frac{d^{3}p}{(2\pi)^{3}} \, e^{ -i\vec{p}\cdot \vec{x} } \left( \omega_ {p} A_ {p}^{\ddagger}-\frac{A_ {-p}}{2} \right) . \end{align*}\] <p>and</p> \[\begin{align*} \omega_ {p}&amp;= \sqrt{ m^{2}+\vec{p}^{2} },\\ A_ {p}^{\ddagger} &amp;= \frac{A_ {p}^{\dagger}}{2\omega_ {p}}. \end{align*}\] <p>with commutation relation</p> \[[A_ {p_ {1} },A^{\ddagger}_ {p_ {2} }] = (2\pi)^{d}\delta^{d}(p_ {1}-p_ {2}).\] <p>In the decomposition, every thing is defined at mass scale $m$. In the paper the creation and annihilation operators are sometime written as $A_ {\vec{p}}^{(0)}$, with an extra naught, it has to do with the definition of normal ordering we choose. If we are normal ordering at some bare mass $m_ {0}$, then we put the superscript $(0)$ to remind us of that. We will go to details later.</p> <hr/> <p>It would be helpful to mention the connection between our convention and that widely adopted in various textbooks. In Schrodinger picture it reads</p> \[\phi(\vec{x}) = \int \frac{d^{d}p}{(2\pi)^{d}} \, \frac{1}{\sqrt{2 \omega_ {p} }} (a_ {p} \, e^{ i\vec{p}\cdot \vec{x} } + a^{\dagger}_ {p}\,e^{ -i\vec{p}\cdot \vec{x} }).\] <p>The canonical commutation relation reads</p> \[[a_ {p},a^{\dagger}_ {k}] = (2\pi)^{d}\delta^{d}(\vec{p}-\vec{k}).\] <p>Comparing to our convention, we have</p> \[\boxed{ \begin{align*} A_ {p} &amp;\equiv \sqrt{ 2\omega_ {p} }\,a_ {p},\quad A^{\dagger}_ {p} \equiv \sqrt{ 2\omega_ {p} }\,a^{\dagger}_ {p}, \\ A^{\ddagger}_ {p} &amp;:= \frac{A^{\dagger}_ {p}}{2\omega_ {p}} = \frac{a^{\dagger}_ {p}}{\sqrt{ 2\omega_ {p} }}, \\ [A_ {p},A^{\ddagger}_ {k}] &amp;= (2\pi)^{d}\,\delta^{d}(\vec{p}-\vec{k}). \end{align*} }\] <hr/> <p>The renormalized quantities are define as</p> \[m^{2}=m_ {0}^{2} + \delta m^{2}, \quad \sqrt{ \lambda } = \sqrt{ \lambda_ {0} } + \delta \sqrt{ \lambda }.\] <p>or equivalently</p> \[g = g_ {0} + \delta g.\] <p>We also define $v$ to be the vev of field in some physical vacuum,</p> \[v = \frac{m}{\sqrt{ 2\lambda }} + \delta v.\] <p>Perturbative expansion:</p> \[\begin{align*} \delta m^{2}&amp; =\sum_ {i=1}^{\infty} \delta m^{2}_ {i} , \quad \delta m^{2}_ {i}\sim \mathcal{O}(g^{i+1}), \\ \delta g &amp;= \sum_ {i=1}^{\infty} \delta g_ {i}, \quad \delta g_ {i} \sim \mathcal{O}(g^{i+2}),\\ H &amp;= \sum_ {i=0}^{\infty} H_ {i},\quad H_ {i} \sim \mathcal{O}(g^{i-2}) , \\ A &amp;= \sum_ {i=0}^{\infty}A_ {i}, \quad A_ {i} \sim \mathcal{O}(g^{i-2}) , \\ \delta v &amp;= \sum_ {i=1}^{\infty} \delta v_ {i} ,\quad \delta v_ {i} \sim \mathcal{O}(g^{i}), \\ \left\lvert{\Psi}\right\rangle &amp;= \sum_ {i=0}^{\infty} \left\lvert{\Psi_ {i}}\right\rangle , \quad \left\lvert{\Psi}\right\rangle _ {i} \sim \mathcal{O}(g^{i}), \\ I &amp;\sim \mathcal{O}(g^{2}). \end{align*}\] <p>Where $I$ is some variable which will be define later, I put it here for the sake of completeness.</p> <h1 id="3-normal-ordering-with-mass-m">3. Normal ordering with mass m</h1> <p>This section is based on Sidney Coleman’s <a href="http://users.physik.fu-berlin.de/%7Ekamecke/ps/coleman.pdf">1975 paper</a> and his lecture note on the aspects of symmetry, the chapter about classical and quantum lumps. In the meanwhile I have adopted notations and convention according to previous chapter.</p> <p>In Coleman’s 1975 paper mentioned above, he studied the sine-Gordon model</p> \[\mathcal{L} = \frac{1}{2} (\partial_ {\mu}\phi)^{2} + \frac{\alpha_ {0}}{\beta^{2}}\cos \beta \phi+\gamma_ {0},\] <p>where things with a nought are bare (not renormalized), and famously pointed out:</p> <ol> <li>As for any theory of a <strong>scalar field</strong> with <strong>nonderivative interaction</strong> in <strong>2 dimensional spacetime</strong>, normal ordering the Hamiltonian alone is enough to cancel all the divergences at any loop order;</li> <li>If the $\beta$-parameter exceeds $8\pi$, the Hamiltonian density is not bounded below.</li> <li>If $\beta&lt;8\pi$, the model is equivalent to the charge-zero sector of almost-massive Thirring model.</li> <li>The fermion in the Thirring model is massless if $\beta=4\pi$.</li> </ol> <p>Turns out there are more details to normal ordering than I thought. In textbooks such that by Peskin&amp;Schroeder, or that by Mark Srednicki, normal ordering is regarded as a simple, even trivial, ad hoc procedure that puts all the creation operators to the left of all the annihilation operators, in order to eliminate the zero point energy of the trivial vacuum. But, as we dig deeper, more details begin to surface.</p> <hr/> <p>A crucial property of normal ordering is that expectation values of normal-ordered operators vanish in the free theory:</p> \[\left\langle{0}\right\rvert : \mathcal{O} :\left\lvert{0}\right\rangle =0\] <p>for any operator $\mathcal{O}$ and free vacuum $\left\lvert{0}\right\rangle$. There are various formulations of this notion <sup id="fnref:Polchinski" role="doc-noteref"><a href="#fn:Polchinski" class="footnote" rel="footnote">1</a></sup> , such as <code class="language-plaintext highlighter-rouge">creation-annihilation operator normal ordering</code>, <code class="language-plaintext highlighter-rouge">conformal normal ordering</code>, <code class="language-plaintext highlighter-rouge">functional integral normal ordering</code>, etc. In this note we will only talk about familiar creation-annihilation operator normal ordering.</p> <p>Something that is less mentioned is that, normal ordering involves a mass scale $m$. In most cases, it is rather obvious what $m$ we should choose, that is the mass of the free particle, let’s call it free mass. However, in order to tell what the free mass is, we need to what the Hamiltonian is, for example if we can unambiguously separate the Hamiltonian into $\mathcal{H}_ {0}+U(\phi)$, where $\mathcal{H}_ {0}=\pi^{2} / 2+(\partial_ {x}\phi)^{2} /2+m^{2}\phi^{2} /2$, then $m$ is the free mass. Sometimes the situation is not so straightforward, for sometimes it is more convenient to put $m^{2}\phi^{2} /2$ into the interaction part, such as in the case of sine-Gordon model, as a result the free Hamiltonian only contains the kinetic part, and the free particles appears to be massless. In general, given a quadratic term of form $a \phi^{2}$ where $a$ is some real parameter, we can choose how much of it is to be put into the free Hamiltonian part, and the rest goes to the interaction. For example, we can pick a number such as $m=0.511$ MeV and say that $m^{2}\phi^{2}/2$ goes to the free Hamiltonian, such that the free particle has mass $m$, as a result, $(a-\frac{m^{2}}{2})\phi^{2}$ will go to the interaction. This is just a matter of convenience, the observables should not depend on such arbitrary choices.</p> <p>So, how does all this relate to normal ordering? Normal ordering is a procedure that rearranges creation and annihilation operators. These operators inherently depend on the free mass of the particle. $a^{\dagger}_ {p}$ creates a particle of momentum $\vec{p}$ <strong>with mass $m$</strong>, the energy of the particle is $\sqrt{ \vec{p}^{2}+m^{2} }$. I repeat, <strong>the choice of $m$ depends on what you choose to call the free Hamiltonian, and that choice is somehow arbitrary.</strong> The result of changing $m$ can be absorbed in a redefinition of the theory parameters.</p> <p>My assumption is, the field operator $\phi(x)$ itself is independent of the aforementioned choice of mass parameter $m$, while the stuff that do depend on $m$ are</p> <ol> <li>creation and annihilation operators $a_ {p,m}$ and $a^{\dagger}_ {p,m}$,</li> <li>the energy $\omega=\sqrt{ \vec{p}^{2}+m^{2} }$, we will write it as $\omega_ {p,m}$ explicitly,</li> <li>states in Fock space. For example, the free vacuum $\left\lvert{0,m}\right\rangle$ is by definition annihilated by $a_ {p,m}$. Since the states in the Fock space are constructed by applying $a^{\dagger}_ {p,m}$ consecutively, a re-definition of $a^{\dagger}_ {p,m}$ to, say $a^{\dagger}_ {p,\mu}$ will also change the states themselves.</li> </ol> <p>Recall that the field operator can be expanded in terms of energy and ladder operators,</p> \[\phi(\vec{x}) = \int \frac{d^{d}k}{(2\pi)^{d}}\, \frac{1}{\sqrt{ 2\omega_ {k,m} }} (a_ {k,m} \, e^{ i\vec{k}\cdot \vec{x} } + a^{\dagger}_ {k,m}\,e^{ -i\vec{k}\cdot \vec{x} })\] <p>and the $m$-dependence in $\omega_ {k,m}$, $a_ {k,m}$ and $a^{\dagger}_ {k,m}$ should cancel out so that $\phi(\vec{x})$ itself is $m$-independent.</p> <hr/> <p>We can define the <strong>normal ordering at $m$</strong> by decomposing the Schrodinger picture fields and momenta into creation and annihilation part:</p> \[\begin{align*} \phi^{+}(\vec{x}) &amp;= \int \frac{d^{3}p}{(2\pi)^{3}} \, e^{ -i\vec{p}\cdot \vec{x} } A^{\ddagger}_ {p,m} \\ \phi^{-}(\vec{x}) &amp;= \int \frac{d^{3}p}{(2\pi)^{3}} \, e^{ i\vec{p}\cdot \vec{x} } \frac{A_ {p,m}}{2\omega_ {p,m}}, \end{align*}\] <p>similarly for the canonical momenta</p> \[\pi^{\pm }(\vec{x}) = \pm i\sqrt{ -\nabla^{2}+m^{2} }\phi^{\pm }(\vec{x}) ,\] <p>which implies</p> \[\begin{align*} \pi^{-}&amp;= - \frac{i}{2} \int \frac{d^{3}p}{(2\pi)^{3}} \, e^{ i\vec{p}\cdot \vec{x} } A_ {p,m} ,\\ \pi^{+} &amp;= i \int \frac{d^{3}p}{(2\pi)^{3}} \, e^{ -i\vec{p}\cdot \vec{x} } \omega_ {p,m}A^{\ddagger}_ {p,m} . \end{align*}\] <p>It is easy to verify that</p> \[\begin{align*} \phi(\vec{x}) &amp;= \phi^{+}(\vec{x}) + \phi^{-}(\vec{x}) , \\ \pi(\vec{x}) &amp;= \pi^{+}(\vec{x}) + \pi^{-}(\vec{x}) . \end{align*}\] <p>We can arrange a sting of field operators using the Wick’s theorem, which says that a string of product of field operators can be rewritten as the sum of all the possible contractions of operators, all of them normal ordered. For example,</p> \[\phi(\vec{x})\phi(\vec{x}) = :\phi(\vec{x})\phi(\vec{x}): + \text{ contraction}\left\lbrace \phi(\vec{x})\phi(\vec{x}) \right\rbrace .\] <p>The contraction is where different choice of $m$ generates different results. Let’s write the contraction at $m$ as $C_ {m}\left\lbrace \cdots \right\rbrace$, we have</p> \[\boxed{ \begin{align*} \phi^{2}(\vec{x}) &amp;= :\phi^{2}(\vec{x}):_ {m} + C_ {m}\left\lbrace \phi^{2}(\vec{x}) \right\rbrace , \\ C_ {m}\left\lbrace \phi^{2}(\vec{x}) \right\rbrace &amp;= [\phi^{-},\phi^{+}] = \int \frac{d^3p}{(2\pi)^{3}} \, \frac{1}{2\omega_ {p,m}}. \end{align*} }\] <p>Recall that $\phi^{2}$ is $m$-independent, while the normal ordering and the contraction are $m$-dependent. This gives us a means to connect normal ordering at different mass $m$ and $m_ {0}$, since</p> \[\phi^{2}(\vec{x}) = :\phi^{2}(\vec{x}):_ {m} + C_ {m}(\phi^{2}(\vec{x})) = :\phi^{2}(\vec{x}):_ {m_ {0}} + C_ {m_ {0}}(\phi^{2}(\vec{x})),\] <p>which implies that</p> \[\begin{align*} :\phi^{2}(\vec{x}):_ {m_ {0}} &amp;= :\phi^{2}(\vec{x}):_ {m} + C_ {m}-C_ {m_ {0}} \\ &amp;= :\phi^{2}(\vec{x}):_ {m} + \frac{1}{2} \int \frac{d^{3}p}{(2\pi)^{3}} \, \left( \frac{1}{\omega_ {p,m}} - \frac{1}{\omega_ {p,m_ {0}}} \right) . \end{align*}\] <p>where $C_ {m}$ is short for $C_ {m}(\phi^{2})$, a short-handed notation we will use extensively for the rest of the note. $C_ {m}$ is a c-number, usually given by a divergent integral.</p> <p>Similarly,</p> \[\boxed{ (\partial_ {i}\phi)^{2} = :(\partial_ {i}\phi)^{2} : + \int \frac{d^{3}p}{(2\pi)^{3}} \,\left( \frac{\vec{p}^{2}}{2\omega_ {p,m}} \right) }\] <p>and</p> \[\boxed{ \pi^{2}(\vec{x}) = :\pi^{2}(\vec{x}):_ {m} + \frac{1}{2}\int \frac{d^{3}p}{(2\pi)^{3}} \, \omega_ {p,m}. }\] <p>Let’s look at another example which is slightly more complicated, that is the normal ordering of four field operators $\phi^{4}(\vec{x})$,</p> \[\begin{align*} \phi^{4}(\vec{x}) &amp;= :\phi^{4}(\vec{x})+\text{all contractions}:_ {m} \\ &amp;= :\phi^{4}(\vec{x})+6C_ {m}\phi^{2}(\vec{x})+3C^{2}_ {m}:_ {m} \end{align*}\] <p>where the factor $6$ comes from $6$ distinct ways to contract two fields out of four, and the factor $3$ comes from 3 distinct ways to contract all the fields. Take $6C_ {m}\phi^{2}$ for example, it (including the combinatoric factors) can be conveniently written as</p> \[\frac{1}{2} C_ {m} \frac{d^{2}}{d\phi^{2}} \phi^{4} = 6 C_ {m} \phi^{2},\] <p>where the factor of $\frac{1}{2}$ is to cancel the double counting of any contraction. Similarly, for the full contraction, we can write it as</p> \[\frac{1}{2}\left( \frac{1}{2}C_ {m} \frac{d^{2}}{d\phi^{2}} \right)^{2} \phi^{4} = 3C_ {m}^{2}.\] <p>The symmetry factors need some explanation. Each $C_ {m}$ comes with a symmetry factor $1/2$, since $C_ {m}$ is the contraction of $\phi^{2}$, which is always double counted. There are two pairs of contraction out of four $\phi$’s, hence the extra symmetry factor $1/2$.</p> <p>If there were six $\phi$’s to contract, the total contraction of $\phi^{6}(\vec{x})$ comprises of three pairs of $C_ {m}$. We can calculate the total contraction using</p> \[\frac{1}{3!}\left( \frac{1}{2}C_ {m} \frac{d^{2}}{d\phi^{2}} \right)^{3} \phi^{6}(\vec{x}) = 15 C_ {m}^{3}.\] <p>The symmetry factor $1/n!$ reminds us of the Taylor expansion of exponents. We can assemble all the contractions together in a neat formula. In general, given any polynomial function $U(\phi)$ of $\phi$, we have</p> \[\boxed{ U(\phi) = :\exp \left\lbrace \frac{1}{2}C_ {m} \frac{d^{2}}{d\phi^{2}} \right\rbrace U(\phi):_ {m}. }\] <p>Note it is the double derivative $d^{2}/d\phi^{2}$, not single derivative $d/d(\phi^{2})$.</p> <hr/> <p>For a free theory of mass $m$, and for any source function $J(x)$, we have</p> \[\begin{align*} \exp \left\lbrace i \int \, J(x)\phi(x) d^{2}x \right\rbrace &amp;=\; :\exp \left\lbrace i \int d^{2}x \, J(x)\phi(x) \right\rbrace:_ {m} \\ &amp;\;\;\;\;\;\times \exp \left\lbrace -\frac{1}{2}\int d^{2}x d^{2}y J(x) \, \Delta(x-y)J(y) \right\rbrace \end{align*}\] <p>where $\Delta(x-y)$ is the Wightman function. If we go to interaction picture and adopt time ordering, the Wightman functions become Feynman propagators.</p> <hr/> <p>For the sake of completeness, we compare the normal ordering of $\phi^{2}(\vec{x})$, $\pi^{2}$, $(\partial_ {i}\phi)^{2}$ and $\phi^{4}$ at different mass, namely $m$ and $m_ {0}$. The result is given below.</p> \[\begin{align*} :\phi^{2}(\vec{x}):_ {m_ {0}} &amp;= :\phi^{2}(\vec{x}):_ {m} + I , \\ :\pi^{2}(\vec{x}):_ {m_ {0}} &amp;= :\pi^{2}(\vec{x}):_ {m} + \frac{1}{2}\int \frac{d^{3}p}{(2\pi)^{3}} \, (\omega_ {p,m}-\omega_ {p,m_ {0}}), \\ :( \vec{\nabla}\phi )\cdot(\vec{\nabla}\phi):_ {m_ {0}} &amp;= :( \vec{\nabla}\phi )\cdot(\vec{\nabla}\phi):_ {m} + \int \frac{d^{3}p}{(2\pi)^{3}} \, \frac{\vec{p}^{2}}{2} \left( \frac{1}{\omega_ {p,m}}-\frac{1}{\omega_ {p,m_ {0}}} \right) , \\ :\phi^{4}(\vec{x}):_ {m_ {0}} &amp;= :\phi^{4}(\vec{x}):_ {m} + 6 I :\phi^{2}:_ {m} +3I^{2}, \\ I &amp;= C_ {m}-C_ {m_ {0}} = \frac{1}{2} \int \frac{d^{3}p}{(2\pi)^{3}} \, \left( \frac{1}{\omega_ {p,m}}-\frac{1}{\omega_ {p,m_ {0}}} \right). \end{align*}\] <p>Recall that the <strong>defining expression</strong> for the Hamiltonian density reads</p> \[\begin{align*} \hat{H}(\vec{x}) &amp;= \int d^{3}x \, :\hat{\mathcal{H}}^{0}(\vec{x}):_ {m_ {0}} = \int d^{3}x \, :\hat{\mathcal{H}}:_ {m} , \\ \hat{\mathcal{H}}^{0}(\vec{x}) &amp;= \frac{1}{2}\pi^{2}(\vec{x})+\frac{1}{2} (\partial_ {i}\phi)^{2} - \frac{m_ {0}^{2}}{4} \phi^{2}(\vec{x}) + \frac{\lambda_ {0}}{4} \phi^{4}(\vec{x}) + A, \end{align*}\] <p>We want to normal order it to get rid of the infinite zero point energy. The thing is, there are two obvious options for the mass scale at which the normal ordering is done: the bare mass $m_ {0}$ and the “physical” mass $m$. At $m_ {0}$ we have</p> \[\begin{align*} \hat{\mathcal{H}}^{0}(\vec{x}) &amp;= :\hat{\mathcal{H}}^{0}(\vec{x}):_ {m_ {0}} + \frac{3}{2}\lambda_ {0} C_ {m_ {0}} :\phi^{2}(\vec{x}):_ {m_ {0}} + \frac{3}{4} \lambda_ {0} C_ {m_ {0}}^{2} - \frac{m_ {0}^{2}}{4}C_ {m_ {0}} \\ &amp;\;\;\;\; + \frac{1}{4} \int \frac{d^{3}p}{(2\pi)^{3}} \, \frac{2\vec{p}^{2}+m_ {0}^{2}}{\omega_ {p,m_ {0}}} . \end{align*}\] <p>We can also rewrite it into normal ordering at $m$:</p> \[\begin{align*} :\hat{\mathcal{H}}^{0}(\vec{x}):_ {m_ {0}} &amp;= :\hat{\mathcal{H}}^{0}(\vec{x}):_ {m} + \frac{3}{2}\lambda_ {0} I :\phi^{2}(\vec{x}):_ {m} + \frac{3}{4} \lambda_ {0} I^{2} - \frac{m_ {0}^{2}}{4}I \\ &amp;\;\;\;\; + \frac{1}{4} \int \frac{d^{3}p}{(2\pi)^{3}} \, \left( \frac{2\vec{p}^{2}+m^{2}}{\omega_ {p,m}} - \frac{2\vec{p}^{2}+m_ {0}^{2}}{\omega_ {p,m_ {0}}} \right) . \end{align*}\] <p>Since, by definition, $:\hat{\mathcal{H}}:_ {m}=:\hat{\mathcal{H}}^{0}:_ {m_ {0}}$, we have</p> \[\begin{align*} \hat{\mathcal{H}}(\vec{x})&amp;= \hat{\mathcal{H}}^{0}(\vec{x}) + \frac{3}{2}\lambda_ {0} I \phi^{2}(\vec{x}) + \frac{3}{4} \lambda_ {0} I^{2} - \frac{m_ {0}^{2}}{4}I \\ &amp;\;\;\;\; + \frac{1}{4} \int \frac{d^{3}p}{(2\pi)^{3}} \, \left( \frac{2\vec{p}^{2}+m^{2}}{\omega_ {p,m}} - \frac{2\vec{p}^{2}+m_ {0}^{2}}{\omega_ {p,m_ {0}}} \right) \end{align*}\] <h1 id="4-triviality-of-phi-fourth-theory">4. Triviality of phi-fourth theory</h1> <p>Renormalization is the process by which the parameters of a quantum field theory (like the mass and coupling constant) are adjusted to account for the effects of interactions at different energy scales. This involves introducing a cutoff $\Lambda$ to regulate divergences and then taking the limit $\Lambda \to \infty$.</p> <p>Triviality in this context means that, as you take the ultraviolet (UV) cutoff $\Lambda \to \infty$, the renormalized coupling constant $\lambda$ tends to zero, making the interacting theory effectively a free (non-interacting) theory. This happens despite having a non-zero bare coupling constant $\lambda_ 0$.</p> <p>When performing calculations in QFT, the bare field $\phi_ 0$ and the renormalized field $\phi$ are related by a wave function renormalization factor $Z$:</p> \[\phi_ 0 = Z^{1/2} \phi.\] <p>As $\Lambda \to \infty$, this factor $Z$ becomes large, effectively rescaling the field. Similarly, the bare coupling constant $\lambda_ 0$ and the renormalized coupling constant $\lambda$ are related by:</p> \[\lambda_ 0 = \frac{\lambda}{Z^2}.\] <p>As $\Lambda \to \infty$, if $Z \to \infty$ (which is the case for $\phi^4$ theory in 4D), the renormalized coupling $\lambda$ must go to zero to keep $\lambda_ 0$ fixed.</p> <p>In summary, saying that $\phi^4$ theory is “trivial” means that, after accounting for the effects of renormalization, the theory becomes non-interacting as the UV cutoff is taken to infinity. This implies that any interacting $\phi^4$ theory in four dimensions cannot remain interacting at all energy scales and instead becomes a free theory at very high energies. This phenomenon is an important aspect of understanding the limitations and behaviors of quantum field theories in different dimensions.</p> <h1 id="5-perturbative-expansion-of-the-hamiltonian">5. Perturbative Expansion of the Hamiltonian</h1> <p>Since we want to cancel divergences in a perturbative manner, that is, order-by-order in (renormalized) coupling $\lambda$. When $\Lambda$ is involved, we should count the order with respect to $\lambda$ first, treating terms such as $\lambda \Lambda,\,\lambda \Lambda^{2}, \cdots\lambda \Lambda^{n}$ all as $\mathcal{O}(\lambda)$, and group things of the same order together. Only then do we take the limit $\Lambda\to\infty$, and cancel the divergences.</p> <p>For the rest of this note, unless explicitly said otherwise, $\lambda$ stants for the <em>renormalized coupling</em> and $\lambda_ {0}$ the bare coupling.</p> <p>I copy the Hamiltonian here:</p> \[\begin{align*} \hat{H}(\vec{x}) &amp;= \int d^{3}x \, :\left\lbrace \hat{\mathcal{H}}^{0}(\vec{x}) + \frac{3}{2}\lambda_ {0} I \phi^{2}(\vec{x}) + \frac{3}{4} \lambda_ {0} I^{2} - \frac{1}{4}I\,m_ {0}^{2} \right\rbrace :_ {m} \\ &amp;\;\;\;\; + \int d^{3}x \,\frac{1}{4} \int \frac{d^{3}p}{(2\pi)^{3}} \, \left( \frac{2\vec{p}^{2}+m^{2}}{\omega_ {p,m}} - \frac{2\vec{p}^{2}+m_ {0}^{2}}{\omega_ {p,m_ {0}}} \right) . \end{align*}\] <p>p.s. <strong>Jarah’s version is written differently</strong>,</p> \[\begin{align*} \hat{H}(\vec{x}) &amp;=\int d^{3}x \, :\left\lbrace \hat{\mathcal{H}}^{0}(\vec{x}) + \frac{3}{2}\lambda_ {0} I \phi^{2}(\vec{x}) + \frac{3}{4} \lambda_ {0} I^{2} - \frac{3}{4}I\,m_ {0}^{2} \right\rbrace :_ {m} \\ &amp;\;\;\;\; + \int d^{3}x \,\frac{1}{4} \int \frac{d^{3}p}{(2\pi)^{3}} \, \frac{(\omega_ {p,m}-\omega_ {p,m_ {0}})^{2}}{\omega_ {p,m}} , \end{align*}\] <p>which is equivalent to our expression.</p> <p>A simple Taylor expansion shows that</p> \[\omega_ {p,m} = \omega_ {p,m_ {0}} + \frac{1}{2} \frac{\delta m^{2}}{\omega_ {p,m_ {0}}} + \mathcal{O}(\delta m^{4}),\] <p>thus</p> \[\omega_ {p,m} - \omega_ {p,m_ {0}} \sim \mathcal{O}(\lambda)\] <p>since $\delta m^{2}=(\cdots)\lambda+(\cdots)\lambda^{2}+\cdots$. Similarly,</p> \[\begin{align*} I &amp;= \frac{1}{2} \int \frac{d^{3}p}{(2\pi)^{3}} \, \left( \frac{1}{\omega_ {p,m}}-\frac{1}{\omega_ {p,m_ {0}}} \right) \\ &amp;= \frac{1}{2} \int \frac{d^{3}p}{(2\pi)^{3}} \, \left( - \frac{\delta m^{2}}{2 \omega^{3}_ {p,m_ {0}}} +\cdots \right)\\ &amp;= -\frac{\delta m^{2}}{4} \int \frac{d^{3}p}{(2\pi)^{3}} \, \frac{1}{\omega^{3}_ {p,m_ {0}} } + \cdots\\ &amp;\sim \mathcal{O}(\lambda) \end{align*}\] <p>The last term in the Hamiltonian density reads</p> \[\frac{1}{4} \int \frac{d^{3}p}{(2\pi)^{3}} \, \left( \frac{2\vec{p}^{2}+m^{2}}{\omega_ {p,m}} - \frac{2\vec{p}^{2}+m_ {0}^{2}}{\omega_ {p,m_ {0}}} \right) = \frac{m_ {0}^{2}\delta m^{2}}{8} \int \frac{d^{3}p}{(2\pi)^{3}} \, \frac{1}{\omega^{3}_ {p,m_ {0}}} +\cdots.\] <p>There is another constant term that is of order $\lambda$:</p> \[- \frac{1}{4}I\,m_ {0}^{2} = \frac{m_ {0}^{2}\,\delta m^{2}}{16}\int \frac{d^{3}p}{(2\pi)^{3}} \, \frac{1}{\omega^{3}_ {p,m_ {0}}} +\cdots.\] <p>This is too bad, since I had hoped that the above equation will cancel the above above equation. But we can rearrange the terms proportional to $m_ {0}^{2}$ such that the integrals cancel each other and leaves us only one single term: $-\frac{3}{4} Im_ {0}^{2}$.</p> <p>The term $\frac{3}{2}\lambda_ {0} I \phi^{2}(\vec{x})$ needs some extra work. It seems to be of order $\lambda_ {0}I\sim \mathcal{O}(\lambda^{2})$, however, often times we need to replace the field operator $\phi$ by $\left\langle \phi \right\rangle+\phi’$, where $\left\langle \phi \right\rangle$ is the expectation valued for $\phi$ under certain circumstances, and it is usually of order $\left\langle \phi \right\rangle\sim 1 / g$ where $g\equiv \sqrt{ \lambda }$. Thus this quadratic term is actually of order $\mathcal{O}(\lambda)$ and we need to keep it.</p> <p>Putting everything together. At the leading order of $\lambda$ we have</p> \[\begin{align*} \hat{H}(\vec{x}) &amp;= \int d^{3}x \, \left\lbrace :\hat{\mathcal{H}}^{0}(\vec{x}) + \frac{3}{2}\lambda_ {0} I \phi^{2}(\vec{x}) - \frac{3}{4} I m_ {0}^{2} :_ {m} \right\rbrace \end{align*}\] <p>Then we write the bare parameters in terms of renormalized ones (recall that $g:= \sqrt{ \lambda }$ for both bare and renormalized parameters), at order $\mathcal{O}(\lambda)$ we have</p> \[\begin{align*} \hat{H}(\vec{x}) &amp;\supset \int d^{3}x \, : \frac{1}{2}\pi^{2}+\frac{1}{2}(\partial_ {i}\phi)^{2} - \frac{m^{2}}{4}\phi^{2}+\frac{g^{2}}{4}\phi^{4}:_ {m} \\ &amp;\;\;\;\; + \int d^{3}x \, : \frac{\delta m^{2}}{4}\phi^{2}-\frac{1}{2}g \delta g\phi^{4}+\frac{3}{2}g^{2}I\phi^{2}-\frac{3}{4}m^{2}I +A :_ {m}. \end{align*}\] <p>We have neglected higher order terms, for example a term $3g\delta g\sim \mathcal{O}(g^{4}) \sim\mathcal{O}(\lambda^{2})$ was dropped from the expression.</p> <h1 id="6-passive-transformation-by-d_-f">6. Passive Transformation by $D_ {f}$</h1> <p>In order to find the approximate Hilbert state with correct vacuum expectation value of $\phi$, we introduce the displacement operator. Given a function $f(\vec{x})$, the associated displacement operator is defined as</p> \[\mathcal{D}_ {f} := \exp \left\lbrace -i\pi(f) \right\rbrace , \quad \pi(f):=\int d^{3}x \, f(\vec{x})\pi(\vec{x}).\] <p>$\pi(f)$ is the <strong>smeared</strong> canonical momentum operator. This definition is similar to the space translation operator</p> \[T_ {\vec{x}} = \exp \left\lbrace -i\hat{P}\cdot \vec{x} \right\rbrace .\] <p>The translation operator changes the position, while the displacement operator changes the vev of the field operator itself. To be more specific,</p> \[\begin{align*} T_ {\vec{x}}\, \phi(\vec{y})\, T_ {\vec{x}}^{\dagger} &amp;= \phi(\vec{y}-\vec{x}),\\ \mathcal{D}_ {f} ^{\dagger} \, \phi(\vec{x})\, \mathcal{D}_ {f} &amp;= \phi(\vec{x})+f(\vec{x}). \end{align*}\] <p>The statement is that, we can use the unitary $\mathcal{D}_ {f}$ to translate the basis of the Hilbert space.</p> <p>I find it helpful to use $T_ {\vec{x}}$ as an example to understand the properties of $\mathcal{D}_ {f}$. Let $\left\lvert{\psi}\right\rangle$ be any state in quantum mechanics, what is the resulting state of $T_ {\vec{x}}$ acting on it? $T_ {\vec{x}}\left\lvert{\psi}\right\rangle$ has two interpretations, the passive view and the active view. In the passive view, the translation operator is seen as a change in the coordinate system or reference frame rather than a change in the physical state itself. The state of the system remains unchanged, but the coordinates used to describe it are shifted. In the active view, the translation operator actively shifts the physical state of the system by a displacement. The coordinates remain fixed, but the state or the field configuration changes. The same goes for the displacement operator $\mathcal{D}_ {f}$, given any state (quantum field theory now, no longer quantum mechanics) $\left\lvert{\Psi}\right\rangle$, $\mathcal{D}_ {f}\left\lvert{\Psi}\right\rangle$ can be seen as either a new state (active perspective), or the same state but in different basis (passive perspective). When discussing kink states and trivial vacuum states in the future, it seems best to consider $\mathcal{D}_ {f}$ passively. This approach allows us to discuss the same states in different bases, or frames. We’ll delve into the details shortly. However, before diving into quantum field theory, I would like to first address the nature of quantum states in quantum mechanics.</p> <hr/> <p>Quantum mechanics is defined over the spatial coordinates $\vec{x}$. The position eigenstates $\left\lvert{\vec{x}}\right\rangle$ form a complete basis of the Hilbert space. However, $\left\lvert{\vec{x}}\right\rangle$ is represented by a Dirac $\delta$-function, which does not belong to the Hilbert space of $L^{2}(\mathbb{R}^{d})$, where $d$ is the dimension of the space, as usually. It is a challenge to mathematical rigor of quantum mechanics.</p> <p>Recall that the Hilbert space $L^{2}(\mathbb{R}^{d})$ consists of all square-integrable functions defined on $\mathbb{R}^{d}$, with an inner product $\left\langle f,g \right\rangle=\int dx \, f^{\ast}g$. This inner product also defines a norm, and with norm we can talk about Cauchy completeness. The space $L^{2}$ is indeed Cauchy complete, since we do not require functions in it to be smooth. The Cauchy completeness makes it a Hilbert space, not a pre-Hilbert space.</p> <p>To deal with mathematical objects such as the Dirac $\delta$-function, quantum mechanics often uses the concept of <code class="language-plaintext highlighter-rouge">rigged Hilbert space</code>, also known as a <code class="language-plaintext highlighter-rouge">Gelfand triplet</code>. A rigged Hilbert space involves three components:</p> <ol> <li>Schwartz space $\mathcal{S}$, the space of <strong>rapidly decreasing smooth</strong> functions. It is a dense subspace of the Hilbert space that we talk about in the next paragraph. By working with $\mathcal{S}$, we can rigorously define unbounded operators and their domains. States here are smooth and decays faster than any polynomial, making them suitable for rigorous operator definitions.</li> <li>Hilbert space $L^{2}$. The Schwartz space $\mathcal{S}$ is a dense subset of $L^{2}$. Here is where all the quantum states reside. These states are normalizable and have finite norm.</li> <li>Dual space $\mathcal{S}^{\ast}$. It includes functionals, also called generalized states. The Dirac delta function represents the position eigenstate, while plane waves represent momentum eigenstates, we can’t fit them into the Hilbert space $L^{2}$, here is where these pathological states reside.</li> </ol> <p>The relationship can be written as</p> \[\mathcal{S} \subset L^{2} \subset \mathcal{S}^{\ast }.\] <p>Actually, I don’t think it makes a lot of sense to regard $\left\lvert{\vec{x}}\right\rangle$ as a physical state, since in real life, due to the uncertainty principal, a particle will never be localized at a specific point. Instead, the position always smears about a certain region, so is its momentum. The role of $\left\lvert{\vec{x}}\right\rangle$ is more of giving us the value of the wave function at position $\vec{x}$, in other words, what naturally appears is the dual version $\left\langle{\vec{x}}\right\rvert$ of $\left\lvert{\vec{x}}\right\rangle$. $\left\langle{\vec{x}}\right\rvert$ can be regarded as map that takes a state in the Hilbert space of quantum states, and spits out a complex number:</p> \[\begin{align*} \left\langle{\vec{x}}\right\rvert : \quad \mathcal{H} &amp;\to \mathbb{C} \\ \left\lvert{\psi}\right\rangle &amp;\mapsto \psi(\vec{x}), \end{align*}\] <p>where $\mathcal{H}$ is not the Hamiltonian but the Hilbert space of quantum states.</p> <p>For a state $\left\lvert{\psi}\right\rangle$ to be a physical state, it should be sensible to talk about</p> \[\left\langle{\psi}\right\rvert \mathcal{O} \left\lvert{\psi}\right\rangle ,\quad \mathcal{O}\text{ is an observable.}\] <p>$\left\lvert{\vec{x}}\right\rangle$ fails this requirement since $\left\langle{\vec{x}}\right\rvert \hat{x} \left\lvert{\vec{x}}\right\rangle=\infty$, this is another reason to say that $\left\lvert{\vec{x}}\right\rangle$ is not a physical state.</p> <hr/> <p>We distinguish two concepts, <code class="language-plaintext highlighter-rouge">states</code> and <code class="language-plaintext highlighter-rouge">wave function</code>. In quantum mechanics, they are sometimes used interchangeably, but they have distinct meanings. A quantum state contains all the information about the system. It can be described in different representations, depending on what information we want to know. For example, if we want to know information about the position, we go to the physical space representation expanded by $\left\lvert{\vec{x}}\right\rangle$. Quantum states can be represented as vectors in a Hilbert space, and there exists pure and mixed states. On the other hand, the wave function is a specific representation of a quantum state in the position (or sometimes momentum) basis. It is a complex-valued function that gives the probability amplitude of finding a particle in a particular position in space. The wave function of a state $\left\lvert{\psi}\right\rangle$ is denoted by $\psi(x)$, where $x$ is the position.</p> <p>In the passive perspective, a state before and after spatial translation is the same state, they just have different wave functions, because in order to get the wave function we need two things: bases and a state, even though the state is unchanged but the bases are changed now, thus the final expression is also changed.</p> <hr/> <p>Coming back to the passive perspective regarding the displacement operator $\mathcal{D}_ {f}$ acting on a state, for example the kink state $\left\lvert{K}\right\rangle$. We regard $\mathcal{D}_ {f}\left\lvert{K}\right\rangle$ (or is it $D_ {f}^{\dagger}\left\lvert{K}\right\rangle$? I don’t remember, anyways the argument works the same) as the same state as $\left\lvert{K}\right\rangle$, but “shifted”. In the case of quantum mechanics, the things that get shifted are wave functions; in quantum field theory, it should be <strong>wave functional</strong>, the quantum field theoretical counterpart of wave functions. Let’s dive into the details.</p> <p>Consider a scalar field theory. The “coordinate” for such a theory would not be $\vec{x},\vec{y}$ but field configurations $\phi(\vec{x})$. Instead of the position of a single particle, we now consider the entire configuration of the field $\phi(x)$ at a particular time. The wave functional $\Psi[\phi]$ describes the quantum state of the entire field configuration $\phi(x)$ at a given time. Recall how the quantization is done in quantum mechanics: classically a particle occupies a specific position $\vec{x}(t)$ at any given time $t$, after quantization, instead of $\vec{x}(t)$ we have a wave function $\psi$ that maps each $\vec{x}$ to a complex number. This is just to say that the wave function is a function of spacetime. Similarly, in QFT, let $\Psi[\phi]$ be a functional, then by definition it assigns a complex number to each field configuration $\phi(\vec{x})$,</p> \[\Psi: \phi(\vec{x}) \mapsto \mathbb{C}.\] <p>Similar to $\left\lvert{\vec{x}}\right\rangle$ is the eigen state of $\hat{x}$, $\hat{x}\left\lvert{\vec{x}}\right\rangle=\vec{x}$, we can construct the eigen state of field operator $\hat{\phi}$ by</p> \[\hat{\phi}(\vec{x})\left\lvert{\phi}\right\rangle = \phi(\vec{x})\left\lvert{\phi}\right\rangle ,\] <p>Any wave functional can be given as a superposition of such eigen states. Let $\left\lvert{\Psi}\right\rangle$ be a well-behaved wave functions, it can be formally written as</p> \[\left\lvert{\Psi}\right\rangle = \int D\phi(\vec{x}) \, \Psi[\phi(\bullet)] \left\lvert{\phi(\bullet)}\right\rangle ,\] <p>where the bullet in $\phi(\bullet)$ indicates a spatial coordinate, it is here to remind us that $\phi$ is a function, but I don’t want to waste another Latin letter.</p> <p>Given the quantum state $\left\lvert{\Psi}\right\rangle$, the wave functional corresponding to this state is given by</p> \[\Psi [\phi(\bullet)] = \left\langle \phi \middle\vert \Psi \right\rangle \in \mathbb{C}.\] <p>As a consistency check, let’s see if we can reproduce the result $\left\langle{\Psi}\right\rvert\hat{\phi}(\vec{x}) \left\lvert{\Psi}\right\rangle=\psi(\vec{x})$ for some classical field $\psi(\vec{x})$. We have</p> \[\begin{align*} \left\langle{\Psi}\right\rvert \hat{\phi}(\vec{x})\left\lvert{\Psi}\right\rangle &amp;= \int D\varphi \, \Psi ^\ast [\varphi]\left\langle{\varphi}\right\rvert\, \hat{\phi}(\vec{x})\,\int D\varphi' \, \Psi[\varphi']\left\lvert{\varphi'}\right\rangle \\ &amp;= \int D\varphi \, \Psi^\ast [\varphi] D\varphi' \, \Psi[\varphi']\left\langle{\varphi}\right\rvert\, \varphi'(\vec{x})\left\lvert{\varphi'}\right\rangle \\ &amp;= \int D\varphi \, \Psi^\ast [\varphi] D\varphi' \, \Psi[\varphi'] \varphi'(\vec{x}) \delta(\varphi-\varphi') \\ &amp;= \int D\varphi \, \Psi^\ast [\varphi]\, \Psi[\varphi] \varphi(\vec{x}) \\ &amp;= \int D\varphi \, \left\lvert \Psi[\varphi] \right\rvert^{2} \varphi(\vec{x}), \end{align*}\] <p>and recall that $\left\lvert \Psi[\varphi] \right\rvert^{2}$ is the probability of finding $\varphi$ in $\Psi$, thus indeed we have</p> \[\int D\varphi \, \left\lvert \Psi[\varphi] \right\rvert^{2} \varphi(\vec{x}) = \left\langle \hat{\phi}(\vec{x}) \right\rangle =: \psi(\vec{x}).\] <p>Time evolution is generated by the Hamiltonian, yielding a functional Schrodinger equation:</p> \[i\hbar \left\lvert{\Psi[\phi]}\right\rangle = \hat{H}\left\lvert{\Psi[\phi]}\right\rangle ,\] <hr/> <p>For the ground state (or vacuum state) of the free scalar field, the wave functional $\Psi_0[\phi]$ has a Gaussian form, it is basically an infinite lattice of harmonic oscillators. It can be written as:</p> \[\Psi_0[\phi] = N \exp \left( -\frac{1}{2} \int d^3x \, d^3y \, \phi(x) K(x,y) \phi(y) \right)\] <table> <tbody> <tr> <td>where $N$ is a normalization constant, and $K(x,y)$ is a kernel that depends on the mass $m$ of the scalar field and the spatial separation $</td> <td>x - y</td> <td>$.</td> </tr> </tbody> </table> <p>For a free scalar field, $K(x,y)$ can be written in terms of the Fourier transform:</p> \[K(x,y) = \int \frac{d^3k}{(2\pi)^3} \, \omega_k \, e^{i k \cdot (x - y)}\] <p>with $\omega_k = \sqrt{k^2 + m^2}$.</p> <p>The wave functional $\Psi_0[\phi]$ provides the probability amplitude for the field configuration $\phi(x)$. The exponential form indicates that the ground state is a Gaussian distribution centered around $\phi(x) = 0$, reflecting the fact that the vacuum state has no preferred field configuration (zero field on average).</p> <p>For more information please refer to this <a href="https://physics.stackexchange.com/questions/746099/schroedinger-equation-for-wave-functional-qft">post</a>.</p> <hr/> <p>Now we can talk about passive perspective of the action of the displacement operator $D_ {f}$, in a more rigorous way. $\mathcal{D}_ {f}$ will increase the basis $\left\lvert{\varphi}\right\rangle$ by $f(\vec{x})$,</p> \[\mathcal{D}_ {f}\left\lvert{\varphi(\vec{x})}\right\rangle = \left\lvert{\varphi(\vec{x})+f(\vec{x})}\right\rangle .\] <p>Then, as you can verify, we have</p> \[\left\langle{\Psi}\right\rvert \mathcal{D}_ {f}^{\dagger} \hat{\phi}(\vec{x}) \mathcal{D}_ {f}\left\lvert{\Psi}\right\rangle = \psi(\vec{x})+f(\vec{x}),\] <p>as we showed before. We can regard $\mathcal{D}_ {f}\left\lvert{\Psi}\right\rangle$ as the same state as $\left\lvert{\Psi}\right\rangle$, just measured with different basis: instead of $\left\langle \varphi \middle\vert \Psi \right\rangle$, we have $\left\langle \varphi+f \middle\vert \Psi \right\rangle$.</p> <p>In the following notes, we will talk about the spontaneous symmetry breaking, and enter the main part of the projcet.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:Polchinski" role="doc-endnote"> <p>J. Polchinski, String Theory. Vol. 1: An Introduction to the Bosonic String. Cambridge Univ. Pr., UK, 1998. <a href="#fnref:Polchinski" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Baiyang Zhang</name></author><category term="#domainWall"/><category term="kink"/><summary type="html"><![CDATA[Table of Contents]]></summary></entry><entry><title type="html">Introduction to Resurgence Part 1</title><link href="https://baiyangzhang.github.io/blog/2024/Introduction-to-Resurgence-Part-1/" rel="alternate" type="text/html" title="Introduction to Resurgence Part 1"/><published>2024-06-26T00:00:00+00:00</published><updated>2024-06-26T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Introduction-to-Resurgence-Part-1</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Introduction-to-Resurgence-Part-1/"><![CDATA[<h1 id="table-of-contents">Table of Contents</h1> <ul> <li><a href="#1-motivation">1. Motivation</a></li> <li><a href="#2-analytic-continuation-and-monodromy">2. Analytic Continuation and Monodromy</a></li> <li><a href="#3-an-example-by-poincare">3. An example by Poincare</a></li> <li><a href="#4-the-differential-algebra">4. The differential algebra</a></li> </ul> <h1 id="1-motivation">1. Motivation</h1> <p>The following is an incomplete list of the potential applications of resurgence theory.</p> <ul> <li>Normal forms for dynamical systems</li> <li>Gauge theory of singular connections</li> <li>Quantization of symplectic and Poisson manifolds</li> <li><code class="language-plaintext highlighter-rouge">Floer</code> homology and <code class="language-plaintext highlighter-rouge">Fukaya</code> categories</li> <li>Knot invariants</li> <li>Wall-crossing and stability conditions in algebraic geometry</li> <li>Spectral networks</li> <li>WKB approximation in quantum mechanics</li> <li><strong>Perturbative expansions in quantum field theory (QFT)</strong></li> </ul> <p>The most surprising result, at least for me, of resurgence theory in QFT is that one can uncover the non-perturbative results from perturbative expansion alone! Typically, calculating non-perturbative results requires every possible resource—like the topology of the vacuum manifold—anything but perturbative methods. However, resurgence theory enables us to derive non-perturbative results, such as instanton contributions, through the analytical continuation of perturbative data! In one sense, it feels like black magic; yet, perhaps I shouldn’t be so surprised, for if we fully understand the perturbative expansions to all orders, we essentially grasp everything about the equation of motion, which inherently includes all non-perturbative information. In theory, then, perturbative expansions should be capable of yielding non-perturbative insights. However, this is only in theory. It’s still utterly astonishing to witness it in practice.</p> <p>Speaking of understanding the quantum field theory, it is impossible to make sense of perturbation theory <strong>without</strong> knowing at least some facets of the resurgence theory. After all, considering that if we include more and more perturbative terms in any perturbative power expansion, the power series eventually diverges, so what sense does it make to just consider the first few terms? Claiming they give the dominant results would be ridiculous. However the miraculous agreement between perturbative QED and experiments clearly suggests that perturbation expansion makes sense, it is by no chance a coincidence. The answer to this question lies in resurgence theory.</p> <hr/> <p>H. Poincare mentions the so-called “a kind of misunderstanding between geometers and astronomers about the meaning of the word convergence”, He proposed a simple example: consider the following series</p> \[\sum \frac{1000^{n}}{n!} \text{ and }\sum \frac{n!}{1000^{n}},\] <p>Poincare said that for geometers, i.e. mathematicians in his time, the first one converges because at large $n$ the terms gets smaller and smaller. But for astronomers the first one is as good as divergent since the next terms doesn’t get smaller until $n$ is larger than $1000$. For astronomers the second series diverges because the first $1000$ terms decreases quickly.</p> <p>He then proposes to reconcile both points of view by clarifying the role that divergent series (in the sense of geometers) can play in the approximation of certain functions. This is the origin of the modern theory of asymptotic expansion.</p> <hr/> <p>In this note we shall focus on <code class="language-plaintext highlighter-rouge">formal power series</code>, sometimes also called the polynomial forms, such as the Stirling series. Thus the previous example should be written as</p> \[\sum \frac{1000^{n}}{n!}t^{n} \quad \text{ and } \quad \sum \frac{n!}{1000^{n}}t^{n}\] <p>where the first one has <strong>infinite</strong> <strong>radius of convergence</strong> while the second one has <strong>zero radius of convergence</strong>. For us, <code class="language-plaintext highlighter-rouge">divergent series</code> will usually mean a formal power series with zero radius of convergence.</p> <p>First we will introduce the <code class="language-plaintext highlighter-rouge">Borel-Laplace sumamtion</code>, which obtains a function from a divergent formal series. The relation between the obtained function and the original power series is an example of <code class="language-plaintext highlighter-rouge">asymptotic expansion of Gevrey type</code>. We shall also introduce the phenomenon for which <code class="language-plaintext highlighter-rouge">J. Ecalle</code> coined the name <code class="language-plaintext highlighter-rouge">resurgence</code> at the beginning of the 1980s.</p> <h1 id="2-analytic-continuation-and-monodromy">2. Analytic Continuation and Monodromy</h1> <p><code class="language-plaintext highlighter-rouge">Formal power series</code> is a generalization of normal power series, or polynomial, in the sense that we consider a power series of infinite order as a formal object and don’t worry about evaluation yet, let alone if it is convergent. Provided a ring $R$, consider the set of formal power series in $X$ with coefficients from $R$, denoted by $R[[X]]$, is another ring, for example, multiply one polynomial to another and we have a new polynomial. It is called the <strong>ring of formal power series in the variable $X$ over $R$</strong>.</p> <p>First we run through some definitions and concepts that might be used in the future.</p> <p>We say a complex-valued function $f:\Omega \to \mathbb{C}$ is <code class="language-plaintext highlighter-rouge">analytic</code> if $f$ is represented by a convergent power series expansion on a neighborhood around every point $a\in\Omega$.</p> <p>We say a complex-valued function $f:\Omega \to \mathbb{C}$ is <code class="language-plaintext highlighter-rouge">holomorphic</code> iff it satisfied Cauchy-Riemann relation, which is equivalent to $\partial f/\partial \overline{z}=0$ . If we regard $z$ and $\overline{z}$ as independent variables, a holomorphic function $f$ is only a function of $z$ not $\overline{z}$.</p> <p>A differential manifold is a topological space (given by closed sets and all that stuff) with differential structure, which practically means that you can find a way to do derivatives on the manifold. A n-Dimensional real (Complex) manifold is locally homeomorphic to $\mathbb{R}^N (\mathbb{C}^n)$, plus the condition that the transition from one chart (coordinate system) to another is <code class="language-plaintext highlighter-rouge">homeomorphic (holomorphic)</code>.</p> <p>An <code class="language-plaintext highlighter-rouge">open disk</code> of radius $r$ around $z_ 0$ is the set of points $z$ on $\mathbb{C}$ that satisfies</p> \[\left\lvert z-z_ 0 \right\rvert &lt; r.\] <p>A <strong>open deleted disk of radius $r$ around $z_ 0$</strong> is the set of points with</p> \[0 &lt; \left\lvert z-z_ 0 \right\rvert &lt; r.\] <p>a deleted disk is also called a punctured disk, since the origin $z_ {0}$ has been taken out.</p> <hr/> <p>A complex atlas on a 2-dimensional manifold is a collection of charts that cover the manifold, where each chart maps a portion of the manifold to an open subset of the complex plane $\mathbb{C}$, and the transition functions between overlapping charts are holomorphic (complex differentiable).</p> <p>Take the Riemann sphere (which we will talk about in more detail later) for example. The Riemann sphere $\mathbb{C}P^1$ is a classic example of a 2-dimensional complex manifold. It can be visualized as the complex plane plus a point at infinity. To see that all the infinities on a complex plain can be identified as a single point, notice that in $[z_ {0},z_ {1}]$ when $z_ {1}\to \infty e^{ i\theta }$ it is equivalent to $\left[ \frac{z_ {0}}{\infty e^{ i\theta }},1 \right]$, and no matter the angle $\theta$ it always goes to $[0,1]$. To construct a complex atlas for the Riemann sphere, we use two charts:</p> <ol> <li> <p><strong>Chart $U_ 1$</strong>: This chart covers the sphere minus the point at infinity. It maps each point $z$ in the complex plane $\mathbb{C}$ to itself: \(\phi_ 1: U_ 1 \rightarrow \mathbb{C}, \quad \phi_ 1(z) = z\) Here, $U_ 1 = \mathbb{C}$.</p> </li> <li> <p><strong>Chart $U_ 2$</strong>: This chart covers the sphere minus the origin. It maps each point $z$ in the complex plane, excluding the origin, to its reciprocal: \(\phi_ 2: U_ 2 \rightarrow \mathbb{C}, \quad \phi_ 2(z) = \frac{1}{z}\) Here, $U_ 2 = \mathbb{C} \setminus {0}$.</p> </li> </ol> <p>The two charts overlap on $U_ 1 \cap U_ 2 = \mathbb{C} \setminus {0}$. The transition functions between these charts are:</p> <ul> <li>From $U_ 1$ to $U_ 2$: \(\phi_ 2 \circ \phi_ 1^{-1}(z) = \frac{1}{z}\)</li> <li>From $U_ 2$ to $U_ 1$: \(\phi_ 1 \circ \phi_ 2^{-1}(z) = \frac{1}{z}\)</li> </ul> <p>Both transition functions are holomorphic, as the function $f(z) = \frac{1}{z}$ is complex differentiable wherever $z \neq 0$.</p> <p>To say that two complex atlases on a manifold are <code class="language-plaintext highlighter-rouge">analytically equivalent</code> means that the combined atlas they form (by taking all the charts from both atlases) is itself a complex atlas. This implies that the transition functions between the charts of one atlas and the charts of the other atlas are holomorphic wherever they overlap.</p> <hr/> <p>By a <code class="language-plaintext highlighter-rouge">complex structure</code> on a manifold, we mean an equivalent class of analytically equivalent complex atlases on the manifold. If we give a manifold a complex atlas, then we have given it a complex structure.</p> <p>A Riemann surface is a pair $(X,\Sigma)$ where $X$ is a connected 2-dimensional manifold and $\Sigma$ is a complex structure on $X$. The simplest Riemann surface is the complex plane itself.</p> <hr/> <ul> <li> <p>$\mathbb{C} P^n$ Model: The (n+1)-tuple $z = (z^0,\cdots,z^n)$ defines a vector in space $\mathbb{C}^{n+1}$. Define a equivalence relation $\sim$ between two vectors,</p> \[(u^0,\cdots,u^n) \sim (v^0,\cdots,v^n) \text{ if } \exists \lambda\neq 0 \in \mathbb{C} \text{ so that } \mathbf{u} = \lambda \mathbf{v}\] </li> </ul> <p>then</p> \[\mathbb{C} P^{n} \equiv (\mathbb{C}^{n+1}-\left\lbrace0\right\rbrace)/\sim,\] <p>and the $n+1$ numbers are call <code class="language-plaintext highlighter-rouge">homogeneous coordinates</code> and is denoted by $[z^0,\cdots,z^n]$. We can make one of them constantly equal to 1, then only the rest are really coordinates, it is called <code class="language-plaintext highlighter-rouge">inhomogeneous coordinates</code>.</p> <p><code class="language-plaintext highlighter-rouge">Meromouphic functions</code> are functions holomorphic except at a discrete set of isolated poles.</p> <p>A <code class="language-plaintext highlighter-rouge">domain</code> in $\mathbb{C}$ is a connected non-empty open subset of $\mathbb{C}$.</p> <hr/> <p><strong>Riemann Sphere</strong></p> <p>There are two ways to think of $\overline{C} \equiv \mathbb{C} \cup \left\lbrace\infty\right\rbrace$, namely the compactified complex plane, by adding a point called infinity $\infty$.</p> <ul> <li>complex projective plane $\mathbb{C}P^1$.</li> <li>a 2D sphere $\mathbb{S}^2$. The coordinates is given by the stereographic projection, except for the north pole $N$, $\pi : \mathbb{S}^2-\left\lbrace N \right\rbrace \to \mathbb{C}$.</li> </ul> <p>The space $\overline{\mathbb{C}}$ has the structure of e Riemann surface and it is called the <code class="language-plaintext highlighter-rouge">Riemann sphere</code>. We can introduce two charts on the Riemann sphere,</p> \[\mathfrak{U}_ 1 = \mathbb{C},\quad \mathfrak{U}_ 2 = \mathbb{C}^\ast \cup \left\lbrace\infty\right\rbrace\] <p>where $\mathbb{C}^\ast$ is the punctured complex plane, $\mathbb{C}^\ast \equiv \mathbb{C} - \left\lbrace0\right\rbrace$.</p> <p><strong>Theorem.</strong> A function is meromorphic on $\overline{\mathbb{C}}$ iff its restriction on $\mathbb{C}$ is a rational function.</p> <p>By the restriction of a function, we mean that to restrict the domain so that the it is well defined, no singularities. For example, the function $f:x\to 1/x$ has a singularity at $x=0$, then if we want something which is just like $f$ but has no singularity, we can just restrict the domain to $\mathbb{R} - \left\lbrace0\right\rbrace$, which is said to be a restriction of $f$.</p> <p>A <code class="language-plaintext highlighter-rouge">germ</code> of functions at a point $a\in\mathbb{C}$ is a set of function defined in the neighborhood of $a$ which all have the same Taylor expansion. A more mathematical definition is as following.</p> <p>Use $\mathcal{O}(a)$ to denote the set of functions which are defined in a neighborhood of $a$ and is holomorphic at $a$. Define an equivalence relation $\sim$ so that if $f\sim g$ for $f,g \in \mathcal{O}(a)$, then $f,g$ are identical on some neighborhood of a. The equivalence class is called a germ of holomorphic functions at $a$.</p> <p>Intuitively, the germ of a function tells us how a function behaves locally at point $a$.</p> <hr/> <p>The <code class="language-plaintext highlighter-rouge">Fundamental Uniqueness Theorem (FUT)</code> for holomorphic functions:</p> <p><strong>Theorem.</strong> If $f,g$ are holomorphic functions on a domain $D\in\mathbb{C}$ and $f \sim g$ for some point $a\in D$, namely f and g are in the same germ at a, then f is identical to g on $D$.</p> <p>The germ of $f$ will be denoted by $\overline{f}$, if there is no ambiguity about around which point it is defined.</p> <hr/> <p><strong>Analytic Continuation, Monodromy</strong></p> <p>First we introduce the analytic continuation in a different way, more formal and more mathematical. We begin by defining <code class="language-plaintext highlighter-rouge">pairs</code>. The idea is that, a function is not only defined by the values but also the domain on which it is defined.</p> <p>A <code class="language-plaintext highlighter-rouge">pair</code> $(U,f)$ is a non-zero open disk $U\subset \mathbb{C}$ (why does it has to be open? I don’t know.) and a function, holomorphic on $U$, such that the radius of $U$ is the maximum radius of convergence of the series expansion of $f$. The center of the pair is the center of $U$. Usually $U$ will stop at some singular point.</p> <p>Another concept is adjacency, two pairs $(U,f)$ and $(V,g)$ are said to be <code class="language-plaintext highlighter-rouge">adjacent</code> if $U\cap V \neq 0$ and $f \equiv g$ on $U\cap V$.</p> <p>If there is a <code class="language-plaintext highlighter-rouge">finite</code> sequence of pairs $(U_ i,f_ i),\quad i = 0,1,\cdots, n$ so that for all $i$, $(U_ i,f_ i)$ is adjacent to $(U_ {i\pm 1},f_ {i\pm 1})$, then $(U_ 0,f_ 0)$ is said to be the analytical continuation of $(U_ n,f_ n)$.</p> <p>We can define a analytical continuation along a curve $\gamma: [0,1] \to \mathbb{C}$. The definition is kind of intuitive so I will skip it here. Now the question is, is the analytical continued function $(U_ n,f_ n)$ dependent on the path? The answer is the monodromy theorem:</p> <p><strong>Theorem.</strong> If the two path are homotopic, then the analytical continuation results to the same functions.</p> <p>If in any doubt, just think of the $\ln{z}$ function.</p> <hr/> <p><strong>Linear Differential System</strong></p> <p>A <code class="language-plaintext highlighter-rouge">linear system</code> is short for a complex linear ordinary differential system. A linear system of order p is a system with p first order ordinary differential equations.</p> \[\frac{dy(x)}{dx} = A(x) y(x),\quad y(x) = \begin{pmatrix} y_ 1(x)\\ \vdots \\ y_ p(x) \end{pmatrix}\] <p>where $y(x)$ is a column vector of functions, and $A$ is the $p\times p$ coefficient matrix. The system is referred to as $(S)$.</p> <p>We used $\mathbb{C}(x)$ to denote the field of complex rational functions, and $\mathscr{M}(D)$ the field of meromorphic functions on domain $D$, and $\mathscr{O}(D)$ the ring of holomorphic functions on domain $D$.</p> <p>A <code class="language-plaintext highlighter-rouge">fundamental solution</code> of $(S)$ is a $p\times p$ matrix whose columns are $\mathbb{C}$-linear independent solutions to $(S)$.</p> <p>The <code class="language-plaintext highlighter-rouge">Wronskian</code> for $n$ functions are defined to be</p> \[W(f_ 1,\cdots, f_ n)(x) \equiv \begin{vmatrix} f_ 1(x) &amp; \cdots &amp; f_ n(x)\\ f'_ 1(x)&amp; \cdots &amp; f'_ n(x)\\ \cdots \\ f^{(n-1)}(x) &amp; \cdots &amp; f^{(n-1)}(x) \end{vmatrix}.\] <p>Let $\Sigma= \left\lbrace a_ 1,\cdots,a_ n \right\rbrace\subset \overline{\mathbb{C}}$ be the set of singular points of $(S)$. Let $U_ \Sigma \equiv \overline{\mathbb{C}}\backslash \Sigma$.</p> <p>Recall a nice property of Wronskian: Let $\mathscr{D}$ a domain in $U_ \Sigma$, $W$ a $p\times p$ solution of $(S)$, the following are equivalent:</p> <ul> <li>W is a fundamental solution of $(S)$</li> <li>$\det{W(x)}\neq 0$ for some $x \in \mathscr{D}$</li> <li>$\det{W(x)}\neq 0$ for all $x \in \mathscr{D}$</li> </ul> <p>In other words, the Wronskian is either nonzero on the entire domain, or identically zero.</p> <hr/> <p><strong>Differential Galois Theory</strong></p> <p>A <code class="language-plaintext highlighter-rouge">differential field</code> $(k,\partial)$ is a field $k$ with derivation. A \hl{differential homomorphism} $\phi:(k_ 1,\partial)\to(k_ 2,\partial)$ from $k_ 1$ to $k_ 2$ is a field homomorphism that commutates with $\partial$. A triple $(k_ 1, \phi, k_ 2)$ is called a differential extension. $k_ 2$ is also called a differential extension of $k_ 1$.</p> <p>A differential system</p> \[\partial y = A y\] <p>where $A$ is a $p \times p$ matrix.</p> <h1 id="3-an-example-by-poincare">3. An example by Poincare</h1> <p>To get some feeling about resurgence, let’s start with an example first given by Poincare. This example shows <strong>how an divergent series emerges from a function.</strong></p> <p>Fix $w\in \mathbb{C}$ and $\left\lvert w \right\rvert&lt;1$. Consider the series of functions of the complex variable $t$,</p> \[\phi_ {k}(t) := \frac{w^{k}}{1+kt},\quad \phi(t):= \sum_ {k\geq 0} \phi_ {k}(t).\] <p>This series is uniformly convergent on</p> \[U:=C^{\ast } - \left\lbrace -1,-\frac{1}{2},-\frac{1}{3},\dots \right\rbrace .\] <p>Hence the sum $\phi$ is <code class="language-plaintext highlighter-rouge">holomorphic</code> in $U$. Actually $\phi$ is meromorphic on $\mathbb{C}^{\ast}$ (not on $\mathbb{C}$ since the origin would be a limiting point of the poles) with simple poles at $1 / \mathbb{N}$.</p> <p>We now show how this function $\phi$ gives rise to a divergent formal series when $t$ approaches $0$. The idea is to expand each $\phi_ {k}$ first in terms of $t$. For each $k \in \mathbb{N}$, we have a <em>convergent</em> Taylor expansion at $t=0$,</p> \[\phi_ {k}(t) = w^{k}\sum_ {n\geq 0}(-1)^{n}(kt)^{n}, \quad \left\lvert t \right\rvert&lt; \frac{1}{k} .\] <p>One might be tempted to recombine the (convergent) Taylor expansion of $\phi_ {k}$ to give $\phi(t)$. It amounts to considering the well-defined <strong>formal series</strong></p> \[\tilde{\phi}(t) := \sum_ {n\geq 0}(-1)^{n} b_ {n} t^{n}, \quad b_ {n}:= \sum_ {k\geq 0}k^{n} w^{k}.\] <p>We see that $b_ {n}$ is convergent since</p> \[\lim_ { k \to \infty } \frac{(k+1)^{n}w^{k+1}}{k^{n}w^{k}} = w &lt;1 \text{ by construction}.\] <p>However, it turns out that <strong>this formal series is divergent!</strong></p> <p>To see this, make the substitution $w = e^{ s }$. Then, since $\text{Re }w &lt;1$, we have</p> \[b_ {0}=(1-w)^{-1} = (1-e^{ s })^{-1}\] <p>and</p> \[b_ {n} = \left( w \frac{d}{dw} \right)^{n}b_ {0} = \left( \frac{d}{ds} \right)^{n} b_ {0}.\] <p>There is an easy way to tell if a series has non-zero radius of convergence, by some kind of a “dominance criterion”. If the series of study $a_ {n}$ is dominated by $AB^{n}$ where $A,B$ are real and $A,B&gt;0$, namely for all but finite $n$ we have $\left\lvert a_ {n} \right\rvert \leq AB^{n}$. Then the formal series</p> \[F(\xi) := \sum(-1)^{n} a_ {n} \frac{\xi^{n}}{n!}\] <p>would have infinite radius of convergence. <strong>$F$ can be seen as a map of the formal series to a function of $\xi$, note that we have inserted a factor of $1 / n!$ into the sum to make is more convergent</strong>. In our case of $b_ {n}$, we see that</p> \[F(\xi) = \sum(-1)^{n} b_ {n} \frac{\xi^{n}}{n!} = \sum(-1)^{n} \frac{\xi^{n}}{n!}\left( \frac{d}{d s} \right)^{n} b_ {0}(s) = b_ {0}(s-\xi) = \frac{1}{1-e^{ s-\xi }} .\] <p>This functions has finite radius of convergence, since the last expression in the equation above diverges at $\xi=s+2\pi i \mathbb{Z}$. The radius of convergence is not infinite! Thus $\tilde{\phi}$ must have zero radius of convergence.</p> <hr/> <p>Now the question is to understand the relation between $\tilde{\phi}$ and $\phi$. We shall see in this note that the <code class="language-plaintext highlighter-rouge">Borel-Laplace</code> summation is a way of going from the divergent formal series $\tilde{\phi}$ to the finite function $\phi$. $\tilde{\phi}$ is actually the <code class="language-plaintext highlighter-rouge">asymptotic expansion</code> of $\phi(t)$ at $t=0$. We shall explain what it means next.</p> <p>We can already observe that the moduli of the coefficients $b_ {n}$ satisfy</p> \[\left\lvert b_ {n} \right\rvert &lt;AB^{n} n! ,\quad n \in \mathbb{N}\] <p>for some $A,B&gt;0$. Such inequalities are called <code class="language-plaintext highlighter-rouge">1-Gevrey estimates</code> for the formal series $\tilde{\phi}(t)=\sum b_ {n}t^{n}$.</p> <p>We remark that, since the original function $\phi(t)$ is not holomorphic (nor meromorphic) in any neighborhood of 0, because of the accumulation at the origin of the sequence of simple poles $- \frac{1}{k}$. Thus it would be very surprising to find a positive radius of convergence for $\tilde{\phi}$.</p> <hr/> <p>Resurgence theory can also be used to study power series of the form</p> \[\sum_ {i} \left( \sum_ {j} a_ {ij}t^{j} \right) e^{ -c_ {j} / t }\] <p>note that the variable $t$ appears at two places, once in the series and once in the exponent. The exponent term is the small correction that is invisible to Taylor expansion at $t=0$, and the formal series in the parenthesis diverges.</p> <p>There are many examples of such series in physics. For example, the series could represent the solution of an ordinary differential equation, or the value of some integral, or the perturbative results. In the below is a list of where you might find series like this:</p> <ul> <li>Normal forms for dynamical systems</li> <li>Gauge theory of singular connections</li> <li>Quantization of symplectic and Poisson manifolds</li> <li>Floer homology and Fukaya categories</li> <li>Knot invariants</li> <li>Wall-crossing and stability conditions in algebraic geometry</li> <li>Spectral networks</li> <li>WKB approximation in quantum mechanics</li> <li>Perturbative expansions in quantum field theory (QFT).</li> </ul> <p>There has been some recent work in the physics literature suggesting the possibility that the divergent series obtained from the perturbative expansion may have more information about the true nature of the QFT that one might naively expect.</p> <p>In the next note we will dive into the details of resurgence theory, beginning with the differential algebra $(\mathbb{C}[[1 / z]],\partial)$.</p> <h1 id="4-the-differential-algebra">4. The differential algebra</h1> <p>It will be convenient for us to set $z = 1/t$ in order to “work at $\infty$” rather than at the origin, since we will often talk about compactified spaces. This means that we shall deal with expansions involving <em>non-positive</em> integer powers of the indeterminate. We denote the set of all the <code class="language-plaintext highlighter-rouge">formal power series</code>, i.e., polynomials in $1 / z$ by</p> \[\mathbb{C}[\![z^{-1}]\!] = \left\{ \phi=\sum_ {n\geq 0}a_ {n}z^{-n} \,\middle\vert\, a_ {i} \in \mathbb{C} \right\}.\] <p>This is a vector space with basis $1, z^{-1},z^{-2}$, etc. It is also an algebra when we take into account the Cauchy product</p> \[\left( \sum a_ {n}z^{-n} \right) \left( \sum b_ {n} z^{-n} \right) = \sum c_ {n} z^{-n}, \quad c_ {n} = \sum_ {p+q=n} a_ {p} b_ {q}.\] <p>The derivation</p> \[\partial = \frac{d}{d z}\] <p>further makes it a <em>differential algebra</em>, which simply means $\partial$ is a linear map which satisfied the Leibniz rules.</p> <p>This is the derivative in terms of $z$, it is natural to ask what is the derivative in terms of $t$. The answer is straightforward,</p> \[\partial = \frac{d}{d z} = \frac{d}{d t^{-1}} = \frac{d}{-t^{-2}dt} =-t^{2} \frac{d}{d t} .\] <p>Then, in mathematical terminology, there is an isomorphism of differential algebra between $(\mathbb{C}[[z^{-1}]],\partial)$ and $(\mathbb{C}[[t]],\partial)$.</p> <hr/> <p>The <code class="language-plaintext highlighter-rouge">standard valuation</code>, or sometimes called the <code class="language-plaintext highlighter-rouge">order</code>, on $\mathbb{C}[[z^{-1}]]$ is the map</p> \[\text{val}: \mathbb{C}[\![z^{-1}]\!] \to \mathbb{N} \cup \infty\] <p>defined by $\text{val }(0)=\infty$ and</p> \[\boxed{ \text{val }(\phi) := \text{min } \left\{ n\in \mathbb{N} \,\middle\vert\, a_ {n}\neq 0 \right\} ,\quad \phi =\sum a_ {n} z^{-n} \neq 0. }\] <p>For $\nu \in\mathbb{N}$, we will use the notation</p> \[z^{-\nu}\mathbb{C}[\![z^{-1}]\!] = \left\{ \sum_ {n\geq \nu} a_ {n}z^{-n} \,\middle\vert\, a_ {\nu},a_ {n+1},\dots \in \mathbb{C} \right\}.\] <p>This is the set of all the complex polynomials in $z^{-1}$ such that the standard valuation is no less than $\nu$.</p> <p>From the viewpoint of the ring structure, ${\frak I} = z^{-1}\mathbb{C}[[z^{-1}]]$ is the maximal ideal of the ring $\mathbb{C}[[z^{-1}]]$. It is often referred to as the <em>formal series without constant term</em>.</p> <p>It is obvious that</p> \[\text{val }(\partial \phi) \geq \text{val }(\phi)+1\] <p>with equality iff there is no constant term.</p> <hr/> <p>With the help of the standard valuation, we can introduce the concept of <code class="language-plaintext highlighter-rouge">distance</code> into the ring of the formal series. Define</p> \[d(\phi,\psi) := 2^{-\text{val }(\phi-\psi)},\quad \phi,\psi \in \mathbb{C}[\![z^{-1}]\!]\] <p>as the distance between $\phi$ and $\psi$. It can only take discrete values, such as $1, 1 / 2, 1 / 4,$ etc.</p> <p>With the definition of distance, $\mathbb{C}[[z^{-1}]]$ becomes a <code class="language-plaintext highlighter-rouge">complete metric space</code>. The topology induced by this distance is called the <code class="language-plaintext highlighter-rouge">Krull topology</code> or the <code class="language-plaintext highlighter-rouge">topology of the formal convergence</code> (or the ${\frak I}$-adic topology). It provides a simple way of using the language of topology to describe certain algebraic properties.</p> <p>We mention that a sequence $\phi_ {n}$ of formal series is a Cauchy sequence iff for each $i\in\mathbb{N}$, the $i$-the coefficient is stationary, namely the $i$-th coefficient of $\phi_ {n}$ becomes a constant when $n$ is larger than certain natural number.</p>]]></content><author><name>Baiyang Zhang</name></author><category term="resurgence"/><summary type="html"><![CDATA[Table of Contents]]></summary></entry><entry><title type="html">Yoneda Lemma</title><link href="https://baiyangzhang.github.io/blog/2024/Yoneda-Lemma/" rel="alternate" type="text/html" title="Yoneda Lemma"/><published>2024-06-18T00:00:00+00:00</published><updated>2024-06-18T00:00:00+00:00</updated><id>https://baiyangzhang.github.io/blog/2024/Yoneda-Lemma</id><content type="html" xml:base="https://baiyangzhang.github.io/blog/2024/Yoneda-Lemma/"><![CDATA[<h1 id="table-of-contents">Table of Contents</h1> <ul> <li><a href="#1-representables">1. Representables</a></li> <li><a href="#2-yoneda-lemma">2. Yoneda Lemma</a></li> <li><a href="#3-the-proof-of-yoneda-lemma">3. The Proof of Yoneda Lemma</a></li> <li><a href="#4-consequences-of-the-yoneda-lemma">4. Consequences of the Yoneda Lemma</a></li> </ul> <h1 id="1-representables">1. Representables</h1> <p>A category is a world of objects, all looking at one another. Each sees the world from a different viewpoint. Take the category of topological spaces for example, consider the object with only one point, denoted $\star$, given another topological space $T$, a map</p> \[\star\to T\] <p>can be regarded as $\star$ looking at $T$. What does $\star$ see? Since $\star$ itself is a point, the image given by a continuous map (by definitions the morphisms in the category of topological spaces are continuous maps) of $\star$ is another point in $T$, that’s to say, a point can only see other points! $\star$ can’t see any other structures, limited by its nature. This is similar to what happens in a society, with real people in it as objects. A curve, on the other hand, could see much more. It can see a point if it wants (a constant map), but it can also see another curve in other objects. In the language of category theory, $A$ seeing $B$ means a map from $A$ to $B$, and all the perspectives an from $A$ of $B$ translates into <em>the set of arrows $\mathcal{M}(A,B)$</em>.</p> <p>We can also ask the dual question: <em>fixing an object in a category, what the set of all the maps into it</em>? Take the category $\text{Set}$ of sets for example. Consider a set with only two elements. Given any set $X$, the maps from $X$ to the two element set is the subset of $X$.</p> <p>In the following we will talk about how each object sees and is seen by the category. This naturally leads to the notion of <code class="language-plaintext highlighter-rouge">representable functors</code>, or just <code class="language-plaintext highlighter-rouge">representables</code>.</p> <hr/> <p>Fix an object $A \in \mathcal{A}$. Consider the <em>totality</em> of maps <em>out of</em> $A$. To each $B\in \mathcal{A}$, there is assigned the set $\mathcal{A}(A,B)$ of maps from $A$ to $B$. This assignation is actually <strong>functorial</strong>, in the sense that to <em>each</em> $B\in\mathcal{A}$, there is a set $A(A,B)$, and to each arrow in $A$, there is another arrow in the codomain of this functor, which we will define shortly.</p> <p><strong>Definition 1.</strong> Let $\mathcal{A}$ be a locally small (meaning that the arrows from any object to any another actually form a set) category and $A\in \mathcal{A}$. Define a functor</p> \[H^{A}: B \mapsto \mathcal{A}(A,B)\] <p>where $\mathcal{A}(A,B)$ are the collection of arrows from $A$ to $B$, here $\mathcal{A}(A,B)$ is regarded as a set. Thus</p> \[H^{A}: \mathcal{A}\to \text{Set}\] <p>where $\text{Set}$ is the category of sets, the objects of which are sets and the arrows are functions from one set to another. Obviously $H^{A}$ is a <em>set-valued functor</em> defined on $\mathcal{A}$. For $A’ \in \mathcal{A}$,</p> \[H^{A}(A') := \mathcal{A}(A \to A') \text{ regarded as a set}.\] <p>An easy way to remember the direction of arrows is to think of $A$ in $H^{A}$ as standing high above its peers, since it appears in superscript, it is standing “upstairs”, as a result $A$ has a pretty good view, enabling it to “see” other objects in $\mathcal{A}$, and the arrow $A \to B$ represents that $A$ is watching $B$. With this analogy, the big brother is watching everyone in the nation, this makes the big brother the <em>initial object.</em> Similarly, given $A \in \mathcal{A}$, when we need to talk about arrow coming from other objects <em>into</em> $A$, we will define the functor $H_ {A}$ where $H_ {A}(B)$ is the set of arrows from $B$ to $A$ this time, for $A$ sits at the bottom and everyone can see $A$.</p> <p>For a map $g: A’ \to A’’$ in $\mathcal{A}$, $H^{A}$ maps $g$ to another map from $H^{A}(A’)$ to $H^{A}(A’’)$ by composition, that is</p> \[H^{A}(A'): A \to A', \quad H^{A}(A'') : A\to A'', \quad H^{A}(g): (A\to A') \to (A\to A'')\] <p>where $H^{A}(g)$ is realized by</p> \[A\to A' \xrightarrow{g} A''\] <p>which is a map from $A$ to $A’’$, hence an element of $H^{A}(A’’)$.</p> <p>To explain it in a different way, consider an element $X\in H^{A}(A’)$, $X$ by construction is a map from $A$ to $A’$. Let $Y \in H^{A}(A’’)$, then $Y$ is nothing but a map from $A$ to $A’’$. Now, what is an arrow from $X$ to $Y$? It is something that maps $A\to A’$ to $A \to A’’$, which can be achieved by the composition $g\,\circ\,X$, where $g: A’ \to A’’$.</p> <p>Sometimes $H^{A}(g)$ is written as $g\,\circ\,-$, where $-$ is a place holder; or written as $g_ {\ast}$, reminding us that it is somehow “induced” by $g$. All are frequently used in publications.</p> <hr/> <p>Again, let $A$ be a locally small category. A functor</p> \[X: \mathcal{A} \to \text{Set}\] <p>is <code class="language-plaintext highlighter-rouge">representable</code> if</p> \[X \cong H^{A} \text{ for some } A \in \mathcal{A}.\] <p>$A$ is said to be a <code class="language-plaintext highlighter-rouge">representation</code> of $X$, together with an isomorphism between $H^{A}$ and $X$. In other words, when dealing with a representable functor $X$, identifying a representation for $X$ requires more than just specifying an object $A$; we must also precisely determine how $X$ is isomorphic to $H^A$.</p> <p>Representable functors are sometimes just called <code class="language-plaintext highlighter-rouge">representables</code>. Only set-valued functors (functors with codomain $\text{Set}$) can be representable.</p> <p>Representable functors are important for a few reasons. They are important for understanding the Yoneda lemma, which is the topic of this note and arguable the most profound lemma in category theory. We will introduce the Yoneda lemma shortly, roughly speaking it states that <em>every functor</em> is <em>naturally isomorphic</em> to a functor represented by some object in the category. This lemma provides a powerful tool for embedding any locally small category into a category of functors (where the arrows are natural transformations). The Yoneda embedding, which arises from this, embeds a category into a category of presheaves, preserving and reflecting properties of objects and morphisms. If you don’t know (or not interested in) what a presheave is, just ignore it.</p> <p>Furthermore, representable functors are key in the study of natural transformations. The <code class="language-plaintext highlighter-rouge">naturality condition</code> can be better understood and characterized using representables. Representables also play a role in the study of adjoints and limits. For instance, adjoint functors can often be characterized using representables, and the existence of certain limits and colimits (limits where all the arrows are reversed) can be analyzed through representable functors. Representables are also indispensable to sheaf theory and topos theory, providing a link between geometric intuition and abstract category-theoretic formalism. Unfortunately these fascinating results lie beyond the scope of this simple note.</p> <hr/> <p>Since we are already talking about the category of functors, it is perhaps a good time to mention two similar but distinct definitions in category theory, namely the category of functors and the so-called $2$-category.</p> <ul> <li> <p><strong>Category of Functors</strong>: This is a construction where the objects are functors and the morphisms between these objects are natural transformations. Specifically, given two categories $\mathcal{C}$ and $\mathcal{D}$, the category of functors, often denoted $\text{Fun}(\mathcal{C}, \mathcal{D})$ or just $[\mathcal{C},\mathcal{D}]$, has as objects all functors from $\mathcal{C}$ to $\mathcal{D}$ and as morphisms the natural transformations between these functors.</p> </li> <li> <p><strong>$2$-Category</strong>: A $2$-category is a more general and abstract concept. In a $2$-category, there are objects, morphisms between objects (also called <code class="language-plaintext highlighter-rouge">1-morphisms</code>), and morphisms between morphisms (called <code class="language-plaintext highlighter-rouge">2-morphisms</code>), or “arrows between arrows”. This structure introduces a new level of morphisms.</p> </li> </ul> <p>In a certain sense, the category of functors between two categories can be seen as a specific example of a 2-category, where the objects are the categories, the 1-morphisms are the functors between these categories, and the 2-morphisms are the natural transformations between these functors. However, the concept of a 2-category is broader and can be applied to many other contexts beyond just categories and functors.</p> <hr/> <p><strong>Example.1</strong> Consider the category of sets, denoted $\text{Set}$, let $1$ be the set of only one element. Now, what would $H^{1}$ be? It can be written as</p> \[\text{Mor}(1,-) \text{ or } \text{Hom}(1,-) \text{ or } \text{Set}(1,-),\] <p>they all mean the same thing: the maps from $1$ to something else. Let $S \in Set$, $H^{1}(S)$ would be the collection of the maps from $1$ to $S$, which is itself another set, hence</p> \[H^{1}: \text{Set} \to \text{Set}.\] <p>Since a map from $1$ to a set $S$ amounts to an element of $S$, we have</p> \[H^{1}(S) \cong S \quad \;\forall\; S \in \text{Set}.\] <p>It can be shown (which I will not do here) that this isomorphism is <em>natural</em> in $S$, so $H^{1}$ is naturally isomorphic to the identity functor $\mathbb{1}_ {\text{Set}}$. Hence $\mathbb{1}_ {\text{Set}}$ is representable, by $1$.</p> <hr/> <p>Representability is not a property shared by just any set-valued functor. In fact, rather few functors are representable, consider the total amount of functors we could construct. However, forgetful functors <em>tend to be</em> representable. We state without proof the following proposition.</p> <p><strong>Proposition.</strong> Any set-valued functor with a left adjoint is representable.</p> <hr/> <p>We have defined, for each object $A$ of category $\mathcal{A}$ , a functor $H^{A}\in[\mathcal{A},\text{Set}]$ (given two categories $\mathcal{A}$ and $\mathcal{B}$, $[\mathcal{A},\mathcal{B}]$ is the functor category from the former to the latter). This describes how $A$ sees the world. As $A$ varies, so does its view of the world. On the other hand, it is always the same world being seen, so the different views from different objects are somehow related. Generally speaking, whenever there is a map between objects $A$ and $A’$, there is also an induced map between $H^{A}$ and $H^{A’}$. Since $H^{A}$ are $H^{A’}$ are both functors (the “view” of $A,A’$), a map between them are possibly natural transformation. It is only a possibility since we still have to show that it satisfies naturality condition.</p> <p>To be precisely, a map</p> \[f: A' \to A,\quad A,A'\in \mathcal{A}\] <p>induces a natural transformation</p> \[H^{f} : H^{A} \to H^{A'}.\] <p>An interactive diagram of this can be found <a href="https://q.uiver.app/#q=WzAsMixbMCwwLCJcXG1hdGhjYWx7QX0iXSxbMywwLCJcXHRleHR7U2V0fSJdLFswLDEsIkheQSIsMCx7ImN1cnZlIjotNH1dLFswLDEsIkhee0EnfSIsMix7ImN1cnZlIjo0fV0sWzIsMywiSF5mIiwwLHsic2hvcnRlbiI6eyJzb3VyY2UiOjIwLCJ0YXJnZXQiOjIwfX1dXQ==">here</a>.</p> <p>Recall that a natural transformation $\alpha$ between two functors $F$ and $G$, both from category $\mathcal{C}$ to category $\mathcal{D}$, consists of components. Each component is a morphism in category $\mathcal{D}$. Namely, for each object $X$ in category $\mathcal{C}$, the <code class="language-plaintext highlighter-rouge">component</code> of the natural transformation $\alpha$ at $X$ is a morphism in category $\mathcal{D}$:</p> \[\alpha_ X : F(X) \rightarrow G(X)\] <p>These components must satisfy a naturality condition, which states that for every morphism $f: X \rightarrow Y$ in category $\mathcal{C}$, the naturality diagram commutes. The naturality condition must hold for all objects and morphisms in category $C$, making the transformation “natural” in the sense that it works consistently across the entire category.</p> <p>Coming back to $H^{f}$. Let $B\in \mathcal{A}$, what is the $B$-component $H^{f}_ {B}$ of $H^{f}$? Recall that $f$ maps $A’$ to $A$, by construction $H^{f}$ maps in the opposite direction, it is the function</p> \[H^{A}(B) \equiv \mathcal{A}(A,B) \to H^{A'}(B)\equiv \mathcal{A}(A',B),\] <p>in terms of the elements, let $p \in \mathcal{A}(A,B)$ we have</p> \[H^{f}: p \mapsto p\,\circ\,f.\] <p><strong>Definition.</strong> Let $\mathcal{A}$ be a locally small category, the functor</p> \[H^{-}: \mathcal{A}^{\text{op}} \to [\mathcal{A},\text{Set}]\] <p>is defined on objects such as $A$ by $H^{-}(A)=H^{A}$, and on maps such as $f$ by $H^{-}(f)=H^{f}$.</p> <p>Some explanation is in order. The dash $-$ in $H^{-}$ is a placeholder, to be filled with whatever it acts on, may it be an object or an arrow. $\mathcal{A}^{\text{op}}$ is the opposite, or dual category of $\mathcal{A}$, with same objects but reversed arrows (all of them). $\mathcal{A}^{\text{op}}$ is a category, $[\mathcal{A},\text{Set}]$ is another category ( of functors from $\mathcal{A}$ to $\text{Set}$), thus $H^{-}$ is a map from one category to another, thus a functor. $H^{-}$ of $A$ is $H^{A}$, which is a set-valued functor on $\mathcal{A}$, hence $H^{A}$ is an object of $[\mathcal{A},\text{Set}]$.</p> <p>All of the definitions presented so far in this chapter can be dualized. At the formal level, this is trivial: just reverse all the arrows! But speaking with our analogy, after dualizing it, we are no longer asking what objects see, but <em>how they are seen</em>:</p> <p>Let $\mathcal{A}$ be a <em>locally small</em> category and $A\in \mathcal{A}$. We define a functor $H_ {A}$ as follows,</p> \[H_ {A} := \mathcal{A}(-,A): \mathcal{A}^{\text{op}}\to\text{Set}\] <p>where</p> <ul> <li>for objects $B \in \mathcal{A}$, put $H_ {A}(B) = \mathcal{A}(B,A)$;</li> <li>For maps $g:B’\to B$, define</li> </ul> \[H_ {A}(g) = g^{\ast } = - \,\circ\,g: \mathcal{A}(B,A)\to\mathcal{A}(B',A)\] <p>by</p> \[p\mapsto p\,\circ\,g \quad \;\forall\; p: B\to A.\] <hr/> <p>Note that a map $B’\to B$ induces a map in the opposite direction, $H_ {A}(B)\to H_ {A}(B’)$.</p> <p>We now define representability for <em>contravariant set-valued</em> functors.</p> <p>Let $\mathcal{A}$ be a locally small category, and $X$ be a set-valued contravariant functor,</p> \[X: \mathcal{A}^{\text{op}} \to \text{Set}.\] <p>We say $X$ is <strong>representable</strong> is $X \cong H_ {A}$ for some $A\in \mathcal{A}$. A <code class="language-plaintext highlighter-rouge">representation</code> of $X$ is a choice of $A$ and an isomorphism between $X$ and $H_ {A}$.</p> <p>As an example, take the power set (contravariant-)functor $\mathcal{P}$ for example. Recall that the power set $\mathcal{P}(S)$ of a set $S$ is the collection of subsets of $S$. Let $S,S’\in \text{Set}$ be two sets, and $f: S \to S’$ a map (morphism) in the category of sets. Since we are regarding $\mathcal{P}$ as a contravariant functor, we should define $\mathcal{P}(f)$, which is a map from $\mathcal{P}(S’)$ to $\mathcal{P}(S)$, notice the reversed direction. Well, turns out this can be done in a more or less direct way: we define $\mathcal{P}(f)$ to be in a sense the <em>inverse</em> of $f$! Take $U\in\mathcal{P}(S’)$, we define the action on $U$ by $\mathcal{P}(f)$ by $f^{-1}(U)$, where $f^{-1}$ is <strong>not</strong> the inverse of $f$, for we didn’t assume that $f$ is invertible at all, but rather the preimage of $f$,</p> \[f^{-1} (U) := \left\lbrace s\in S \,\middle\vert\, f(s)\in U \right\rbrace .\] <p>On the other hand, the subsets of $S$ can be regarded as a maps from $S$ to $2$, the set with two elements, which we call <code class="language-plaintext highlighter-rouge">true</code> and <code class="language-plaintext highlighter-rouge">false</code>. To see how it works, take $S=\left\lbrace 1,2 ,3\right\rbrace$, the subset $\left\lbrace 1,2 \right\rbrace$ can be regarded as a map $g: S\to \left\lbrace \text{true,false} \right\rbrace$ where $1,2$ are map to true and $3$ is mapped to false. Such maps are sometimes called the characteristic functions. This provides as another way to look at power sets, and confirms the idea that in category theory everything is a morphism!</p> <p>Note that $\chi:=\left\lbrace \text{true,false} \right\rbrace$ is itself an object in $\text{Set}$, so we can talk about the Hom-functor $H_ {\chi}$, defined by maps from other stuff into $\chi$. Maybe not too surprisingly, $H_ {\chi}$ is isomorphic to the power functor $\mathcal{P}$,</p> \[\mathcal{P} \cong H_ {\chi}.\] <p>Try to convince yourself with it, better with some simple examples. Thus we say the power functor $\mathcal{P}$ is representable, and the representation is $\chi$.</p> <hr/> <p>Just as we assembled the covariant representables $H^{A}$’s into a big functor $H^{-}$, we can do the same for the contravariant representables $H_ {A}$. If $f: A \to A’$ is a map in $\mathcal{A}$, there is an induced natural transformation $H_ {f}$:</p> \[H_ {f}: H_ {A} \to H_ {A'},\quad H_ {A},H_ {A'}: \mathcal{A}\to\text{Set}.\] <hr/> <p>Let $\mathcal{A}$ be a locally small category. The <code class="language-plaintext highlighter-rouge">Yoneda embedding</code> of $\mathcal{A}$ is the functor</p> \[H_ {-}: \mathcal{A} \to [A^{\text{op}},\text{Set}]\] <p>defined on objects $A \in \mathcal{A}$ as $H_ {-}(A)=H_ {A}$ and arrows $H_ {-}(f)=H_ {f}$.</p> <p>Note that in $[\mathcal{A}^{\text{op}},\text{Set}]$, the objects are functors from $\mathcal{A}^{\text{op}}$ to $\text{Set}$ and the arrows are natural transformations.</p> <p>The Yoneda embedding provides a way to represent objects in a category as sets of morphisms (arrows) from other objects in the category to them. For each object $A\in\mathcal{A}$, the Yoneda embedding assigns a functor $H_ {A}$, it is sometimes called the Yoneda functor. In a sense, the Yoneda embedding allows as to regard each $A$ as arrows. Or, more precisely, it allows us to represent each $A$ as a set-valued functor. Yoneda embedding is a one-to-one correspondence between objects in $\mathcal{A}$ and functors in $[\mathcal{A},\text{Set}]$. In a sense to be explained, $H_ {-}$ embeds $\mathcal{A}$ into $[\mathcal{A},\text{Set}]$.</p> <hr/> <p>Let $\mathcal{A}$ be a locally small category, the functor</p> \[\text{Hom}_ {\mathcal{A}}: \mathcal{A}^{\text{op}}\times \mathcal{A}\to\text{Set}\] <p>is defined by the following diagram,</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/hom-480.webp 480w,/img/hom-800.webp 800w,/img/hom-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/hom.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> $\text{Hom}_ {\mathcal{A}}: \mathcal{A}^{\text{op}}\times \mathcal{A}\to\text{Set}.$ </div> <p>This is like a generalization of $\text{Hom}(A,B)$ that we have encountered before. Recall that $\text{Hom}(A,B)$ is the set of the morphisms from $A$ to $B$, now $\text{Hom}_ {\mathcal{A}}$ is generalized such that it can also take two maps $f,g$ as well.</p> <hr/> <p>Given an arbitrary object in an arbitrary category, it is in general meaningless to talk about the “element” of this object since it not necessarily a set. However, in the category of sets, an element is the same thing as a map $1\to A$. This inspires the following definition.</p> <p>Let $A$ be a locally small category. A <code class="language-plaintext highlighter-rouge">Generalized element</code> of $A$ is a map with codomain $A$. A map $S\to A$ is a generalized element of $A$ of shape $S$.</p> <p>For example, a generalized element of a set $S$ of shape $\mathbb{N}$ is nothing but a sequence in $S$. In the category of topological spaces, the generalized elements of shape $1$ (the one point space) are points, and the generalized elements of shape $\mathbb{S}^{1}$ are loops.</p> <hr/> <p><strong>Theorem.</strong></p> <p>If $H_ A \cong H_ {A’}$ where $A, A’$ are objects of a category $\mathcal{A}$ and $H_ A$ is the Yoneda embedding, then $A \cong A’$.</p> <p><strong>Proof.</strong></p> <p>To prove this theorem, we need to show that if the Yoneda embeddings $H_ A$ and $H_ {A’}$ are isomorphic as functors, then the objects $A$ and $A’$ must be isomorphic in the category $\mathcal{A}$.</p> <p>Recall that the Yoneda embedding $H_ A$ is defined as the functor:</p> \[H_ A = \text{Hom}_ {\mathcal{A}}(-, A)\] <p>Similarly,</p> \[H_ {A'} = \text{Hom}_ {\mathcal{A}}(-, A')\] <p>Given $H_ A \cong H_ {A’}$, there exists a natural isomorphism $\eta: H_ A \to H_ {A’}$. This means for each object $X$ in $\mathcal{A}$, there is an isomorphism $\eta_ X: \text{Hom}_ {\mathcal{A}}(X, A) \to \text{Hom}_ {\mathcal{A}}(X, A’)$ that is natural in $X$.</p> <p>We need to show there exists an isomorphism $f: A \to A’$ in $\mathcal{A}$.</p> <p>Consider the identity morphism $\text{id}_ A \in \text{Hom}_ {\mathcal{A}}(A, A)$. The natural isomorphism $\eta$ gives us an isomorphism:</p> \[\eta_ A: \text{Hom}_ {\mathcal{A}}(A, A) \to \text{Hom}_ {\mathcal{A}}(A, A')\] <p>Applying $\eta_ A$ to $\text{id}_ A$, we get a morphism $f \in \text{Hom}_ {\mathcal{A}}(A, A’)$:</p> \[f = \eta_ A(\text{id}_ A)\] <p>Since $\eta$ is a natural isomorphism, there exists an inverse natural transformation $\eta^{-1}$ such that $\eta^{-1} \eta = \text{id}$.</p> <p>Applying $\eta^{-1}_ {A’}$ to the identity morphism $\text{id}_ {A’} \in \text{Hom}_ {\mathcal{A}}(A’, A’)$, we get:</p> \[g = \eta^{-1}_ {A'}(\text{id}_ {A'}) \in \text{Hom}_ {\mathcal{A}}(A', A)\] <p>We now have morphisms $f: A \to A’$ and $g: A’ \to A$. We need to show that these morphisms are inverses of each other.</p> <p>Consider $f \circ g \in \text{Hom}_ {\mathcal{A}}(A’, A’)$. Since $\eta$ is a natural isomorphism, we have:</p> \[\eta_ {A'}(g) = \eta_ {A'}(\eta^{-1}_ {A'}(\text{id}_ {A'})) = \text{id}_ {A'}\] <p>Thus, $f \circ g = \text{id}_ {A’}$.</p> <p>Similarly, consider $g \circ f \in \text{Hom}_ {\mathcal{A}}(A, A)$. By the natural isomorphism $\eta$, we have:</p> \[\eta_ A(g \circ f) = \eta_ A(\eta_ A^{-1}(\text{id}_ {A})) = \text{id}_ A .\] <p>Thus, $g \circ f = \text{id}_ A$.</p> <p>Since $f \circ g = \text{id}_ {A’}$ and $g \circ f = \text{id}_ A$, it follows that $f$ and $g$ are indeed inverses of each other. Therefore, $f: A \to A’$ is an isomorphism in $\mathcal{A}$.</p> <p>If the above proof is too abstract for you, it is always a good idea to come up with a simple example through which to see in real time how the logic works. In this case, a good example is to consider the category $\text{Set}$ of sets and let $A=\left\lbrace 1,2 \right\rbrace$, $A’=\left\lbrace a,b \right\rbrace$.</p> <h1 id="2-yoneda-lemma">2. Yoneda Lemma</h1> <p>Let $\mathcal{A}$ be a locally small category so that the arrows from one object to another actually form a set. Let $X$ be a <strong>set-valued contravariant functor</strong> $X: \mathcal{A}^{\text{op}}\to\text{Set}$, let $H_ {A}$ be the Yoneda embedding, that is $H_ {A}(B)$ for all $B\in\mathcal{A}$ is the set of the arrows $\mathcal{A}[B,A]$. Now we have two distinct contravariant functor, the question is, what is the nature of the set of arrows from $H_ {A}$ to $X$? Recall that functors $\mathcal{A}^{\text{op}}\to\text{Set}$ is a presheaf, pre- in the sense that we haven’t talked about how can they be glued together to form a global sheaf. We can rephrase the question: for each $A\in\mathcal{A}$ we have a representable presheaf $H_ {A}$, if $X$ is another presheaf, what are the maps $H_ {A}\to X$?</p> <p>Since $H_ {A}$ and $X$ are both objects of the presheaf category $\text{PSh}:=[\mathcal{A}^{\text{op}},\text{Set}]$, the maps from $H_ {A}$ to $X$ are maps in $\text{PSh}$. Since $H_ {A}$ and $X$ are also functors, a map between them is a natural transformation, denoted $\text{Hom}(H_ {A},X)$.</p> <p>There is an informal principle of general category theory that allows us to guess the answer. In category theory, many conditions are indeed designed to ensure that different ways of composing arrows yield essentially the same result. This concept is central to the coherence conditions that appear in various categorical structures. Now, given all the ingredients, that is a locally small category $\mathcal{A}$, any element $A\in\mathcal{A}$, two presheaves $H_ {A}$ and $X$, we can construct two sets:</p> <ol> <li>$\text{Hom}(H_ {A},X)$, the set of the natural transformations from $H_ {A}$ to $X$ and,</li> <li>$X(A)$, the value of $A$ acted by $X$.</li> </ol> <p>The informal principle suggests that these two sets are the same:</p> \[\text{Hom}(H_ {A},X) \cong X(A).\] <p>This should hold for all $A\in\mathcal{A}$ and $X\in \text{PSh}$.</p> <p>This is the informal statement of the Yoneda lemma. The formal statement is the following.</p> <hr/> <p><strong>The Yoneda Lemma.</strong> For any functor $X: \mathcal{A}^{\text{op}} \to \text{Set}$ and any object $A$ in $\mathcal{A}$, there is a <strong>natural isomorphism</strong>:</p> \[\text{Hom}(H_ A, X) \cong X(A),\] <p>where $\text{Hom}(H_ A, X)$ is the set of natural transformations from $H_ A$ to $X$.</p> <hr/> <p>A few comments. The set $\text{Hom}(H_ A, X)$ consists of all ways you can map the functor $H_ A$ to $X$ while respecting the structure of the category. The isomorphism $\text{Hom}(H_ A, X) \cong X(A)$ means that understanding these natural transformations is equivalent to simply looking at the set $X(A)$.</p> <p>Think of $H_ A$ as a way to “probe” the structure of the category $\mathcal{A}$ using the object $A$. The Yoneda Lemma tells us that instead of looking at all possible ways to probe the category (which could be complicated), we can focus on the specific set $X(A)$, which contains all the information we need about the functor $X$.</p> <p>Now it would be helpful to look at a concrete example. Let’s use the category of sets, $\text{Set}$, and consider the set $A = \left\lbrace 1,2 \right\rbrace$. We’ll use the power set functor $P$, which maps each set to its power set (the set of all its subsets) and each function to the corresponding image function. For a set $B$, the Yoneda embedding $H_ A$ is defined as:</p> \[H_ A(B) = \text{Set}(B, A).\] <p>This is the set of all functions from $B$ to $A$.</p> <p>For the functor $P: \text{Set}^{\text{op}} \to \text{Set}$ and the set $A$, the Yoneda Lemma states that there is a natural isomorphism:</p> \[\text{Hom}(H_ A, P) \cong P(A).\] <p>Let’s apply Yoneda lemma. The Yoneda Embedding $H_ A$ reads</p> \[H_ A(B) = \text{Set}(B, \left\lbrace 1,2 \right\rbrace).\] <p>For any set $B$, this is the set of all functions from $B$ to $\left\lbrace 1,2 \right\rbrace$. The power set functor $P$ acting on $B$ reads</p> \[P(B) = \left\lbrace \text{Subsets of } B \right\rbrace .\] <p>For example, if $B = \left\lbrace a,b \right\rbrace$, then $P(B) = \left\lbrace \emptyset ,\left\lbrace a \right\rbrace ,\left\lbrace b \right\rbrace ,\left\lbrace a,b \right\rbrace \right\rbrace$. A natural transformation $\eta: H_ A \rightarrow P$ assigns to each set $B$ a function $\eta_ B: H_ A(B) \to P(B)$, satisfying a naturality condition.</p> <p>Let’s use $B = \left\lbrace a,b \right\rbrace$ and see how a natural transformation works in practice. The Yoneda Embedding $H_ A(B)$ reads</p> \[H_ A(\left\lbrace a,b \right\rbrace) = \text{Set}(\left\lbrace a,b \right\rbrace, \left\lbrace 1,2 \right\rbrace),\] <p>this is the set of all functions from $\left\lbrace a,b \right\rbrace$ to $\left\lbrace 1,2 \right\rbrace$. There are $2^2 = 4$ such functions:</p> \[f_ 1(a) = 1, f_ 1(b) = 1; \quad f_ 2(a) = 1, f_ 2(b) = 2; \quad f_ 3(a) = 2, f_ 3(b) = 1; \quad f_ 4(a) = 2, f_ 4(b) = 2.\] <p>The power set functor $P(\left\lbrace a,b \right\rbrace)$ is</p> \[P(\left\lbrace a,b \right\rbrace) = \left\lbrace \emptyset ,\left\lbrace a \right\rbrace ,\left\lbrace b \right\rbrace ,\left\lbrace a,b \right\rbrace \right\rbrace.\] <p>A natural transformation $\eta$ would map each function in $H_ A(B)$ to a subset of $B$.</p> <p>Let’s define $\eta$ by mapping each function to the subset of $B$ where the function value is 1:</p> \[\eta_ {\left\lbrace a,b \right\rbrace}(f) = \left\lbrace x \in \left\lbrace a,b \right\rbrace \,\middle\vert\, f(x) = 1 \right\rbrace\] <p>For each $f_ i$:</p> <ul> <li>$\eta(f_ 1) = \left\lbrace a,b \right\rbrace$</li> <li>$\eta(f_ 2) = \left\lbrace a\right\rbrace$</li> <li>$\eta(f_ 3) = \left\lbrace b\right\rbrace$</li> <li>$\eta(f_ 4) = \emptyset$</li> </ul> <p>This mapping respects the structure of $P(B)$, and the action of $\eta$ on morphisms (functions between sets) respects naturality.</p> <p>To have a better feeling about “naturality” in Yoneda lemma, lets yet look at one last example. Let’s consider a simple category $\mathcal{A}$ with two objects and a few morphisms. Let $\mathcal{A}$ have objects $A$ and $B$, with the following morphisms:</p> <ul> <li>$\text{Hom}_ {\mathcal{A}}(A, A) = \left\lbrace \text{id}_ A \right\rbrace$</li> <li>$\text{Hom}_ {\mathcal{A}}(B, B) = \left\lbrace \text{id}_ B \right\rbrace$</li> <li>$\text{Hom}_ {\mathcal{A}}(B, A) = \left\lbrace f \right\rbrace$</li> </ul> <p>We have $\mathcal{A}$ defined as follows:</p> \[\begin{array}{c|cc} \mathcal{A} &amp; A &amp; B \\ \hline A &amp; \text{id}_ A &amp; f \\ B &amp; \varnothing &amp; \text{id}_ B \\ \end{array}\] <p>Define a contravariant functor $X: \mathcal{A}^{\text{op}} \to \text{Set}$. Let:</p> \[X(A) = \left\lbrace x \right\rbrace \quad \text{and} \quad X(B) = \left\lbrace y_ 1, y_ 2 \right\rbrace\] <p>Now, let’s define how $X$ acts on morphisms. $X$ reverses the direction of morphisms, so we have:</p> <p>\(X(\text{id}_ A) = \text{id}_ {X(A)} = \text{id}_ {\left\lbrace x\right\rbrace}\) \(X(\text{id}_ B) = \text{id}_ {X(B)} = \text{id}_ {\left\lbrace y_ 1, y_ 2\right\rbrace}\) \(X(f) : X(A) \to X(B) \quad \text{is a function mapping } x \text{ to either } y_ 1 \text{ or } y_ 2\)</p> <p>Suppose $X(f)(x) = y_ 1$.</p> <p>Now, consider the Yoneda embedding $H_ {A}$:</p> <p>\(H_ {A}(A) = \text{Hom}_ {\mathcal{A}}(A, A) = \left\lbrace \text{id}_ A \right\rbrace\) \(H_ {A}(B) = \text{Hom}_ {\mathcal{A}}(B, A) = \left\lbrace f \right\rbrace\)</p> <p>A natural transformation $\eta : H_ {A} \to X$ consists of functions $\eta_ B: H_ {A}(B) \to X(B)$ and $\eta_ A: H_ {A}(A) \to X(A)$ such that the following diagram commutes:</p> \[\begin{array}{c} X(A) \xrightarrow{X(f)} X(B) \\ \uparrow{\eta_A} \quad \quad \uparrow{\eta_B} \\ H_ {A}(A) \xrightarrow{H_ {A}(f)} H_ {A}(B) \end{array}\] <p>More explicitly, it is</p> \[\begin{array}{c} \left\lbrace x \right\rbrace \xrightarrow{X(f)} \left\lbrace y_ {1},y_ {2} \right\rbrace \\ \uparrow{\eta_A} \quad \quad \quad \uparrow{\eta_B} \\ \mathbb{1}_ {A} \;\;\xrightarrow{H_ {A}(f)}\;\;f \;\;\;\;\; \end{array}\] <p>where $\mathbb{1}_ {A}$ is another way to write $\text{id}_ {A}$, we will use them interchangeably. The naturality condition requires that</p> \[X(f)\,\circ\,\eta_ {A} = \eta_ {B} \,\circ\,H_ {A}(f).\] <p>In our example, the components of $\eta$ are:</p> <p>\(\eta_ A : H_ {A}(A) \to X(A), \text{ which is } \quad \eta_ A(\text{id}_ A) = x\) \(\eta_ B : H_ {A}(B) \to X(B), \text{ which is } \quad \eta_ B(f) = y_ 1\)</p> <p>then the naturality condition requires that</p> \[\eta_ {B}: f\mapsto y_ {1},\] <p>not $y_ {2}$, since we defined $X(f)$ to map $x$ to $y_ {1}$. This is the power of naturality condition!</p> <p>Then, the Yoneda lemma says that $\text{Hom}(H_ {A}, X)$ is isomorphic to $X(A)=\left\lbrace x \right\rbrace$, that is, $\text{Hom}(H_ {A},X)$ consists of a single natural transformation $\eta$. There is no other way to construct a natural transformation, for example $\eta’$ such that $\eta’_ {B}:f\mapsto y_ {2}$, since it will violate the naturality condition.</p> <h1 id="3-the-proof-of-yoneda-lemma">3. The Proof of Yoneda Lemma</h1> <p>Let $\text{PSh}$ be the category of presheaves, that is the category of set-valued, contravariant functor with domain $\mathcal{A}$. It is also written as $[\mathcal{A}^{\text{op}},\text{Set}]$ or $\text{Hom}(\mathcal{A}^{\text{op}},\text{Set})$.</p> <p>In order to prove the Yoneda lemma, we need to show that for any $a\in\mathcal{A}$ and $X\in \text{PSh}$, there exists a bijection (isomorphism) between $\text{Hom}(\mathcal{A}^{\text{op}},X)$ and $X(A)$.</p> <p>Let’s define two maps:</p> <ul> <li>sharp map:</li> </ul> \[\begin{align*} \bullet^{\sharp}: \text{Hom}(H_ {A},X) &amp;\to X(A),\\ f &amp;\mapsto f^{\sharp}, \end{align*}\] <ul> <li>flat map:</li> </ul> \[\begin{align*} \bullet^{\flat}: X(A) &amp;\to\text{Hom}(H_ {A},X),\\ x &amp;\mapsto x^{\flat}. \end{align*}\] <p>We will first construct ${\sharp}$ and $\flat$ maps, then demonstrate that they are mutually inverse, that is $\sharp\,\circ\,\flat=\flat\,\circ\,\sharp=\mathbb{1}$.</p> <p>Given $\alpha: H_ {A}\to X$, $\alpha ^{\sharp}\in X(A)$. We need find an element in $X(A)$ so that we can identify $\alpha ^{\sharp}$ with it, that is how we construct the sharp map. Now, we don’t know anything about $X(A)$, except that $\alpha_ {A}$, namely the $A$-component of $\alpha$, maps $H_ {A}(A)$ to $X(A)$. Now we need to find an element in $H_ {A}(A)$ so we can apply $\alpha_ {A}$ on it, an obvious choice is simply $\mathbb{1}_ {A}$. $H_ {A}(\mathbb{1}_ {A})\in X(A)$, so we define</p> \[\boxed{ \alpha ^{\sharp} := \alpha_ {A}(\mathbb{1}_ {A}). }\] <p>In a sense, we are using $\alpha$ to define $\alpha ^{\sharp}$.</p> <hr/> <p>Next we move on to construct the flat map that maps $X(A)$ to $\text{Hom}(H_ {A},X)$. Let $x\in X(A)$, $x^{\flat} \in H_ {A}\to X$. If you draw all the relations down and stare at it for long enough, you will eventually find the way to construct $x^{\flat}$ from all the ingredients we have. To define $x^{\flat}$ we need to define each component of $x^{\flat}$. Let $B\in \mathcal{A}$ be any object, the $B$-component of $x^{\flat}$ (recall that $x^{\flat}$ is a natural transformation) maps $H_ {A}(B)$ to $X(B)$. Let $f\in H_ {A}(B)$, $f: B\to A$, thus $X(f):X(A)\to X(B)$. Write $X(f)$ as $X_ {f}$ for short. $X_ {f}(x)\in X(B)$, it is just what we needed, namely an element in $X(B)$, to define $x^{\flat}$! Now we can let</p> \[\begin{align*} x^{\flat}_ {B}: H_ {A}(B) &amp;\to X(B), \\ f &amp;\mapsto X_ {f}(x). \end{align*}\] <p>Next we need to show that the naturality condition is satisfied. Naturality means that for any $B,B’\in\mathcal{A}$, in the following diagram the blue part commutes.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/Yoneda1-480.webp 480w,/img/Yoneda1-800.webp 800w,/img/Yoneda1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/Yoneda1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Naturality condition means that the blue square commutes. </div> <p>Follow the left-top path, $x^{\flat}_ {B}$ sends $f$ to $X_ {f}(x)$, then $X_ {g}$ sends it to $X_ {g}\,\circ\,X_ {f}(x)$. Follow the bottom-right path, $H_ {A}(g)=-\,\circ\,g$ sends $f$ to $f\,\circ\,g$, then $x^{\flat}_ {B’}$ sends it to $X_ {f\,\circ\,g}(x)$. Since $X$ is a contravariant functor, $X_ {f\,\circ\,g}=X_ {g}\,\circ\,X_ {f}$, thus these two different ways to compose arrows are the same!</p> <hr/> <p>Next, we show that $\sharp\,\circ\,\flat$ is identity map, which means that given any $x\in X(A)$,</p> \[(x^{\flat})^{\sharp}=x.\] <p>Recall that, by construction for $\alpha \in \text{Hom}(H_ {A},X(A))$, $\alpha ^{\sharp}=\alpha_ {A}(\mathbb{1}_ {A})$. Apply this to $x^{\flat}$ we have</p> \[x^{\flat}=x^{\flat}_ {A}(\mathbb{1}_ {A}).\] <p>Then</p> \[(x^{\flat})^{\sharp}=x^{\flat}_ {A}(\mathbb{1}_ {A}).\] <p>How does the sharp map work? Given $y\in X_ {A}$ and any $B\in\mathcal{A}$, $y^{\flat}: f\mapsto X_ {f}(y)$, where $f\in \text{Hom}(B,A)$. Apply this to the above equation, let $f=\mathbb{1}_ {A}$ and $y=x$, we have</p> \[(x^{\flat})^{\sharp}=x^{\flat}_ {A}(\mathbb{1}_ {A}) = X_ {\mathbb{1}_ {A}}(x),\] <p>Since $X$ as a functor must map $\mathbb{1}_ {A}$ to $\mathbb{1}_ {X(A)}$,</p> \[(x^{\flat})^{\sharp}=x^{\flat}_ {A}(\mathbb{1}_ {A}) = X_ {\mathbb{1}_ {A}}(x) = \mathbb{1}_ {X(A)}(x)=x.\] <hr/> <p>Next we need to show that $\flat\,\circ\,\sharp=\mathbb{1}$, that is</p> \[(\alpha ^{\sharp})^{\flat}=\mathbb{1}.\] <p>First regard $\alpha ^{\sharp}$ as whole and perform the flat map. Let $B\in\mathcal{A}$ and $f\in H_ {A}(B)$, for the $B$-component of natural transformation $(\alpha ^{\sharp})^{\flat}$ we have</p> \[(\alpha ^{\sharp})^{\flat}_ {B}: f\mapsto X_ {f}(\alpha ^{\sharp}).\] <p>Then performing the sharp map, $\alpha ^{\sharp}:\alpha\mapsto \alpha_ {A}(\mathbb{1}_ {A})$, thus</p> \[(\alpha ^{\sharp})^{\flat}_ {B}: f\mapsto X_ {f}(\alpha ^{\sharp}) = X_ {f}(\alpha_ {A}(\mathbb{1}_ {A})).\] <p>To evaluate $X_ {f}(\alpha_ {A}(\mathbb{1}_ {A}))$ we need to use the naturality condition between $A,B\in\mathcal{A}$ and $f:B\to A$, which says the following two maps are identical:</p> \[\begin{align*} H_ {A}(A) &amp;\xrightarrow{H_ {A}(f) =-\,\circ\,f}H_ {A}(B) \xrightarrow{\alpha_ {B}} X(B), \\ H_ {A}(A) &amp; \xrightarrow{\alpha_ {A}}X(A)\xrightarrow{X_ {f}}X(B). \end{align*}\] <p>Then \(X_ {f}(\alpha_ {A}(\mathbb{1}_ {A})) = \alpha_ {B}(f).\)</p> <p>Thus we have</p> \[(\alpha ^{\sharp})^{\flat}_ {B}(f) = \alpha_ {B(f)} \implies (\alpha ^{\sharp})^{\flat} = \alpha.\] <hr/> <p>We have established the bijection between $\text{Hom}(H_ {A},X)$ and $X$, for each $A$ and $X$. For the last part of our proof, we need to show that this bijection is natural for all the $A$ and $X$.</p> <p>Naturality in $A$ states that for all $X$ and $B\in\mathcal{A}$, let $f\in H_ {A}(B)$, the following square commutes.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/naturalityInA-480.webp 480w,/img/naturalityInA-800.webp 800w,/img/naturalityInA-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/naturalityInA.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The naturality condition in $A$, where $H_f=H(f)$. </div> <p>Natural transformation is a map between two functors, so when we talk about naturality in $A$, what functors are we talking about? One of them is the functor that maps $A$ to $\text{Hom}(H_ {A},X)$, let’s denote it by $\text{Hom}(H_ {\bullet},X)$; The other functor is just $X$.</p> <p>Let $\alpha \in \text{Hom}(H_ {A},X)$, recall that we constructed $A^{\sharp}$ by $A^{\sharp}=\alpha_ {A}(\mathbb{1}_ {A})$. The element-version of naturality in $A$ reads</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/natAele-480.webp 480w,/img/natAele-800.webp 800w,/img/natAele-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/natAele.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The naturality condition in $A$ written in elements. Strictly speaking the arrows should be $\mapsto$. </div> <p>Now we need to show that in the right-bottom corner, the equality holds. Since $H_ {f}:= f\,\circ\,-$,</p> \[H_ {f}(\mathbb{1}_ {B}) = f\,\circ\mathbb{1}_ {B}=f.\] <p>Thus</p> \[(\alpha \,\circ\,H_ {f})(\mathbb{1}_ {B}) = \alpha_ {B}(f).\] <p>The naturality in $X$ is easier. It states that the following diagram commutes.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/naturalityInX-480.webp 480w,/img/naturalityInX-800.webp 800w,/img/naturalityInX-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/naturalityInX.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The naturality condition in $X$. </div> <p>in terms of elements, we have the following diagram. It is obvious to see that it indeed commutes.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/natXele-480.webp 480w,/img/natXele-800.webp 800w,/img/natXele-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/natXele.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The naturality condition in $X$ written in elements. Strictly speaking the arrows should be $\mapsto$. </div> <h1 id="4-consequences-of-the-yoneda-lemma">4. Consequences of the Yoneda Lemma</h1> <p>The Yoneda lemma is fundamental in category theory. Here we look at some important consequences.</p> <p><strong>Corollary 1.</strong> Let $\mathcal{A}$ be a locally small category. Let $X$ be a presheaf on $\mathcal{A}$. A representation of $X$ is an object $A\in\mathcal{A}$ together with one element $u\in X(A)$, such that for all $B\in \mathcal{A}$ and $x \in X(B)$, there is a unique map $\overline{x}:B\to A$ such that $X_ {\overline{x}}(u)=x$.</p> <p>Recall that by definition, a representation is an $A\in \mathcal{A}$ and a natural isomorphism</p> \[\alpha: H_ {A} \xrightarrow{\sim}X\] <p>where $\xrightarrow{\sim}$ means an isomorphism. The corollary then says that such pairs $(X,\alpha)$ are in natural bijection with pairs $(A,\mu)$, such that</p> \[X_ {\overline{x}}(u) = x.\] <p>Pairs $(B,x)$ with $B\in\mathcal{A}$ are sometimes called elements of $X$. The element $u$ is sometimes called a universal element of $X$, since $u$ can point to anything in $X(B)$.</p> <p>To prove the corollary, we need only to show that the natural transformation $u^{\flat}: H_ {A}\to X$ is an isomorphism, which means that $X$ indeed has a representation, namely $(A, u^{\flat})$, iff for all $B$ and $x\in X(B)$, there exists a unique $\overline{x}: B\to A$ such that</p> \[X_ {\overline{x}}(u) = x.\] <p>By definition, $u^{\flat}$ is an isomorphism iff for all $B$,</p> \[u^{\flat}(B): H_ {A} (B) \xrightarrow{\sim} X(B).\] <p>But we already have</p> \[u^{\flat}_ {B}(\overline{x}) = X_ {\overline{x}}(u)\] <p>by construction, thus we have proved the corollary.</p> <hr/> <p>Another consequence of the Yoneda lemma is the following.</p> <p><strong>Corollary 2.</strong> For any locally small category $\mathcal{A}$, the Yoneda embedding</p> \[H_ {\bullet}: \mathcal{A} \to \text{Hom}(\mathcal{A}^{\text{op}},\text{Set})\] <p>is full and faithful.</p> <p>Informally, this says that for any $A,A’\in\mathcal{A}$, a map $H_ {A}\to H_ {A’}$ is the same thing as a map $A \to A’$.</p> <p>We will now write down the detailed proof, but just mention that the key point is let $X$ in the Yoneda lemma</p> \[\text{Hom}(H_ {A},X) \cong X(A)\] <p>to be $H_ {A’}$.</p> <p>The word “embedding” is used to mean a map $A\to B$ that makes $A$ isomorphic to its image in $B$. For example, a bijection $F: A\to B$ may be called an embedding, for $A$ is isomorphic to its image $f(A)$ in $B$. Corollary 2 says that a full and faithful functor $F: \mathcal{A}\to \mathcal{B}$ can be reasonably called an embedding, as it makes $\mathcal{A}$ equivalent to its image in $\mathcal{B}$.</p> <hr/> <p>The third consequence of the Yoneda lemma is the following.</p> <p><strong>Corollary 3.</strong> Let $\mathcal{A}$ be a locally small category, and $A,A’\in\mathcal{A}$. Then</p> \[H_ {A}\cong H_ {A'} \Longleftrightarrow A\cong A' \Longleftrightarrow H^{A}\cong H^{A'}.\] <p>We will also neglect the proof here.</p> <hr/> <p>Another interesting application of the Yoneda lemma can be found in Terrence Tao’s blog <a href="https://terrytao.wordpress.com/2023/08/25/yonedas-lemma-as-an-identification-of-form-and-function-the-case-study-of-polynomials/">here</a>, titled <em>Yoneda’s lemma as an identification of form and function: the case study of polynomials</em>. In his blog, Terrence Tao talked about formal polynomials, or polynomial forms $\mathbb{Z}[n]$ and polynomial functions $\mathbb{Z}[n]$. In the former, the indeterminate $n$ is a purely formal object, while in the latter, $n$ can take value in any ring $R$. Terrence Tao mentioned that</p> <blockquote> <p>… one only interprets polynomial forms in a specific ring $R$, then some information about the polynomial could be lost (and some features of the polynomial, such as roots, may be “invisible” to that interpretation). But this turns out not to be the case if one considers interpretations in all rings simultaneously…</p> </blockquote> <p>For example, consider the simplest linear formal polynomial $f=n$, it is different from $f=-n$. However, in the two-element ring $\mathbb{Z}_ {2}$, since for $a\in\mathbb{Z}_ {2}$, $a\equiv-a$.</p> <p>Given a Polynomial form $P$ which can act on different rings, such as $R$ and $S$, we have</p> \[P: R\to R \quad \text{or} \quad S\to S.\] <p>It is obvious, since given a formal polynomial $P(n)\in \mathbb{Z}[n]$, we can turn it into a <strong>polynomial function</strong> on ring $R$, which is a map $R\to R$, if we let $n=x$ for some $x\in R$, let’s denote it by $P_ {R}$. Similarly for ring $S$. Let $\phi: R\to S$ be a ring homomorphism, then we have the following commutation relation:</p> \[\phi \,\circ\, P_ {R} = P_ {S} \,\circ\, \phi\] <p>It means that the ring homomorphism is compatible to polynomial functions, which is not so surprising. The surprising part is that the converse statement is also true: Let $F$ be a function that can act on different rings, for example if $F$ acts on a ring $R$, then we write</p> \[F_ {R} : R\to R,\] <p>Similarly for ring $S$, $F_ {S}: S\to S$. Let $\phi: R\to S$ be a ring homomorphism. The statement is that, if</p> \[\phi \,\circ\,F_ {R} = F_ {S} \,\circ\, \phi\] <p>holds for <strong>all rings</strong> and <strong>all homomorphisms</strong>, then $F=P$ for some polynomial form $P\in \mathbb{Z}[ [n] ]$. Note that $F$ could be <strong>any functions</strong>, but as long as it satisfies the condition, then it must be a <strong>polynomial function</strong>.</p> <p>To better understand the statement, let’s set $A=\mathbb{Z}[[ n ]]$, turns out, $\mathbb{Z}[[ n ]]$ as an object in the category $\text{Ring}$ of rings is quite powerful, for the reason that we can construct a lot of arrows from it to other rings, it can see a lot, like the big brother from <em>1984</em>.Apply the commutation relation between any function $F$ and $\phi$, where</p> \[\phi: \mathbb{Z}[[ n ]] \to R\] <p>is the evaluation map, and let $x\in R$. For example, the action of $\phi_ {x}$ on $n$ is to give $n$ the value of $x$. The commutation relation is shown in the following figure, both in sets and in elements.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/commutePolynomial-480.webp 480w,/img/commutePolynomial-800.webp 800w,/img/commutePolynomial-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/commutePolynomial.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Commutation relation. We have picked an element $n\in \mathbb{Z}[[n]]$. </div> <p>Now the Yoneda lemma comes into play. There are two categories at play here: $\text{Ring}$ and $\text{Set}$, and the forgetful</p> \[U: \text{Ring} \to \text{Set}\] <p>is defined to map a ring $R$ to its underlying set $U(R)$, and maps a ring homomorphism $\phi$ to the corresponding function between sets $U(\phi)$.</p> <p>Here is a change of perspective: the function $F$ can be regarded as a natural transformation! And we will show that the naturality condition is nothing but the commutation relation. As a natural transformation, it maps underling functor to underlying functor, for example, we said that</p> \[F_ {\mathbb{Z}[[ n ]] } : \mathbb{Z}[[n]] \to \mathbb{Z}[[n]]\] <p>Now regard $F_ {\mathbb{Z}[[n]]}$ as the $\mathbb{Z}[[n]]$-component of $F$, and the right-hand-side actually should be a function not between $\mathbb{Z}[[n]]$, but between the underlying sets $U(\mathbb{Z}[[n]])$. Take $F_ {R}$ for example, $F_ {R}: R\to R$ should be in fact a function $F_ {R}: U(R) \to U(R)$.</p> <p>The commutation relation between $\phi$ and $F$ is equivalent to the naturality condition, as is shown in the figure below.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/img/naturalityCommute-480.webp 480w,/img/naturalityCommute-800.webp 800w,/img/naturalityCommute-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/img/naturalityCommute.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The naturality condition is equivalent to the commutation relation. </div> <p>The identification between the polynomial forms and functions can now be written as</p> \[U(\mathbb{Z}[[n]])\cong \text{Hom}(U,U)\equiv F.\] <p>On the other hand, given an element $x\in R$, the evaluation map provides a map $\phi_ {x}: \mathbb{Z}[[n]] \to R$. Conversely, given an evaluation map $\phi$, we can identify an element $x\in R$ by evaluate $n$, that is $x_ {\phi}:=\phi(n)$. Thus the evaluation homomorphism provides a 1-2-1 correspondence between $R$ and maps in $\mathbb{Z}[[n]]\to R$. This correspondence is, again, at the level of sets $U(R)$ and $\text{Hom}(\mathbb{Z}[[n]],R)$. We write the correspondence in a form that applies for all the rings:</p> \[U(-) \cong \text{Hom}(\mathbb{Z}[[n]],-).\] <p>Now come back to the last-last equation, in the second term in $\text{Hom}(U,U)$ we can rewrite the first $U$ as</p> \[U \cong \text{Hom}(\mathbb{Z}[[n]],-) = H^{\mathbb{Z}[[n]]},\] <p>the identification between functions and polynomial forms can be written as</p> \[U(\mathbb{Z}[[n]]) ~===~ \text{Hom}(H^{\mathbb{Z}[[n]]},U),\] <p>which is the familiar Yoneda lemma</p> \[X(A) \cong \text{Hom}(H^{A},X).\]]]></content><author><name>Baiyang Zhang</name></author><category term="categoryTheory"/><summary type="html"><![CDATA[Table of Contents]]></summary></entry></feed>